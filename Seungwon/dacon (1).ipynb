{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dacon.ipynb","provenance":[],"collapsed_sections":["byckt4mfDb9Z"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"8b20da70d77f4923a036435a358786b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fa2de959e4fd4c4b891e440884e26e9a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e87fffa978954feb8075ac44b9b3e1e7","IPY_MODEL_27006a08c8724da9a6e1df4e653379cc"]}},"fa2de959e4fd4c4b891e440884e26e9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e87fffa978954feb8075ac44b9b3e1e7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_495d0a976e824c2aac6d4755d4f46b75","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":112563643,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":112563643,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b2bfa047d3d0417caeacf68877e0b55f"}},"27006a08c8724da9a6e1df4e653379cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_51d2028db6b041de8acda16d35213766","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 107M/107M [01:18&lt;00:00, 1.43MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bdf3a40232914e0b9bb52d0f16d95ca2"}},"495d0a976e824c2aac6d4755d4f46b75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b2bfa047d3d0417caeacf68877e0b55f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51d2028db6b041de8acda16d35213766":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bdf3a40232914e0b9bb52d0f16d95ca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YeERJDh7eHdx","executionInfo":{"status":"ok","timestamp":1613584806881,"user_tz":-540,"elapsed":18348,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}},"outputId":"21d1ed6e-ad45-4d38-f721-1a30f875a8b1"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4SzhHo9LeJ9Y","executionInfo":{"status":"ok","timestamp":1613585008169,"user_tz":-540,"elapsed":128630,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}}},"source":["from google.colab import output\r\n","# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\r\n","!cp \"/content/drive/MyDrive/data_2.zip\" \"data_2.zip\"\r\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czO39sqLeKkv","executionInfo":{"status":"ok","timestamp":1613585114072,"user_tz":-540,"elapsed":233807,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}},"outputId":"1de6c109-134c-4e40-a80a-51bb73825050"},"source":["# data_2.zip을 현재 디렉터리에 압축해제\r\n","!unzip \"data_2.zip\""],"execution_count":2,"outputs":[{"output_type":"stream","text":["Archive:  data_2.zip\n","  inflating: dirty_mnist_2nd.zip     \n","  inflating: dirty_mnist_2nd_answer.csv  \n","  inflating: mnist_data.zip          \n","  inflating: sample_submission.csv   \n","  inflating: test_dirty_mnist_2nd.zip  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ytSAiaxieLVu","executionInfo":{"status":"ok","timestamp":1613585216261,"user_tz":-540,"elapsed":335251,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}}},"source":["from google.colab import output\r\n","# 현재 디렉터리에 dirty_mnist라는 폴더 생성\r\n","!mkdir \"./dirty_mnist\"\r\n","#dirty_mnist.zip라는 zip파일을 dirty_mnist라는 폴더에 압축 풀기\r\n","!unzip \"dirty_mnist_2nd.zip\" -d \"./dirty_mnist/\"\r\n","# 현재 디렉터리에 test_dirty_mnist라는 폴더 생성\r\n","!mkdir \"./test_dirty_mnist\"\r\n","#test_dirty_mnist.zip라는 zip파일을 test_dirty_mnist라는 폴더에 압축 풀기\r\n","!unzip \"test_dirty_mnist_2nd.zip\" -d \"./test_dirty_mnist/\"\r\n","# 출력 결과 지우기\r\n","output.clear()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"zY1whAqydW0R"},"source":["class SELayer(nn.Module):\r\n","    def __init__(self, channel, reduction=16):\r\n","        super(SELayer, self).__init__()\r\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\r\n","        self.fc = nn.Sequential(\r\n","            nn.Linear(channel, channel // reduction, bias=False),\r\n","            nn.ReLU(inplace=True),\r\n","            nn.Dropout(p=drop_prob),\r\n","            nn.Linear(channel // reduction, channel, bias=False),\r\n","            nn.Sigmoid()\r\n","        )\r\n","\r\n","    def forward(self, x):\r\n","        b, c, _, _ = x.size()\r\n","        y = self.avg_pool(x).view(b, c)\r\n","        y = self.fc(y).view(b, c, 1, 1)\r\n","        return x * y.expand_as(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":102,"referenced_widgets":["8b20da70d77f4923a036435a358786b3","fa2de959e4fd4c4b891e440884e26e9a","e87fffa978954feb8075ac44b9b3e1e7","27006a08c8724da9a6e1df4e653379cc","495d0a976e824c2aac6d4755d4f46b75","b2bfa047d3d0417caeacf68877e0b55f","51d2028db6b041de8acda16d35213766","bdf3a40232914e0b9bb52d0f16d95ca2"]},"id":"eeQnPvk1rwYb","executionInfo":{"status":"ok","timestamp":1613585222626,"user_tz":-540,"elapsed":340698,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}},"outputId":"6d331135-c9a9-437a-ad5c-8dba55109e5a"},"source":["'''\r\n","import torch.hub\r\n","hub_model = torch.hub.load(\r\n","    'moskomule/senet.pytorch',\r\n","    'se_resnet50',\r\n","    pretrained=True,)\r\n","'''"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading: \"https://github.com/moskomule/senet.pytorch/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n","Downloading: \"https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl\" to /root/.cache/torch/hub/checkpoints/seresnet50-60a8950a85b2b.pkl\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8b20da70d77f4923a036435a358786b3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=112563643.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s0b-JZFkeSnI","executionInfo":{"status":"ok","timestamp":1613585222880,"user_tz":-540,"elapsed":340347,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}}},"source":["\r\n","import torch.nn as nn\r\n","from torch.hub import load_state_dict_from_url\r\n","from torchvision.models import ResNet\r\n","from senet.se_module import SELayer\r\n","\r\n","\r\n","def conv3x3(in_planes, out_planes, stride=1):\r\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\r\n","\r\n","\r\n","class SEBasicBlock(nn.Module):\r\n","    expansion = 1\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n","                 base_width=64, dilation=1, norm_layer=None,\r\n","                 *, reduction=16):\r\n","        super(SEBasicBlock, self).__init__()\r\n","        self.conv1 = conv3x3(inplanes, planes, stride)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.dropout1 = torch.nn.Dropout(p=drop_prob)\r\n","        self.conv2 = conv3x3(planes, planes, 1)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.se = SELayer(planes, reduction)\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = x\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","        out = self.dropout1(out)\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","        out = self.se(out)\r\n","\r\n","        if self.downsample is not None:\r\n","            residual = self.downsample(x)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","        return out\r\n","\r\n","\r\n","class SEBottleneck(nn.Module):\r\n","    expansion = 4\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n","                 base_width=64, dilation=1, norm_layer=None,\r\n","                 *, reduction=16):\r\n","        super(SEBottleneck, self).__init__()\r\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\r\n","                               padding=1, bias=False)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\r\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.se = SELayer(planes * 4, reduction)\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = x\r\n","\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv3(out)\r\n","        out = self.bn3(out)\r\n","        out = self.se(out)\r\n","\r\n","        if self.downsample is not None:\r\n","            residual = self.downsample(x)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","\r\n","        return out\r\n","\r\n","\r\n","def se_resnet18(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-18 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBasicBlock, [2, 2, 2, 2], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","\r\n","'''\r\n","def se_resnet34(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","'''\r\n","\r\n","def se_resnet50(num_classes=1_000, pretrained=False):\r\n","    \"\"\"Constructs a ResNet-50 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBottleneck, [3, 4, 6, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    if pretrained:\r\n","        model.load_state_dict(load_state_dict_from_url(\r\n","            \"https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl\"))\r\n","    return model\r\n","\r\n","\r\n","def se_resnet101(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-101 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBottleneck, [3, 4, 23, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","\r\n","\r\n","def se_resnet152(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-152 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBottleneck, [3, 8, 36, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","\r\n","\r\n","class CifarSEBasicBlock(nn.Module):\r\n","    def __init__(self, inplanes, planes, stride=1, reduction=16):\r\n","        super(CifarSEBasicBlock, self).__init__()\r\n","        self.conv1 = conv3x3(inplanes, planes, stride)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.conv2 = conv3x3(planes, planes)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.se = SELayer(planes, reduction)\r\n","        if inplanes != planes:\r\n","            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\r\n","                                            nn.BatchNorm2d(planes))\r\n","        else:\r\n","            self.downsample = lambda x: x\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = self.downsample(x)\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","        out = self.se(out)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","\r\n","        return out\r\n","\r\n","\r\n","class CifarSEResNet(nn.Module):\r\n","    def __init__(self, block, n_size, num_classes=10, reduction=16):\r\n","        super(CifarSEResNet, self).__init__()\r\n","        self.inplane = 16\r\n","        self.conv1 = nn.Conv2d(\r\n","            3, self.inplane, kernel_size=3, stride=1, padding=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(self.inplane)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.layer1 = self._make_layer(\r\n","            block, 16, blocks=n_size, stride=1, reduction=reduction)\r\n","        self.layer2 = self._make_layer(\r\n","            block, 32, blocks=n_size, stride=2, reduction=reduction)\r\n","        self.layer3 = self._make_layer(\r\n","            block, 64, blocks=n_size, stride=2, reduction=reduction)\r\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","        self.fc = nn.Linear(64, num_classes)\r\n","        self.initialize()\r\n","\r\n","    def initialize(self):\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","\r\n","    def _make_layer(self, block, planes, blocks, stride, reduction):\r\n","        strides = [stride] + [1] * (blocks - 1)\r\n","        layers = []\r\n","        for stride in strides:\r\n","            layers.append(block(self.inplane, planes, stride, reduction))\r\n","            self.inplane = planes\r\n","\r\n","        return nn.Sequential(*layers)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.conv1(x)\r\n","        x = self.bn1(x)\r\n","        x = self.relu(x)\r\n","\r\n","        x = self.layer1(x)\r\n","        x = self.layer2(x)\r\n","        x = self.layer3(x)\r\n","\r\n","        x = self.avgpool(x)\r\n","        x = x.view(x.size(0), -1)\r\n","        x = self.fc(x)\r\n","\r\n","        return x\r\n","\r\n","\r\n","class CifarSEPreActResNet(CifarSEResNet):\r\n","    def __init__(self, block, n_size, num_classes=10, reduction=16):\r\n","        super(CifarSEPreActResNet, self).__init__(\r\n","            block, n_size, num_classes, reduction)\r\n","        self.bn1 = nn.BatchNorm2d(self.inplane)\r\n","        self.initialize()\r\n","\r\n","    def forward(self, x):\r\n","        x = self.conv1(x)\r\n","        x = self.layer1(x)\r\n","        x = self.layer2(x)\r\n","        x = self.layer3(x)\r\n","\r\n","        x = self.bn1(x)\r\n","        x = self.relu(x)\r\n","\r\n","        x = self.avgpool(x)\r\n","        x = x.view(x.size(0), -1)\r\n","        x = self.fc(x)\r\n","\r\n","\r\n","def se_resnet20(**kwargs):\r\n","    \"\"\"Constructs a ResNet-18 model.\r\n","    \"\"\"\r\n","    model = CifarSEResNet(CifarSEBasicBlock, 3, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_resnet32(**kwargs):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    \"\"\"\r\n","    model = CifarSEResNet(CifarSEBasicBlock, 5, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_resnet56(**kwargs):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    \"\"\"\r\n","    model = CifarSEResNet(CifarSEBasicBlock, 9, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_preactresnet20(**kwargs):\r\n","    \"\"\"Constructs a ResNet-18 model.\r\n","    \"\"\"\r\n","    model = CifarSEPreActResNet(CifarSEBasicBlock, 3, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_preactresnet32(**kwargs):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    \"\"\"\r\n","    model = CifarSEPreActResNet(CifarSEBasicBlock, 5, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_preactresnet56(**kwargs):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    \"\"\"\r\n","    model = CifarSEPreActResNet(CifarSEBasicBlock, 9, **kwargs)\r\n","    return model\r\n","\r\n","\r\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"vH3QdHfxeZnd","executionInfo":{"status":"ok","timestamp":1613585223813,"user_tz":-540,"elapsed":339493,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}}},"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import cv2\r\n","from tqdm import tqdm\r\n","import imutils\r\n","import zipfile\r\n","import os\r\n","from PIL import Image\r\n","from torchsummary import summary\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torchvision.models as models\r\n","import torchvision.transforms as T\r\n","from torch.utils.data import DataLoader, Dataset\r\n","from google.colab import output\r\n","\r\n","from torch.hub import load_state_dict_from_url\r\n","from torchvision.models import ResNet\r\n","from senet.se_module import SELayer\r\n","\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 디바이스 설정\r\n","learning_rate = 0.001\r\n","training_epochs = 15\r\n","batch_size = 100\r\n","drop_prob = 0.3"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Ihlr-kBeaj2","executionInfo":{"status":"ok","timestamp":1613585223815,"user_tz":-540,"elapsed":337662,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}}},"source":["dirty_mnist_answer = pd.read_csv(\"/content/dirty_mnist_2nd_answer.csv\")\r\n","# dirty_mnist라는 디렉터리 속에 들어있는 파일들의 이름을 \r\n","# namelist라는 변수에 저장\r\n","namelist = os.listdir('./dirty_mnist/')\r\n","\r\n","# unmpy를 tensor로 변환하는 ToTensor 정의\r\n","class ToTensor(object):\r\n","    \"\"\"numpy array를 tensor(torch)로 변환합니다.\"\"\"\r\n","    def __call__(self, sample):\r\n","        image, label = sample['image'], sample['label']\r\n","        # swap color axis because\r\n","        # numpy image: H x W x C\r\n","        # torch image: C X H X W\r\n","        image = image.transpose((2, 0, 1))\r\n","        return {'image': torch.FloatTensor(image),\r\n","                'label': torch.FloatTensor(label)}\r\n","# to_tensor 선언\r\n","to_tensor = T.Compose([\r\n","                      ToTensor()\r\n","                    ])\r\n","\r\n","class DatasetMNIST(torch.utils.data.Dataset):\r\n","    def __init__(self,\r\n","                 dir_path,\r\n","                 meta_df,\r\n","                 transforms=to_tensor,#미리 선언한 to_tensor를 transforms로 받음\r\n","                 augmentations=None):\r\n","        \r\n","        self.dir_path = dir_path # 데이터의 이미지가 저장된 디렉터리 경로\r\n","        self.meta_df = meta_df # 데이터의 인덱스와 정답지가 들어있는 DataFrame\r\n","\r\n","        self.transforms = transforms# Transform\r\n","        self.augmentations = augmentations # Augmentation\r\n","        \r\n","    def __len__(self):\r\n","        return len(self.meta_df)\r\n","    \r\n","    def __getitem__(self, index):\r\n","        # 폴더 경로 + 이미지 이름 + .png => 파일의 경로\r\n","        # 참고) \"12\".zfill(5) => 000012\r\n","        #       \"146\".zfill(5) => 000145\r\n","        # cv2.IMREAD_GRAYSCALE : png파일을 채널이 1개인 GRAYSCALE로 읽음\r\n","        image = cv2.imread(self.dir_path +\\\r\n","                           str(self.meta_df.iloc[index,0]).zfill(5) + '.png',\r\n","                           cv2.IMREAD_GRAYSCALE)\r\n","        # 0 ~ 255의 값을 갖고 크기가 (256,256)인 numpy array를\r\n","        # 0 ~ 1 사이의 실수를 갖고 크기가 (256,256,1)인 numpy array로 변환\r\n","        image = (image/255).astype('float')[..., np.newaxis]\r\n","        # 정답 numpy array생성(존재하면 1 없으면 0)\r\n","        label = self.meta_df.iloc[index, 1:].values.astype('float')\r\n","        sample = {'image': image, 'label': label}\r\n","        # transform 적용\r\n","        # numpy to tensor\r\n","        if self.transforms:\r\n","            sample = self.transforms(sample)\r\n","\r\n","        # sample 반환\r\n","        return sample"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"3FY4M-FJebgu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613585234366,"user_tz":-540,"elapsed":346521,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}},"outputId":"8389654c-9175-4441-b0c1-0960d56cfa64"},"source":["# nn.Module을 상속 받아 MultiLabelResnet를 정의\r\n","class MultiLabelResnet(nn.Module):\r\n","    def __init__(self):\r\n","        super(MultiLabelResnet, self).__init__()\r\n","        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\r\n","        self.resnet = models.resnet18() \r\n","        self.FC = nn.Linear(1000, 26)\r\n","\r\n","    def forward(self, x):\r\n","        # resnet의 입력은 [3, N, N]으로\r\n","        # 3개의 채널을 갖기 때문에\r\n","        # resnet 입력 전에 conv2d를 한 층 추가\r\n","        x = F.relu(self.conv2d(x))\r\n","\r\n","        # resnet18을 추가\r\n","        x = F.relu(self.resnet(x))\r\n","\r\n","        # 마지막 출력에 nn.Linear를 추가\r\n","        # multilabel을 예측해야 하기 때문에\r\n","        # softmax가 아닌 sigmoid를 적용\r\n","        x = torch.sigmoid(self.FC(x))\r\n","        return x\r\n","# 모델 선언\r\n","model = MultiLabelResnet()\r\n","model.to(device)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultiLabelResnet(\n","  (conv2d): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n","  (resnet): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (FC): Linear(in_features=1000, out_features=26, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"I074H89JecWS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613585234744,"user_tz":-540,"elapsed":344679,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}},"outputId":"587314e3-21bc-4766-da44-facd5038ebef"},"source":["def se_resnet34(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","\r\n","# nn.Module을 상속 받아 MultiLabelResnet를 정의\r\n","class my_resnet_34(nn.Module):\r\n","    def __init__(self):\r\n","        super(my_resnet_34, self).__init__()\r\n","        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\r\n","        self.se_resnet34 =se_resnet34()\r\n","        self.FC = nn.Linear(1000, 26)\r\n","\r\n","    def forward(self, x):\r\n","        # resnet의 입력은 [3, N, N]으로\r\n","        # 3개의 채널을 갖기 때문에\r\n","        # resnet 입력 전에 conv2d를 한 층 추가\r\n","        x = F.relu(self.conv2d(x))\r\n","\r\n","        # resnet18을 추가\r\n","        x = F.relu(self.se_resnet34(x))\r\n","\r\n","        # 마지막 출력에 nn.Linear를 추가\r\n","        # multilabel을 예측해야 하기 때문에\r\n","        # softmax가 아닌 sigmoid를 적용\r\n","        x = torch.sigmoid(self.FC(x))\r\n","        return x\r\n","# 모델 선언\r\n","hub_model = my_resnet_34()\r\n","hub_model.to(device)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["my_resnet_34(\n","  (conv2d): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n","  (se_resnet34): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=4, out_features=64, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=4, out_features=64, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=4, out_features=64, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (3): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (3): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (4): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (5): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=32, out_features=512, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=32, out_features=512, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=32, out_features=512, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=1)\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (FC): Linear(in_features=1000, out_features=26, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"h15uJmGyedOj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613585234746,"user_tz":-540,"elapsed":343003,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}},"outputId":"fb375c9d-302d-4d0f-a54e-e5f96a573524"},"source":["summary(hub_model, input_size=(1, 28, 28))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 3, 26, 26]              30\n","            Conv2d-2           [-1, 64, 13, 13]           9,408\n","       BatchNorm2d-3           [-1, 64, 13, 13]             128\n","              ReLU-4           [-1, 64, 13, 13]               0\n","         MaxPool2d-5             [-1, 64, 7, 7]               0\n","            Conv2d-6             [-1, 64, 7, 7]          36,864\n","       BatchNorm2d-7             [-1, 64, 7, 7]             128\n","              ReLU-8             [-1, 64, 7, 7]               0\n","            Conv2d-9             [-1, 64, 7, 7]          36,864\n","      BatchNorm2d-10             [-1, 64, 7, 7]             128\n","AdaptiveAvgPool2d-11             [-1, 64, 1, 1]               0\n","           Linear-12                    [-1, 4]             256\n","             ReLU-13                    [-1, 4]               0\n","           Linear-14                   [-1, 64]             256\n","          Sigmoid-15                   [-1, 64]               0\n","          SELayer-16             [-1, 64, 7, 7]               0\n","             ReLU-17             [-1, 64, 7, 7]               0\n","     SEBasicBlock-18             [-1, 64, 7, 7]               0\n","           Conv2d-19             [-1, 64, 7, 7]          36,864\n","      BatchNorm2d-20             [-1, 64, 7, 7]             128\n","             ReLU-21             [-1, 64, 7, 7]               0\n","           Conv2d-22             [-1, 64, 7, 7]          36,864\n","      BatchNorm2d-23             [-1, 64, 7, 7]             128\n","AdaptiveAvgPool2d-24             [-1, 64, 1, 1]               0\n","           Linear-25                    [-1, 4]             256\n","             ReLU-26                    [-1, 4]               0\n","           Linear-27                   [-1, 64]             256\n","          Sigmoid-28                   [-1, 64]               0\n","          SELayer-29             [-1, 64, 7, 7]               0\n","             ReLU-30             [-1, 64, 7, 7]               0\n","     SEBasicBlock-31             [-1, 64, 7, 7]               0\n","           Conv2d-32             [-1, 64, 7, 7]          36,864\n","      BatchNorm2d-33             [-1, 64, 7, 7]             128\n","             ReLU-34             [-1, 64, 7, 7]               0\n","           Conv2d-35             [-1, 64, 7, 7]          36,864\n","      BatchNorm2d-36             [-1, 64, 7, 7]             128\n","AdaptiveAvgPool2d-37             [-1, 64, 1, 1]               0\n","           Linear-38                    [-1, 4]             256\n","             ReLU-39                    [-1, 4]               0\n","           Linear-40                   [-1, 64]             256\n","          Sigmoid-41                   [-1, 64]               0\n","          SELayer-42             [-1, 64, 7, 7]               0\n","             ReLU-43             [-1, 64, 7, 7]               0\n","     SEBasicBlock-44             [-1, 64, 7, 7]               0\n","           Conv2d-45            [-1, 128, 4, 4]          73,728\n","      BatchNorm2d-46            [-1, 128, 4, 4]             256\n","             ReLU-47            [-1, 128, 4, 4]               0\n","           Conv2d-48            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-49            [-1, 128, 4, 4]             256\n","AdaptiveAvgPool2d-50            [-1, 128, 1, 1]               0\n","           Linear-51                    [-1, 8]           1,024\n","             ReLU-52                    [-1, 8]               0\n","           Linear-53                  [-1, 128]           1,024\n","          Sigmoid-54                  [-1, 128]               0\n","          SELayer-55            [-1, 128, 4, 4]               0\n","           Conv2d-56            [-1, 128, 4, 4]           8,192\n","      BatchNorm2d-57            [-1, 128, 4, 4]             256\n","             ReLU-58            [-1, 128, 4, 4]               0\n","     SEBasicBlock-59            [-1, 128, 4, 4]               0\n","           Conv2d-60            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-61            [-1, 128, 4, 4]             256\n","             ReLU-62            [-1, 128, 4, 4]               0\n","           Conv2d-63            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-64            [-1, 128, 4, 4]             256\n","AdaptiveAvgPool2d-65            [-1, 128, 1, 1]               0\n","           Linear-66                    [-1, 8]           1,024\n","             ReLU-67                    [-1, 8]               0\n","           Linear-68                  [-1, 128]           1,024\n","          Sigmoid-69                  [-1, 128]               0\n","          SELayer-70            [-1, 128, 4, 4]               0\n","             ReLU-71            [-1, 128, 4, 4]               0\n","     SEBasicBlock-72            [-1, 128, 4, 4]               0\n","           Conv2d-73            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-74            [-1, 128, 4, 4]             256\n","             ReLU-75            [-1, 128, 4, 4]               0\n","           Conv2d-76            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-77            [-1, 128, 4, 4]             256\n","AdaptiveAvgPool2d-78            [-1, 128, 1, 1]               0\n","           Linear-79                    [-1, 8]           1,024\n","             ReLU-80                    [-1, 8]               0\n","           Linear-81                  [-1, 128]           1,024\n","          Sigmoid-82                  [-1, 128]               0\n","          SELayer-83            [-1, 128, 4, 4]               0\n","             ReLU-84            [-1, 128, 4, 4]               0\n","     SEBasicBlock-85            [-1, 128, 4, 4]               0\n","           Conv2d-86            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-87            [-1, 128, 4, 4]             256\n","             ReLU-88            [-1, 128, 4, 4]               0\n","           Conv2d-89            [-1, 128, 4, 4]         147,456\n","      BatchNorm2d-90            [-1, 128, 4, 4]             256\n","AdaptiveAvgPool2d-91            [-1, 128, 1, 1]               0\n","           Linear-92                    [-1, 8]           1,024\n","             ReLU-93                    [-1, 8]               0\n","           Linear-94                  [-1, 128]           1,024\n","          Sigmoid-95                  [-1, 128]               0\n","          SELayer-96            [-1, 128, 4, 4]               0\n","             ReLU-97            [-1, 128, 4, 4]               0\n","     SEBasicBlock-98            [-1, 128, 4, 4]               0\n","           Conv2d-99            [-1, 256, 2, 2]         294,912\n","     BatchNorm2d-100            [-1, 256, 2, 2]             512\n","            ReLU-101            [-1, 256, 2, 2]               0\n","          Conv2d-102            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-103            [-1, 256, 2, 2]             512\n","AdaptiveAvgPool2d-104            [-1, 256, 1, 1]               0\n","          Linear-105                   [-1, 16]           4,096\n","            ReLU-106                   [-1, 16]               0\n","          Linear-107                  [-1, 256]           4,096\n","         Sigmoid-108                  [-1, 256]               0\n","         SELayer-109            [-1, 256, 2, 2]               0\n","          Conv2d-110            [-1, 256, 2, 2]          32,768\n","     BatchNorm2d-111            [-1, 256, 2, 2]             512\n","            ReLU-112            [-1, 256, 2, 2]               0\n","    SEBasicBlock-113            [-1, 256, 2, 2]               0\n","          Conv2d-114            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-115            [-1, 256, 2, 2]             512\n","            ReLU-116            [-1, 256, 2, 2]               0\n","          Conv2d-117            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-118            [-1, 256, 2, 2]             512\n","AdaptiveAvgPool2d-119            [-1, 256, 1, 1]               0\n","          Linear-120                   [-1, 16]           4,096\n","            ReLU-121                   [-1, 16]               0\n","          Linear-122                  [-1, 256]           4,096\n","         Sigmoid-123                  [-1, 256]               0\n","         SELayer-124            [-1, 256, 2, 2]               0\n","            ReLU-125            [-1, 256, 2, 2]               0\n","    SEBasicBlock-126            [-1, 256, 2, 2]               0\n","          Conv2d-127            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-128            [-1, 256, 2, 2]             512\n","            ReLU-129            [-1, 256, 2, 2]               0\n","          Conv2d-130            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-131            [-1, 256, 2, 2]             512\n","AdaptiveAvgPool2d-132            [-1, 256, 1, 1]               0\n","          Linear-133                   [-1, 16]           4,096\n","            ReLU-134                   [-1, 16]               0\n","          Linear-135                  [-1, 256]           4,096\n","         Sigmoid-136                  [-1, 256]               0\n","         SELayer-137            [-1, 256, 2, 2]               0\n","            ReLU-138            [-1, 256, 2, 2]               0\n","    SEBasicBlock-139            [-1, 256, 2, 2]               0\n","          Conv2d-140            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-141            [-1, 256, 2, 2]             512\n","            ReLU-142            [-1, 256, 2, 2]               0\n","          Conv2d-143            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-144            [-1, 256, 2, 2]             512\n","AdaptiveAvgPool2d-145            [-1, 256, 1, 1]               0\n","          Linear-146                   [-1, 16]           4,096\n","            ReLU-147                   [-1, 16]               0\n","          Linear-148                  [-1, 256]           4,096\n","         Sigmoid-149                  [-1, 256]               0\n","         SELayer-150            [-1, 256, 2, 2]               0\n","            ReLU-151            [-1, 256, 2, 2]               0\n","    SEBasicBlock-152            [-1, 256, 2, 2]               0\n","          Conv2d-153            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-154            [-1, 256, 2, 2]             512\n","            ReLU-155            [-1, 256, 2, 2]               0\n","          Conv2d-156            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-157            [-1, 256, 2, 2]             512\n","AdaptiveAvgPool2d-158            [-1, 256, 1, 1]               0\n","          Linear-159                   [-1, 16]           4,096\n","            ReLU-160                   [-1, 16]               0\n","          Linear-161                  [-1, 256]           4,096\n","         Sigmoid-162                  [-1, 256]               0\n","         SELayer-163            [-1, 256, 2, 2]               0\n","            ReLU-164            [-1, 256, 2, 2]               0\n","    SEBasicBlock-165            [-1, 256, 2, 2]               0\n","          Conv2d-166            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-167            [-1, 256, 2, 2]             512\n","            ReLU-168            [-1, 256, 2, 2]               0\n","          Conv2d-169            [-1, 256, 2, 2]         589,824\n","     BatchNorm2d-170            [-1, 256, 2, 2]             512\n","AdaptiveAvgPool2d-171            [-1, 256, 1, 1]               0\n","          Linear-172                   [-1, 16]           4,096\n","            ReLU-173                   [-1, 16]               0\n","          Linear-174                  [-1, 256]           4,096\n","         Sigmoid-175                  [-1, 256]               0\n","         SELayer-176            [-1, 256, 2, 2]               0\n","            ReLU-177            [-1, 256, 2, 2]               0\n","    SEBasicBlock-178            [-1, 256, 2, 2]               0\n","          Conv2d-179            [-1, 512, 1, 1]       1,179,648\n","     BatchNorm2d-180            [-1, 512, 1, 1]           1,024\n","            ReLU-181            [-1, 512, 1, 1]               0\n","          Conv2d-182            [-1, 512, 1, 1]       2,359,296\n","     BatchNorm2d-183            [-1, 512, 1, 1]           1,024\n","AdaptiveAvgPool2d-184            [-1, 512, 1, 1]               0\n","          Linear-185                   [-1, 32]          16,384\n","            ReLU-186                   [-1, 32]               0\n","          Linear-187                  [-1, 512]          16,384\n","         Sigmoid-188                  [-1, 512]               0\n","         SELayer-189            [-1, 512, 1, 1]               0\n","          Conv2d-190            [-1, 512, 1, 1]         131,072\n","     BatchNorm2d-191            [-1, 512, 1, 1]           1,024\n","            ReLU-192            [-1, 512, 1, 1]               0\n","    SEBasicBlock-193            [-1, 512, 1, 1]               0\n","          Conv2d-194            [-1, 512, 1, 1]       2,359,296\n","     BatchNorm2d-195            [-1, 512, 1, 1]           1,024\n","            ReLU-196            [-1, 512, 1, 1]               0\n","          Conv2d-197            [-1, 512, 1, 1]       2,359,296\n","     BatchNorm2d-198            [-1, 512, 1, 1]           1,024\n","AdaptiveAvgPool2d-199            [-1, 512, 1, 1]               0\n","          Linear-200                   [-1, 32]          16,384\n","            ReLU-201                   [-1, 32]               0\n","          Linear-202                  [-1, 512]          16,384\n","         Sigmoid-203                  [-1, 512]               0\n","         SELayer-204            [-1, 512, 1, 1]               0\n","            ReLU-205            [-1, 512, 1, 1]               0\n","    SEBasicBlock-206            [-1, 512, 1, 1]               0\n","          Conv2d-207            [-1, 512, 1, 1]       2,359,296\n","     BatchNorm2d-208            [-1, 512, 1, 1]           1,024\n","            ReLU-209            [-1, 512, 1, 1]               0\n","          Conv2d-210            [-1, 512, 1, 1]       2,359,296\n","     BatchNorm2d-211            [-1, 512, 1, 1]           1,024\n","AdaptiveAvgPool2d-212            [-1, 512, 1, 1]               0\n","          Linear-213                   [-1, 32]          16,384\n","            ReLU-214                   [-1, 32]               0\n","          Linear-215                  [-1, 512]          16,384\n","         Sigmoid-216                  [-1, 512]               0\n","         SELayer-217            [-1, 512, 1, 1]               0\n","            ReLU-218            [-1, 512, 1, 1]               0\n","    SEBasicBlock-219            [-1, 512, 1, 1]               0\n","AdaptiveAvgPool2d-220            [-1, 512, 1, 1]               0\n","          Linear-221                 [-1, 1000]         513,000\n","          ResNet-222                 [-1, 1000]               0\n","          Linear-223                   [-1, 26]          26,026\n","================================================================\n","Total params: 21,980,912\n","Trainable params: 21,980,912\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.99\n","Params size (MB): 83.85\n","Estimated Total Size (MB): 85.85\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MRzNcwB_shTg"},"source":["#weights,biases = hub_model.layers[0].get_weights()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pH4URwebeeX0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613557544910,"user_tz":-540,"elapsed":6550644,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"023fd36a-154e-41a6-9047-9f64c3ba12a6"},"source":["# cross validation을 적용하기 위해 KFold 생성\r\n","from sklearn.model_selection import KFold\r\n","def fit(learning_rate=0.001, epochs=10, train_batch_size=128, test_batch_size=32, drop_prob=0.3):\r\n","  kfold = KFold(n_splits=5, shuffle=True, random_state=0)\r\n","\r\n","  # dirty_mnist_answer에서 train_idx와 val_idx를 생성\r\n","  best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\r\n","  for fold_index, (trn_idx, val_idx) in enumerate(kfold.split(dirty_mnist_answer),1):\r\n","      print(f'[fold: {fold_index}]')\r\n","      # cuda cache 초기화\r\n","      torch.cuda.empty_cache()\r\n","\r\n","      #train fold, validation fold 분할\r\n","      train_answer = dirty_mnist_answer.iloc[trn_idx]\r\n","      test_answer  = dirty_mnist_answer.iloc[val_idx]\r\n","\r\n","      #Dataset 정의\r\n","      train_dataset = DatasetMNIST(\"dirty_mnist/\", train_answer)\r\n","      valid_dataset = DatasetMNIST(\"dirty_mnist/\", test_answer)\r\n","    \r\n","      #DataLoader 정의\r\n","      train_data_loader = DataLoader(\r\n","          train_dataset,\r\n","          batch_size = train_batch_size,\r\n","          shuffle = False,\r\n","          num_workers = 3,\r\n","          drop_last=True\r\n","      )\r\n","      valid_data_loader = DataLoader(\r\n","          valid_dataset,\r\n","          batch_size = test_batch_size,\r\n","          shuffle = False,\r\n","          num_workers = 3,\r\n","          drop_last=True\r\n","      )\r\n","      # 모델 선언\r\n","      #model = MultiLabelResnet()\r\n","      #model=torch.load(('/content/drive/MyDrive/Colab Notebooks/dacon/models/5_resnet18_0.8095_epoch_0.pth'))\r\n","\r\n","      #model.to(device)# gpu에 모델 할당\r\n","\r\n","      # 훈련 옵션 설정\r\n","      optimizer = torch.optim.Adam(hub_model.parameters(),\r\n","                                  lr = learning_rate)\r\n","      lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\r\n","                                                  step_size = 5,\r\n","                                                  gamma = 0.75)\r\n","      criterion = torch.nn.BCELoss()\r\n","      \r\n","      # 훈련 시작\r\n","      valid_acc_max = 0\r\n","      for epoch in range(epochs):\r\n","          \r\n","          # 1개 epoch 훈련\r\n","          train_acc_list = []\r\n","          with tqdm(train_data_loader,#train_data_loader를 iterative하게 반환\r\n","                  total=train_data_loader.__len__(), # train_data_loader의 크기\r\n","                  unit=\"batch\") as train_bar:# 한번 반환하는 smaple의 단위는 \"batch\"\r\n","\r\n","                  for sample in train_bar:\r\n","                    train_bar.set_description(f\"Train Epoch {epoch}\")\r\n","                    # 갱신할 변수들에 대한 모든 변화도를 0으로 초기화\r\n","                    # 참고)https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html\r\n","                    optimizer.zero_grad()\r\n","                    images, labels = sample['image'], sample['label']\r\n","\r\n","                    # tensor를 gpu에 올리기 \r\n","                    images = images.to(device)\r\n","                    labels = labels.to(device)\r\n","                  \r\n","                    # 모델의 dropoupt, batchnormalization를 train 모드로 설정\r\n","                    hub_model.train()\r\n","                    # .forward()에서 중간 노드의 gradient를 계산\r\n","                    with torch.set_grad_enabled(True):\r\n","                        # 모델 예측\r\n","                        probs  = hub_model(images)\r\n","                        # loss 계산\r\n","                        loss = criterion(probs, labels)\r\n","                        # 중간 노드의 gradient로\r\n","                        # backpropagation을 적용하여\r\n","                        # gradient 계산\r\n","                        loss.backward()\r\n","                        # weight 갱신\r\n","                        optimizer.step()\r\n","\r\n","                        # train accuracy 계산\r\n","                        probs  = probs.cpu().detach().numpy()\r\n","                        labels = labels.cpu().detach().numpy()\r\n","                        preds = probs > 0.5\r\n","                        batch_acc = (labels == preds).mean()\r\n","                        train_acc_list.append(batch_acc)\r\n","                        train_acc = np.mean(train_acc_list)\r\n","\r\n","                    # 현재 progress bar에 현재 미니배치의 loss 결과 출력\r\n","                    train_bar.set_postfix(train_loss= loss.item(),\r\n","                                          train_acc = train_acc)\r\n","          # 1개 epoch학습 후 Validation 점수 계산\r\n","          valid_acc_list = []\r\n","          with tqdm(valid_data_loader,\r\n","                  total=valid_data_loader.__len__(),\r\n","                  unit=\"batch\") as valid_bar:\r\n","              for sample in valid_bar:\r\n","\r\n","                valid_bar.set_description(f\"Valid Epoch {epoch}\")\r\n","                optimizer.zero_grad()\r\n","                images, labels = sample['image'], sample['label']\r\n","                images = images.to(device)\r\n","                labels = labels.to(device)\r\n","                \r\n","                # 모델의 dropoupt, batchnormalization를 eval모드로 설정\r\n","                hub_model.eval()\r\n","                # .forward()에서 중간 노드의 gradient를 계산\r\n","                with torch.no_grad():\r\n","\r\n","                  # validation loss만을 계산\r\n","                  probs  = hub_model(images)\r\n","                  valid_loss = criterion(probs, labels)\r\n","\r\n","                  # train accuracy 계산\r\n","                  probs  = probs.cpu().detach().numpy()\r\n","                  labels = labels.cpu().detach().numpy()\r\n","                  preds = probs > 0.5\r\n","                  batch_acc = (labels == preds).mean()\r\n","                  valid_acc_list.append(batch_acc)\r\n","\r\n","                valid_acc = np.mean(valid_acc_list)\r\n","                valid_bar.set_postfix(valid_loss = valid_loss.item(),\r\n","                                        valid_acc = valid_acc)\r\n","                      \r\n","          # Learning rate 조절\r\n","          lr_scheduler.step()\r\n","\r\n","          # 모델 저장\r\n","          if valid_acc_max < valid_acc:\r\n","              valid_acc_max = valid_acc\r\n","              best_model = hub_model\r\n","              MODEL = \"SE-resnet34\"\r\n","              # 모델을 저장할 구글 드라이브 경로\r\n","              path = \"/content/drive/MyDrive/Colab Notebooks/models/\"\r\n","              torch.save(best_model, f'{path}{fold_index}_{MODEL}_{valid_loss.item():2.4f}_epoch_{epoch}.pth')\r\n","      \r\n","      # 폴드별로 가장 좋은 모델 저장\r\n","      best_models.append(best_model)\r\n","\r\n","\r\n","fit()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 1]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [04:57<00:00,  1.05batch/s, train_acc=0.549, train_loss=0.681]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:27<00:00, 11.23batch/s, valid_acc=0.493, valid_loss=0.726]\n","Train Epoch 1: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.564, train_loss=0.671]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:27<00:00, 11.22batch/s, valid_acc=0.542, valid_loss=0.68]\n","Train Epoch 2: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.574, train_loss=0.661]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:27<00:00, 11.26batch/s, valid_acc=0.551, valid_loss=0.697]\n","Train Epoch 3: 100%|██████████| 312/312 [04:58<00:00,  1.05batch/s, train_acc=0.584, train_loss=0.654]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:27<00:00, 11.28batch/s, valid_acc=0.582, valid_loss=0.661]\n","Train Epoch 4: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.595, train_loss=0.649]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:27<00:00, 11.22batch/s, valid_acc=0.569, valid_loss=0.673]\n","Train Epoch 5: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.61, train_loss=0.639]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:27<00:00, 11.18batch/s, valid_acc=0.566, valid_loss=0.665]\n","Train Epoch 6: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.621, train_loss=0.628]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:27<00:00, 11.30batch/s, valid_acc=0.592, valid_loss=0.658]\n","Train Epoch 7: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.633, train_loss=0.616]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:28<00:00, 11.00batch/s, valid_acc=0.578, valid_loss=0.696]\n","Train Epoch 8: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.641, train_loss=0.605]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:28<00:00, 10.93batch/s, valid_acc=0.591, valid_loss=0.681]\n","Train Epoch 9: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.648, train_loss=0.597]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:28<00:00, 10.98batch/s, valid_acc=0.571, valid_loss=0.772]\n","  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 2]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.645, train_loss=0.601]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:28<00:00, 11.04batch/s, valid_acc=0.623, valid_loss=0.632]\n","Train Epoch 1: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.658, train_loss=0.585]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:28<00:00, 11.05batch/s, valid_acc=0.624, valid_loss=0.622]\n","Train Epoch 2: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.667, train_loss=0.577]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:28<00:00, 11.08batch/s, valid_acc=0.601, valid_loss=0.745]\n","Train Epoch 3: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.673, train_loss=0.562]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:28<00:00, 10.98batch/s, valid_acc=0.605, valid_loss=0.719]\n","Train Epoch 4: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.678, train_loss=0.547]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:28<00:00, 11.01batch/s, valid_acc=0.604, valid_loss=0.7]\n","Train Epoch 5: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.687, train_loss=0.538]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:28<00:00, 10.92batch/s, valid_acc=0.595, valid_loss=0.739]\n","Train Epoch 6: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.697, train_loss=0.526]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:28<00:00, 10.99batch/s, valid_acc=0.618, valid_loss=0.736]\n","Train Epoch 7: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.703, train_loss=0.515]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:28<00:00, 10.97batch/s, valid_acc=0.594, valid_loss=0.877]\n","Train Epoch 8: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.707, train_loss=0.498]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:28<00:00, 10.94batch/s, valid_acc=0.582, valid_loss=1.05]\n","Train Epoch 9: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.712, train_loss=0.491]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:28<00:00, 10.90batch/s, valid_acc=0.566, valid_loss=1.28]\n","  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 3]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.695, train_loss=0.535]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:28<00:00, 10.99batch/s, valid_acc=0.663, valid_loss=0.612]\n","Train Epoch 1: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.711, train_loss=0.495]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:28<00:00, 11.00batch/s, valid_acc=0.649, valid_loss=0.717]\n","Train Epoch 2: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.717, train_loss=0.491]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:28<00:00, 11.01batch/s, valid_acc=0.635, valid_loss=0.942]\n","Train Epoch 3: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.72, train_loss=0.48]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:28<00:00, 11.08batch/s, valid_acc=0.651, valid_loss=0.748]\n","Train Epoch 4: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.725, train_loss=0.471]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:28<00:00, 11.07batch/s, valid_acc=0.625, valid_loss=0.958]\n","Train Epoch 5: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.732, train_loss=0.464]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:28<00:00, 11.01batch/s, valid_acc=0.649, valid_loss=0.757]\n","Train Epoch 6: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.744, train_loss=0.442]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:28<00:00, 11.02batch/s, valid_acc=0.664, valid_loss=0.685]\n","Train Epoch 7: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.752, train_loss=0.426]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:28<00:00, 10.98batch/s, valid_acc=0.654, valid_loss=0.712]\n","Train Epoch 8: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.757, train_loss=0.426]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:28<00:00, 10.97batch/s, valid_acc=0.66, valid_loss=0.725]\n","Train Epoch 9: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.763, train_loss=0.416]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:28<00:00, 11.02batch/s, valid_acc=0.646, valid_loss=0.938]\n","  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 4]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.742, train_loss=0.472]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:28<00:00, 10.96batch/s, valid_acc=0.712, valid_loss=0.535]\n","Train Epoch 1: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.765, train_loss=0.426]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:28<00:00, 11.04batch/s, valid_acc=0.7, valid_loss=0.594]\n","Train Epoch 2: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.77, train_loss=0.417]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:28<00:00, 11.07batch/s, valid_acc=0.705, valid_loss=0.516]\n","Train Epoch 3: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.771, train_loss=0.411]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:28<00:00, 11.04batch/s, valid_acc=0.692, valid_loss=0.617]\n","Train Epoch 4: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.778, train_loss=0.394]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:28<00:00, 11.02batch/s, valid_acc=0.696, valid_loss=0.593]\n","Train Epoch 5: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.785, train_loss=0.371]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:28<00:00, 10.99batch/s, valid_acc=0.712, valid_loss=0.529]\n","Train Epoch 6: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.794, train_loss=0.361]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:28<00:00, 11.03batch/s, valid_acc=0.714, valid_loss=0.551]\n","Train Epoch 7: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.797, train_loss=0.354]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:28<00:00, 11.00batch/s, valid_acc=0.716, valid_loss=0.542]\n","Train Epoch 8: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.798, train_loss=0.356]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:28<00:00, 11.08batch/s, valid_acc=0.714, valid_loss=0.733]\n","Train Epoch 9: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.8, train_loss=0.358]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:28<00:00, 10.96batch/s, valid_acc=0.712, valid_loss=0.69]\n","  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 5]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.778, train_loss=0.433]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:28<00:00, 11.00batch/s, valid_acc=0.759, valid_loss=0.412]\n","Train Epoch 1: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.794, train_loss=0.375]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:28<00:00, 11.02batch/s, valid_acc=0.759, valid_loss=0.406]\n","Train Epoch 2: 100%|██████████| 312/312 [04:58<00:00,  1.04batch/s, train_acc=0.799, train_loss=0.367]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:28<00:00, 11.02batch/s, valid_acc=0.745, valid_loss=0.47]\n","Train Epoch 3: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.797, train_loss=0.354]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:28<00:00, 11.01batch/s, valid_acc=0.73, valid_loss=0.498]\n","Train Epoch 4: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.799, train_loss=0.361]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:28<00:00, 10.96batch/s, valid_acc=0.75, valid_loss=0.457]\n","Train Epoch 5: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.807, train_loss=0.333]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:28<00:00, 10.95batch/s, valid_acc=0.748, valid_loss=0.468]\n","Train Epoch 6: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.816, train_loss=0.317]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:28<00:00, 11.10batch/s, valid_acc=0.758, valid_loss=0.446]\n","Train Epoch 7: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.82, train_loss=0.314]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:28<00:00, 10.88batch/s, valid_acc=0.748, valid_loss=0.502]\n","Train Epoch 8: 100%|██████████| 312/312 [05:00<00:00,  1.04batch/s, train_acc=0.82, train_loss=0.314]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:28<00:00, 10.91batch/s, valid_acc=0.753, valid_loss=0.465]\n","Train Epoch 9: 100%|██████████| 312/312 [04:59<00:00,  1.04batch/s, train_acc=0.818, train_loss=0.327]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:28<00:00, 11.04batch/s, valid_acc=0.745, valid_loss=0.51]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"byckt4mfDb9Z"},"source":["# SaveModel 하나 불러오기"]},{"cell_type":"code","metadata":{"id":"oRiBcxctefv3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1613578000469,"user_tz":-540,"elapsed":2040,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"e90daacc-d7eb-45e7-c164-9c7323990aa3"},"source":["savemodel=torch.load(('/content/drive/MyDrive/Colab Notebooks/dacon/models2/5_SE-resnet34_0.4120_epoch_0.pth'))\r\n","savemodel"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["my_resnet_34(\n","  (conv2d): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n","  (se_resnet34): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=4, out_features=64, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=4, out_features=64, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=4, out_features=64, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (3): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (3): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (4): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (5): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=32, out_features=512, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=32, out_features=512, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=32, out_features=512, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=1)\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (FC): Linear(in_features=1000, out_features=26, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"_tUnHr6YvlAH"},"source":["#test Dataset 정의\r\n","sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","test_dataset = DatasetMNIST(\"test_dirty_mnist/\", sample_submission)\r\n","batch_size = 128\r\n","test_data_loader = DataLoader(\r\n","    test_dataset,\r\n","    batch_size = batch_size,\r\n","    shuffle = False,\r\n","    num_workers = 3,\r\n","    drop_last = False\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-s0YmIylwSOG"},"source":["predictions_list = []\r\n","# 배치 단위로 추론\r\n","prediction_df = pd.read_csv(\"sample_submission.csv\")\r\n","\r\n","# 5개의 fold마다 가장 좋은 모델을 이용하여 예측\r\n","\r\n","# 0으로 채워진 array 생성\r\n","prediction_array = np.zeros([prediction_df.shape[0],\r\n","                             prediction_df.shape[1] -1])\r\n","for idx, sample in enumerate(test_data_loader):\r\n","    with torch.no_grad():\r\n","       # 추론\r\n","        hub_model.eval()\r\n","        images = sample['image']\r\n","        images = images.to(device)\r\n","        probs  = hub_model(images)\r\n","        probs = probs.cpu().detach().numpy()\r\n","        preds = (probs > 0.5)\r\n","\r\n","        # 예측 결과를 \r\n","        # prediction_array에 입력\r\n","        batch_index = batch_size * idx\r\n","        prediction_array[batch_index: batch_index + images.shape[0],:]\\\r\n","                     = preds.astype(int)\r\n","                         \r\n","# 채널을 하나 추가하여 list에 append\r\n","predictions_list.append(prediction_array[...,np.newaxis])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"jEkqauLKwx6B","executionInfo":{"status":"ok","timestamp":1613580035788,"user_tz":-540,"elapsed":626,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"9b3f24bf-15b6-4381-fd11-44fbcc396e8a"},"source":["answer=predictions_list[0]\r\n","answer=answer.astype('int64')\r\n","answer.shape\r\n","answer=np.squeeze(answer, 2)\r\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 0, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 0, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 0, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 1, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 1, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 0, 1])"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"EW3UEy9txNfR","executionInfo":{"status":"ok","timestamp":1613580327422,"user_tz":-540,"elapsed":643,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"62a0bc7d-5e84-4236-c0d8-01f7b1d9dbc4"},"source":["sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","sample_submission.iloc[:,1:] = answer\r\n","sample_submission.to_csv(\"/content/drive/MyDrive/Colab Notebooks/se_resnet34_prediction.csv\", index = False)\r\n","sample_submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","      <th>f</th>\n","      <th>g</th>\n","      <th>h</th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>k</th>\n","      <th>l</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>o</th>\n","      <th>p</th>\n","      <th>q</th>\n","      <th>r</th>\n","      <th>s</th>\n","      <th>t</th>\n","      <th>u</th>\n","      <th>v</th>\n","      <th>w</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50001</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>50002</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50003</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50004</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>54995</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>54996</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>54997</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>54998</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>54999</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 27 columns</p>\n","</div>"],"text/plain":["      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n","0     50000  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","1     50001  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","2     50002  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","3     50003  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  1  1\n","4     50004  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  1  1\n","...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n","4995  54995  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","4996  54996  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","4997  54997  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  1  1\n","4998  54998  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","4999  54999  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  1  1\n","\n","[5000 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"7rX_u9KaDt5T"},"source":["# 모델 다 불러와서 Ensemble"]},{"cell_type":"code","metadata":{"id":"em87pHWeGBmK","executionInfo":{"status":"ok","timestamp":1613585981775,"user_tz":-540,"elapsed":1507,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}}},"source":["model_path_front='/content/drive/MyDrive/Colab Notebooks/dacon/models2/'\r\n","model_names=['1_SE-resnet34_0.6583_epoch_6.pth', '1_SE-resnet34_0.6610_epoch_3.pth', '1_SE-resnet34_0.6799_epoch_1.pth', '1_SE-resnet34_0.6967_epoch_2.pth', \\\r\n","             '1_SE-resnet34_0.7262_epoch_0.pth', '2_SE-resnet34_0.6222_epoch_1.pth', '2_SE-resnet34_0.6316_epoch_0.pth', '3_SE-resnet34_0.6117_epoch_0.pth', \\\r\n","             '3_SE-resnet34_0.6850_epoch_6.pth', '4_SE-resnet34_0.5352_epoch_0.pth', '4_SE-resnet34_0.5420_epoch_7.pth', '4_SE-resnet34_0.5508_epoch_6.pth', '5_SE-resnet34_0.4120_epoch_0.pth']\r\n","model_1perfold_names=['1_SE-resnet34_0.6583_epoch_6.pth', '2_SE-resnet34_0.6222_epoch_1.pth', '3_SE-resnet34_0.6117_epoch_0.pth', '4_SE-resnet34_0.5352_epoch_0.pth', '5_SE-resnet34_0.4120_epoch_0.pth']\r\n","\r\n","model_paths=[]\r\n","for i in range(len(model_1perfold_names)):\r\n","  model_paths.append(model_path_front + model_1perfold_names[i])\r\n","best_models=[] \r\n","for i in range(len(model_paths)):\r\n","  temp_model=torch.load((model_paths[i]))\r\n","  best_models.append(temp_model)\r\n"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnqJb8kqDqM_","executionInfo":{"status":"ok","timestamp":1613585984313,"user_tz":-540,"elapsed":626,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}}},"source":["#test Dataset 정의\r\n","sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","test_dataset = DatasetMNIST(\"test_dirty_mnist/\", sample_submission)\r\n","batch_size = 128\r\n","test_data_loader = DataLoader(\r\n","    test_dataset,\r\n","    batch_size = batch_size,\r\n","    shuffle = False,\r\n","    num_workers = 3,\r\n","    drop_last = False\r\n",")"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9b80OZaDyAL","executionInfo":{"status":"ok","timestamp":1613586057194,"user_tz":-540,"elapsed":58627,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}}},"source":["predictions_list = []\r\n","# 배치 단위로 추론\r\n","prediction_df = pd.read_csv(\"sample_submission.csv\")\r\n","\r\n","# 5개의 fold마다 가장 좋은 모델을 이용하여 예측\r\n","for model in best_models:\r\n","    # 0으로 채워진 array 생성\r\n","    prediction_array = np.zeros([prediction_df.shape[0],\r\n","                                 prediction_df.shape[1] -1])\r\n","    for idx, sample in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            # 추론\r\n","            model.eval()\r\n","            images = sample['image']\r\n","            images = images.to(device)\r\n","            probs  = model(images)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = (probs > 0.5)\r\n","\r\n","            # 예측 결과를 \r\n","            # prediction_array에 입력\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0],:]\\\r\n","                         = preds.astype(int)\r\n","                         \r\n","    # 채널을 하나 추가하여 list에 append\r\n","    predictions_list.append(prediction_array[...,np.newaxis])"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q14pVyHnD0hY","executionInfo":{"status":"ok","timestamp":1613586065721,"user_tz":-540,"elapsed":638,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}},"outputId":"aa166b9f-181e-44c6-e249-b343fb957684"},"source":["# axis = 2를 기준으로 평균\r\n","predictions_array = np.concatenate(predictions_list, axis = 2)\r\n","predictions_mean = predictions_array.mean(axis = 2)\r\n","\r\n","# 평균 값이 0.5보다 클 경우 1 작으면 0\r\n","predictions_mean = (predictions_mean > 0.5) * 1\r\n","predictions_mean"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 1, ..., 1, 1, 1],\n","       [1, 1, 0, ..., 0, 0, 0],\n","       [1, 0, 1, ..., 0, 1, 1],\n","       ...,\n","       [0, 0, 1, ..., 1, 1, 1],\n","       [0, 1, 1, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 1, 0, 1]])"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"hukGtk06D2By","executionInfo":{"status":"ok","timestamp":1613586083047,"user_tz":-540,"elapsed":663,"user":{"displayName":"임승원","photoUrl":"","userId":"14071711355982969288"}},"outputId":"1a5aa628-fcd6-4426-de88-8e830f895597"},"source":["sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","sample_submission.iloc[:,1:] = predictions_mean\r\n","sample_submission.to_csv(\"/content/drive/MyDrive/Colab Notebooks/dacon/ensemble_prediction2.csv\", index = False)\r\n","sample_submission"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","      <th>f</th>\n","      <th>g</th>\n","      <th>h</th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>k</th>\n","      <th>l</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>o</th>\n","      <th>p</th>\n","      <th>q</th>\n","      <th>r</th>\n","      <th>s</th>\n","      <th>t</th>\n","      <th>u</th>\n","      <th>v</th>\n","      <th>w</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50001</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>50002</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50003</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50004</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>54995</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>54996</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>54997</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>54998</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>54999</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 27 columns</p>\n","</div>"],"text/plain":["      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n","0     50000  0  0  1  1  0  1  0  1  1  1  ...  1  0  1  0  1  0  1  0  1  1  1\n","1     50001  1  1  0  1  1  1  0  0  0  1  ...  1  0  1  0  0  0  1  0  0  0  0\n","2     50002  1  0  1  1  1  1  0  1  1  1  ...  1  0  1  0  0  1  1  1  0  1  1\n","3     50003  1  1  1  1  0  1  1  1  0  0  ...  1  1  1  0  1  0  0  1  0  0  0\n","4     50004  0  0  1  0  1  0  0  0  0  0  ...  1  0  0  1  1  1  0  0  0  0  0\n","...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n","4995  54995  1  0  1  1  0  1  0  1  0  0  ...  1  0  0  0  1  0  1  1  0  1  1\n","4996  54996  0  1  1  0  1  0  1  0  0  1  ...  0  0  0  1  1  1  1  0  0  0  0\n","4997  54997  0  0  1  0  0  1  0  1  0  1  ...  0  0  1  0  1  1  1  0  1  1  1\n","4998  54998  0  1  1  1  0  0  1  0  1  1  ...  0  0  0  0  0  0  0  1  0  0  0\n","4999  54999  0  0  0  0  0  0  0  1  1  0  ...  0  0  0  1  0  0  0  1  1  0  1\n","\n","[5000 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"hY6KwU_DMq18"},"source":[""],"execution_count":null,"outputs":[]}]}