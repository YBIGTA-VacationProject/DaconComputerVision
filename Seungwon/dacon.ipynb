{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dacon.ipynb","provenance":[],"collapsed_sections":["byckt4mfDb9Z"],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YeERJDh7eHdx","executionInfo":{"status":"ok","timestamp":1613749278527,"user_tz":-540,"elapsed":19490,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"b6e71cc3-38ca-44a1-8608-44190e3388b5"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4SzhHo9LeJ9Y","executionInfo":{"status":"ok","timestamp":1613749435828,"user_tz":-540,"elapsed":155348,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}}},"source":["from google.colab import output\r\n","# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\r\n","!cp \"/content/drive/MyDrive/data_2.zip\" \"data_2.zip\"\r\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"czO39sqLeKkv","executionInfo":{"status":"ok","timestamp":1613749545156,"user_tz":-540,"elapsed":264247,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"49eaf760-ce41-4ece-8a1a-d8cb9b7a0ba8"},"source":["# data_2.zip을 현재 디렉터리에 압축해제\r\n","!unzip \"data_2.zip\""],"execution_count":3,"outputs":[{"output_type":"stream","text":["Archive:  data_2.zip\n","  inflating: dirty_mnist_2nd.zip     \n","  inflating: dirty_mnist_2nd_answer.csv  \n","  inflating: mnist_data.zip          \n","  inflating: sample_submission.csv   \n","  inflating: test_dirty_mnist_2nd.zip  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ytSAiaxieLVu","executionInfo":{"status":"ok","timestamp":1613749648206,"user_tz":-540,"elapsed":366697,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}}},"source":["from google.colab import output\r\n","# 현재 디렉터리에 dirty_mnist라는 폴더 생성\r\n","!mkdir \"./dirty_mnist\"\r\n","#dirty_mnist.zip라는 zip파일을 dirty_mnist라는 폴더에 압축 풀기\r\n","!unzip \"dirty_mnist_2nd.zip\" -d \"./dirty_mnist/\"\r\n","# 현재 디렉터리에 test_dirty_mnist라는 폴더 생성\r\n","!mkdir \"./test_dirty_mnist\"\r\n","#test_dirty_mnist.zip라는 zip파일을 test_dirty_mnist라는 폴더에 압축 풀기\r\n","!unzip \"test_dirty_mnist_2nd.zip\" -d \"./test_dirty_mnist/\"\r\n","# 출력 결과 지우기\r\n","output.clear()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"zY1whAqydW0R","executionInfo":{"status":"ok","timestamp":1613750002216,"user_tz":-540,"elapsed":4360,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}}},"source":["import torch.nn as nn\r\n","\r\n","class SELayer(nn.Module):\r\n","    def __init__(self, channel, reduction=16):\r\n","        super(SELayer, self).__init__()\r\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\r\n","        self.fc = nn.Sequential(\r\n","            nn.Linear(channel, channel // reduction, bias=False),\r\n","            nn.ReLU(inplace=True),\r\n","            nn.Dropout(p=drop_prob),\r\n","            nn.Linear(channel // reduction, channel, bias=False),\r\n","            nn.Sigmoid()\r\n","        )\r\n","\r\n","    def forward(self, x):\r\n","        b, c, _, _ = x.size()\r\n","        y = self.avg_pool(x).view(b, c)\r\n","        y = self.fc(y).view(b, c, 1, 1)\r\n","        return x * y.expand_as(x)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"eeQnPvk1rwYb","executionInfo":{"status":"ok","timestamp":1613735626251,"user_tz":-540,"elapsed":412,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"37230dc3-a774-4c32-f5dc-412194adca20"},"source":["'''\r\n","import torch.hub\r\n","hub_model = torch.hub.load(\r\n","    'moskomule/senet.pytorch',\r\n","    'se_resnet50',\r\n","    pretrained=True,)\r\n","'''"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\nimport torch.hub\\nhub_model = torch.hub.load(\\n    'moskomule/senet.pytorch',\\n    'se_resnet50',\\n    pretrained=True,)\\n\""]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"s0b-JZFkeSnI","executionInfo":{"status":"ok","timestamp":1613750003178,"user_tz":-540,"elapsed":2118,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}}},"source":["\r\n","from torch.hub import load_state_dict_from_url\r\n","from torchvision.models import ResNet\r\n","\r\n","\r\n","def conv3x3(in_planes, out_planes, stride=1):\r\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\r\n","\r\n","\r\n","class SEBasicBlock(nn.Module):\r\n","    expansion = 1\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n","                 base_width=64, dilation=1, norm_layer=None,\r\n","                 *, reduction=16):\r\n","        super(SEBasicBlock, self).__init__()\r\n","        self.conv1 = conv3x3(inplanes, planes, stride)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.dropout1 = torch.nn.Dropout(p=drop_prob)\r\n","        self.conv2 = conv3x3(planes, planes, 1)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.se = SELayer(planes, reduction)\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = x\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","        out = self.dropout1(out)\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","        out = self.se(out)\r\n","\r\n","        if self.downsample is not None:\r\n","            residual = self.downsample(x)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","        return out\r\n","\r\n","\r\n","class SEBottleneck(nn.Module):\r\n","    expansion = 4\r\n","\r\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\r\n","                 base_width=64, dilation=1, norm_layer=None,\r\n","                 *, reduction=16):\r\n","        super(SEBottleneck, self).__init__()\r\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.dropout1 = torch.nn.Dropout(p=drop_prob)\r\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\r\n","                               padding=1, bias=False)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.dropout2 = torch.nn.Dropout(p=drop_prob)\r\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\r\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.se = SELayer(planes * 4, reduction)\r\n","        self.downsample = downsample\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = x\r\n","\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","        out = self.dropout1(out)\r\n","\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","        out = self.relu(out)\r\n","        out = self.dropout2(out)\r\n","\r\n","\r\n","        out = self.conv3(out)\r\n","        out = self.bn3(out)\r\n","        out = self.se(out)\r\n","\r\n","        if self.downsample is not None:\r\n","            residual = self.downsample(x)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","\r\n","        return out\r\n","\r\n","\r\n","def se_resnet18(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-18 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBasicBlock, [2, 2, 2, 2], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","\r\n","'''\r\n","def se_resnet34(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","'''\r\n","'''\r\n","def se_resnet50(num_classes=1_000, pretrained=False):\r\n","    \"\"\"Constructs a ResNet-50 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBottleneck, [3, 4, 6, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    if pretrained:\r\n","        model.load_state_dict(load_state_dict_from_url(\r\n","            \"https://github.com/moskomule/senet.pytorch/releases/download/archive/seresnet50-60a8950a85b2b.pkl\"))\r\n","    return model\r\n","'''\r\n","\r\n","def se_resnet101(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-101 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBottleneck, [3, 4, 23, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","\r\n","\r\n","def se_resnet152(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-152 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBottleneck, [3, 8, 36, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","\r\n","\r\n","class CifarSEBasicBlock(nn.Module):\r\n","    def __init__(self, inplanes, planes, stride=1, reduction=16):\r\n","        super(CifarSEBasicBlock, self).__init__()\r\n","        self.conv1 = conv3x3(inplanes, planes, stride)\r\n","        self.bn1 = nn.BatchNorm2d(planes)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.conv2 = conv3x3(planes, planes)\r\n","        self.bn2 = nn.BatchNorm2d(planes)\r\n","        self.se = SELayer(planes, reduction)\r\n","        if inplanes != planes:\r\n","            self.downsample = nn.Sequential(nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False),\r\n","                                            nn.BatchNorm2d(planes))\r\n","        else:\r\n","            self.downsample = lambda x: x\r\n","        self.stride = stride\r\n","\r\n","    def forward(self, x):\r\n","        residual = self.downsample(x)\r\n","        out = self.conv1(x)\r\n","        out = self.bn1(out)\r\n","        out = self.relu(out)\r\n","\r\n","        out = self.conv2(out)\r\n","        out = self.bn2(out)\r\n","        out = self.se(out)\r\n","\r\n","        out += residual\r\n","        out = self.relu(out)\r\n","\r\n","        return out\r\n","\r\n","\r\n","class CifarSEResNet(nn.Module):\r\n","    def __init__(self, block, n_size, num_classes=10, reduction=16):\r\n","        super(CifarSEResNet, self).__init__()\r\n","        self.inplane = 16\r\n","        self.conv1 = nn.Conv2d(\r\n","            3, self.inplane, kernel_size=3, stride=1, padding=1, bias=False)\r\n","        self.bn1 = nn.BatchNorm2d(self.inplane)\r\n","        self.relu = nn.ReLU(inplace=True)\r\n","        self.layer1 = self._make_layer(\r\n","            block, 16, blocks=n_size, stride=1, reduction=reduction)\r\n","        self.layer2 = self._make_layer(\r\n","            block, 32, blocks=n_size, stride=2, reduction=reduction)\r\n","        self.layer3 = self._make_layer(\r\n","            block, 64, blocks=n_size, stride=2, reduction=reduction)\r\n","        self.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","        self.fc = nn.Linear(64, num_classes)\r\n","        self.initialize()\r\n","\r\n","    def initialize(self):\r\n","        for m in self.modules():\r\n","            if isinstance(m, nn.Conv2d):\r\n","                nn.init.kaiming_normal_(m.weight)\r\n","            elif isinstance(m, nn.BatchNorm2d):\r\n","                nn.init.constant_(m.weight, 1)\r\n","                nn.init.constant_(m.bias, 0)\r\n","\r\n","    def _make_layer(self, block, planes, blocks, stride, reduction):\r\n","        strides = [stride] + [1] * (blocks - 1)\r\n","        layers = []\r\n","        for stride in strides:\r\n","            layers.append(block(self.inplane, planes, stride, reduction))\r\n","            self.inplane = planes\r\n","\r\n","        return nn.Sequential(*layers)\r\n","\r\n","    def forward(self, x):\r\n","        x = self.conv1(x)\r\n","        x = self.bn1(x)\r\n","        x = self.relu(x)\r\n","\r\n","        x = self.layer1(x)\r\n","        x = self.layer2(x)\r\n","        x = self.layer3(x)\r\n","\r\n","        x = self.avgpool(x)\r\n","        x = x.view(x.size(0), -1)\r\n","        x = self.fc(x)\r\n","\r\n","        return x\r\n","\r\n","\r\n","class CifarSEPreActResNet(CifarSEResNet):\r\n","    def __init__(self, block, n_size, num_classes=10, reduction=16):\r\n","        super(CifarSEPreActResNet, self).__init__(\r\n","            block, n_size, num_classes, reduction)\r\n","        self.bn1 = nn.BatchNorm2d(self.inplane)\r\n","        self.initialize()\r\n","\r\n","    def forward(self, x):\r\n","        x = self.conv1(x)\r\n","        x = self.layer1(x)\r\n","        x = self.layer2(x)\r\n","        x = self.layer3(x)\r\n","\r\n","        x = self.bn1(x)\r\n","        x = self.relu(x)\r\n","\r\n","        x = self.avgpool(x)\r\n","        x = x.view(x.size(0), -1)\r\n","        x = self.fc(x)\r\n","\r\n","\r\n","def se_resnet20(**kwargs):\r\n","    \"\"\"Constructs a ResNet-18 model.\r\n","    \"\"\"\r\n","    model = CifarSEResNet(CifarSEBasicBlock, 3, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_resnet32(**kwargs):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    \"\"\"\r\n","    model = CifarSEResNet(CifarSEBasicBlock, 5, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_resnet56(**kwargs):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    \"\"\"\r\n","    model = CifarSEResNet(CifarSEBasicBlock, 9, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_preactresnet20(**kwargs):\r\n","    \"\"\"Constructs a ResNet-18 model.\r\n","    \"\"\"\r\n","    model = CifarSEPreActResNet(CifarSEBasicBlock, 3, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_preactresnet32(**kwargs):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    \"\"\"\r\n","    model = CifarSEPreActResNet(CifarSEBasicBlock, 5, **kwargs)\r\n","    return model\r\n","\r\n","\r\n","def se_preactresnet56(**kwargs):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    \"\"\"\r\n","    model = CifarSEPreActResNet(CifarSEBasicBlock, 9, **kwargs)\r\n","    return model\r\n","\r\n","\r\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"vH3QdHfxeZnd","executionInfo":{"status":"ok","timestamp":1613750006670,"user_tz":-540,"elapsed":1636,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}}},"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import cv2\r\n","from tqdm import tqdm\r\n","import imutils\r\n","import zipfile\r\n","import os\r\n","from PIL import Image\r\n","from torchsummary import summary\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torchvision.models as models\r\n","import torchvision.transforms as T\r\n","from torch.utils.data import DataLoader, Dataset\r\n","from google.colab import output\r\n","\r\n","from torch.hub import load_state_dict_from_url\r\n","from torchvision.models import ResNet\r\n","\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 디바이스 설정\r\n","learning_rate = 0.001\r\n","training_epochs = 15\r\n","batch_size = 100\r\n","drop_prob = 0.3"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Ihlr-kBeaj2","executionInfo":{"status":"ok","timestamp":1613750009634,"user_tz":-540,"elapsed":1022,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}}},"source":["dirty_mnist_answer = pd.read_csv(\"/content/dirty_mnist_2nd_answer.csv\")\r\n","# dirty_mnist라는 디렉터리 속에 들어있는 파일들의 이름을 \r\n","# namelist라는 변수에 저장\r\n","namelist = os.listdir('./dirty_mnist/')\r\n","\r\n","# unmpy를 tensor로 변환하는 ToTensor 정의\r\n","class ToTensor(object):\r\n","    \"\"\"numpy array를 tensor(torch)로 변환합니다.\"\"\"\r\n","    def __call__(self, sample):\r\n","        image, label = sample['image'], sample['label']\r\n","        # swap color axis because\r\n","        # numpy image: H x W x C\r\n","        # torch image: C X H X W\r\n","        image = image.transpose((2, 0, 1))\r\n","        return {'image': torch.FloatTensor(image),\r\n","                'label': torch.FloatTensor(label)}\r\n","# to_tensor 선언\r\n","to_tensor = T.Compose([\r\n","                      ToTensor()\r\n","                    ])\r\n","\r\n","class DatasetMNIST(torch.utils.data.Dataset):\r\n","    def __init__(self,\r\n","                 dir_path,\r\n","                 meta_df,\r\n","                 transforms=to_tensor,#미리 선언한 to_tensor를 transforms로 받음\r\n","                 augmentations=None):\r\n","        \r\n","        self.dir_path = dir_path # 데이터의 이미지가 저장된 디렉터리 경로\r\n","        self.meta_df = meta_df # 데이터의 인덱스와 정답지가 들어있는 DataFrame\r\n","\r\n","        self.transforms = transforms# Transform\r\n","        self.augmentations = augmentations # Augmentation\r\n","        \r\n","    def __len__(self):\r\n","        return len(self.meta_df)\r\n","    \r\n","    def __getitem__(self, index):\r\n","        # 폴더 경로 + 이미지 이름 + .png => 파일의 경로\r\n","        # 참고) \"12\".zfill(5) => 000012\r\n","        #       \"146\".zfill(5) => 000145\r\n","        # cv2.IMREAD_GRAYSCALE : png파일을 채널이 1개인 GRAYSCALE로 읽음\r\n","        image = cv2.imread(self.dir_path +\\\r\n","                           str(self.meta_df.iloc[index,0]).zfill(5) + '.png',\r\n","                           cv2.IMREAD_GRAYSCALE)\r\n","        # 0 ~ 255의 값을 갖고 크기가 (256,256)인 numpy array를\r\n","        # 0 ~ 1 사이의 실수를 갖고 크기가 (256,256,1)인 numpy array로 변환\r\n","        image = (image/255).astype('float')[..., np.newaxis]\r\n","        # 정답 numpy array생성(존재하면 1 없으면 0)\r\n","        label = self.meta_df.iloc[index, 1:].values.astype('float')\r\n","        sample = {'image': image, 'label': label}\r\n","        # transform 적용\r\n","        # numpy to tensor\r\n","        if self.transforms:\r\n","            sample = self.transforms(sample)\r\n","\r\n","        # sample 반환\r\n","        return sample"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I074H89JecWS","executionInfo":{"status":"ok","timestamp":1613750028511,"user_tz":-540,"elapsed":11167,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"49bb0f9a-f032-41bc-b8a1-4e5639e281ff"},"source":["def se_resnet34(num_classes=1_000):\r\n","    \"\"\"Constructs a ResNet-34 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBasicBlock, [3, 4, 6, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","    return model\r\n","\r\n","class my_resnet_34(nn.Module):\r\n","    def __init__(self):\r\n","        super(my_resnet_34, self).__init__()\r\n","        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\r\n","        self.se_resnet34 =se_resnet34()\r\n","        self.FC = nn.Linear(1000, 26)\r\n","\r\n","    def forward(self, x):\r\n","        # resnet의 입력은 [3, N, N]으로\r\n","        # 3개의 채널을 갖기 때문에\r\n","        # resnet 입력 전에 conv2d를 한 층 추가\r\n","        x = F.relu(self.conv2d(x))\r\n","\r\n","        # resnet18을 추가\r\n","        x = F.relu(self.se_resnet34(x))\r\n","\r\n","        # 마지막 출력에 nn.Linear를 추가\r\n","        # multilabel을 예측해야 하기 때문에\r\n","        # softmax가 아닌 sigmoid를 적용\r\n","        x = torch.sigmoid(self.FC(x))\r\n","        return x\r\n","\r\n","'''\r\n","def se_resnet50(num_classes=1_000, pretrained=False):\r\n","    \"\"\"Constructs a ResNet-50 model.\r\n","    Args:\r\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\r\n","    \"\"\"\r\n","    model = ResNet(SEBottleneck, [3, 4, 6, 3], num_classes=num_classes)\r\n","    model.avgpool = nn.AdaptiveAvgPool2d(1)\r\n","   \r\n","    return model\r\n","\r\n","class my_resnet_50(nn.Module):\r\n","    def __init__(self):\r\n","        super(my_resnet_50, self).__init__()\r\n","        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\r\n","        self.se_resnet50 =se_resnet50()\r\n","        self.FC = nn.Linear(1000, 26)\r\n","\r\n","    def forward(self, x):\r\n","        # resnet의 입력은 [3, N, N]으로\r\n","        # 3개의 채널을 갖기 때문에\r\n","        # resnet 입력 전에 conv2d를 한 층 추가\r\n","        x = F.relu(self.conv2d(x))\r\n","\r\n","        # resnet18을 추가\r\n","        x = F.relu(self.se_resnet50(x))\r\n","\r\n","        # 마지막 출력에 nn.Linear를 추가\r\n","        # multilabel을 예측해야 하기 때문에\r\n","        # softmax가 아닌 sigmoid를 적용\r\n","        x = torch.sigmoid(self.FC(x))\r\n","        return x\r\n","    '''\r\n","# 모델 선언\r\n","hub_model = my_resnet_34()\r\n","hub_model.to(device)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["my_resnet_34(\n","  (conv2d): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n","  (se_resnet34): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=4, out_features=64, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=4, out_features=64, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=4, out_features=64, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=8, out_features=128, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=8, out_features=128, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=8, out_features=128, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","      (3): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=8, out_features=128, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=16, out_features=256, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=16, out_features=256, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=16, out_features=256, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","      (3): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=16, out_features=256, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","      (4): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=16, out_features=256, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","      (5): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=16, out_features=256, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=32, out_features=512, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=32, out_features=512, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (dropout1): Dropout(p=0.3, inplace=False)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Dropout(p=0.3, inplace=False)\n","            (3): Linear(in_features=32, out_features=512, bias=False)\n","            (4): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=1)\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (FC): Linear(in_features=1000, out_features=26, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"id":"h15uJmGyedOj","executionInfo":{"status":"error","timestamp":1613736525897,"user_tz":-540,"elapsed":603,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"2167d91b-c60c-4e76-d0bf-ddc738e614b3"},"source":["summary(hub_model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-3f5e2fa10c6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-ed34a3c6fa78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# 3개의 채널을 갖기 때문에\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# resnet 입력 전에 conv2d를 한 층 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# resnet18을 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.76 GiB total capacity; 13.82 GiB already allocated; 3.75 MiB free; 13.83 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"MRzNcwB_shTg"},"source":["#weights,biases = hub_model.layers[0].get_weights()\r\n","torch.cuda.empty_cache()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pH4URwebeeX0","executionInfo":{"status":"ok","timestamp":1613760204871,"user_tz":-540,"elapsed":10171007,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"ae54fd24-ec27-4617-f66c-f5017564c5de"},"source":["# cross validation을 적용하기 위해 KFold 생성\r\n","from sklearn.model_selection import KFold\r\n","def fit(learning_rate=0.001, epochs=10, train_batch_size=128, test_batch_size=32, drop_prob=0.3):\r\n","  kfold = KFold(n_splits=5, shuffle=True, random_state=0)\r\n","\r\n","  # dirty_mnist_answer에서 train_idx와 val_idx를 생성\r\n","  best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\r\n","  for fold_index, (trn_idx, val_idx) in enumerate(kfold.split(dirty_mnist_answer),1):\r\n","      print(f'[fold: {fold_index}]')\r\n","      # cuda cache 초기화\r\n","      torch.cuda.empty_cache()\r\n","\r\n","      #train fold, validation fold 분할\r\n","      train_answer = dirty_mnist_answer.iloc[trn_idx]\r\n","      test_answer  = dirty_mnist_answer.iloc[val_idx]\r\n","\r\n","      #Dataset 정의\r\n","      train_dataset = DatasetMNIST(\"dirty_mnist/\", train_answer)\r\n","      valid_dataset = DatasetMNIST(\"dirty_mnist/\", test_answer)\r\n","    \r\n","      #DataLoader 정의\r\n","      train_data_loader = DataLoader(\r\n","          train_dataset,\r\n","          batch_size = train_batch_size,\r\n","          shuffle = False,\r\n","          num_workers = 3,\r\n","          drop_last=True\r\n","      )\r\n","      valid_data_loader = DataLoader(\r\n","          valid_dataset,\r\n","          batch_size = test_batch_size,\r\n","          shuffle = False,\r\n","          num_workers = 3,\r\n","          drop_last=True\r\n","      )\r\n","      # 모델 선언\r\n","      #model = MultiLabelResnet()\r\n","      #model=torch.load(('/content/drive/MyDrive/Colab Notebooks/dacon/models/5_resnet18_0.8095_epoch_0.pth'))\r\n","\r\n","      #model.to(device)# gpu에 모델 할당\r\n","\r\n","      # 훈련 옵션 설정\r\n","      optimizer = torch.optim.Adam(hub_model.parameters(),\r\n","                                  lr = learning_rate)\r\n","      lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\r\n","                                                  step_size = 5,\r\n","                                                  gamma = 0.75)\r\n","      criterion = torch.nn.BCELoss()\r\n","      \r\n","      # 훈련 시작\r\n","      valid_acc_max = 0\r\n","      for epoch in range(epochs):\r\n","          \r\n","          # 1개 epoch 훈련\r\n","          train_acc_list = []\r\n","          with tqdm(train_data_loader,#train_data_loader를 iterative하게 반환\r\n","                  total=train_data_loader.__len__(), # train_data_loader의 크기\r\n","                  unit=\"batch\") as train_bar:# 한번 반환하는 smaple의 단위는 \"batch\"\r\n","\r\n","                  for sample in train_bar:\r\n","                    train_bar.set_description(f\"Train Epoch {epoch}\")\r\n","                    # 갱신할 변수들에 대한 모든 변화도를 0으로 초기화\r\n","                    # 참고)https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html\r\n","                    optimizer.zero_grad()\r\n","                    images, labels = sample['image'], sample['label']\r\n","\r\n","                    # tensor를 gpu에 올리기 \r\n","                    images = images.to(device)\r\n","                    labels = labels.to(device)\r\n","                  \r\n","                    # 모델의 dropoupt, batchnormalization를 train 모드로 설정\r\n","                    hub_model.train()\r\n","                    # .forward()에서 중간 노드의 gradient를 계산\r\n","                    with torch.set_grad_enabled(True):\r\n","                        # 모델 예측\r\n","                        probs  = hub_model(images)\r\n","                        # loss 계산\r\n","                        loss = criterion(probs, labels)\r\n","                        # 중간 노드의 gradient로\r\n","                        # backpropagation을 적용하여\r\n","                        # gradient 계산\r\n","                        loss.backward()\r\n","                        # weight 갱신\r\n","                        optimizer.step()\r\n","\r\n","                        # train accuracy 계산\r\n","                        probs  = probs.cpu().detach().numpy()\r\n","                        labels = labels.cpu().detach().numpy()\r\n","                        preds = probs > 0.5\r\n","                        batch_acc = (labels == preds).mean()\r\n","                        train_acc_list.append(batch_acc)\r\n","                        train_acc = np.mean(train_acc_list)\r\n","\r\n","                    # 현재 progress bar에 현재 미니배치의 loss 결과 출력\r\n","                    train_bar.set_postfix(train_loss= loss.item(),\r\n","                                          train_acc = train_acc)\r\n","          # 1개 epoch학습 후 Validation 점수 계산\r\n","          valid_acc_list = []\r\n","          with tqdm(valid_data_loader,\r\n","                  total=valid_data_loader.__len__(),\r\n","                  unit=\"batch\") as valid_bar:\r\n","              for sample in valid_bar:\r\n","\r\n","                valid_bar.set_description(f\"Valid Epoch {epoch}\")\r\n","                optimizer.zero_grad()\r\n","                images, labels = sample['image'], sample['label']\r\n","                images = images.to(device)\r\n","                labels = labels.to(device)\r\n","                \r\n","                # 모델의 dropoupt, batchnormalization를 eval모드로 설정\r\n","                hub_model.eval()\r\n","                # .forward()에서 중간 노드의 gradient를 계산\r\n","                with torch.no_grad():\r\n","\r\n","                  # validation loss만을 계산\r\n","                  probs  = hub_model(images)\r\n","                  valid_loss = criterion(probs, labels)\r\n","\r\n","                  # train accuracy 계산\r\n","                  probs  = probs.cpu().detach().numpy()\r\n","                  labels = labels.cpu().detach().numpy()\r\n","                  preds = probs > 0.5\r\n","                  batch_acc = (labels == preds).mean()\r\n","                  valid_acc_list.append(batch_acc)\r\n","\r\n","                valid_acc = np.mean(valid_acc_list)\r\n","                valid_bar.set_postfix(valid_loss = valid_loss.item(),\r\n","                                        valid_acc = valid_acc)\r\n","                      \r\n","          # Learning rate 조절\r\n","          lr_scheduler.step()\r\n","\r\n","          # 모델 저장\r\n","          if valid_acc_max < valid_acc:\r\n","              valid_acc_max = valid_acc\r\n","              best_model = hub_model\r\n","              MODEL = \"SE-resnet34\"\r\n","              # 모델을 저장할 구글 드라이브 경로\r\n","              path = \"/content/drive/MyDrive/Colab Notebooks/dacon/models3/\"\r\n","              torch.save(best_model, f'{path}{fold_index}_{MODEL}_{valid_loss.item():2.4f}_epoch_{epoch}.pth')\r\n","      \r\n","      # 폴드별로 가장 좋은 모델 저장\r\n","      best_models.append(best_model)\r\n","\r\n","\r\n","fit()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\r  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 1]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.541, train_loss=0.687]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:24<00:00, 12.76batch/s, valid_acc=0.537, valid_loss=0.688]\n","Train Epoch 1: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.549, train_loss=0.681]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:23<00:00, 13.17batch/s, valid_acc=0.55, valid_loss=0.685]\n","Train Epoch 2: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.562, train_loss=0.674]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:23<00:00, 13.13batch/s, valid_acc=0.542, valid_loss=0.673]\n","Train Epoch 3: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.57, train_loss=0.668]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:23<00:00, 13.00batch/s, valid_acc=0.559, valid_loss=0.665]\n","Train Epoch 4: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.579, train_loss=0.66]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:23<00:00, 13.01batch/s, valid_acc=0.553, valid_loss=0.672]\n","Train Epoch 5: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.588, train_loss=0.654]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:23<00:00, 13.03batch/s, valid_acc=0.565, valid_loss=0.676]\n","Train Epoch 6: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.597, train_loss=0.646]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:23<00:00, 13.07batch/s, valid_acc=0.583, valid_loss=0.66]\n","Train Epoch 7: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.607, train_loss=0.64]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:23<00:00, 13.16batch/s, valid_acc=0.598, valid_loss=0.652]\n","Train Epoch 8: 100%|██████████| 312/312 [02:58<00:00,  1.75batch/s, train_acc=0.614, train_loss=0.634]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:23<00:00, 13.05batch/s, valid_acc=0.579, valid_loss=0.673]\n","Train Epoch 9: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.623, train_loss=0.621]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:23<00:00, 13.08batch/s, valid_acc=0.614, valid_loss=0.629]\n","  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 2]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.627, train_loss=0.621]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:24<00:00, 12.95batch/s, valid_acc=0.63, valid_loss=0.625]\n","Train Epoch 1: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.636, train_loss=0.61]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:24<00:00, 12.95batch/s, valid_acc=0.631, valid_loss=0.625]\n","Train Epoch 2: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.641, train_loss=0.607]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:24<00:00, 12.92batch/s, valid_acc=0.633, valid_loss=0.629]\n","Train Epoch 3: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.647, train_loss=0.6]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:24<00:00, 12.91batch/s, valid_acc=0.634, valid_loss=0.629]\n","Train Epoch 4: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.654, train_loss=0.594]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:24<00:00, 12.90batch/s, valid_acc=0.627, valid_loss=0.651]\n","Train Epoch 5: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.664, train_loss=0.575]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:24<00:00, 12.88batch/s, valid_acc=0.641, valid_loss=0.634]\n","Train Epoch 6: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.671, train_loss=0.577]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:24<00:00, 12.88batch/s, valid_acc=0.637, valid_loss=0.661]\n","Train Epoch 7: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.678, train_loss=0.56]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:24<00:00, 12.93batch/s, valid_acc=0.65, valid_loss=0.639]\n","Train Epoch 8: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.684, train_loss=0.549]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:24<00:00, 12.91batch/s, valid_acc=0.648, valid_loss=0.643]\n","Train Epoch 9: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.689, train_loss=0.545]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:24<00:00, 12.75batch/s, valid_acc=0.648, valid_loss=0.649]\n","  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 3]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.683, train_loss=0.559]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:24<00:00, 12.97batch/s, valid_acc=0.679, valid_loss=0.571]\n","Train Epoch 1: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.69, train_loss=0.547]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:23<00:00, 13.07batch/s, valid_acc=0.681, valid_loss=0.585]\n","Train Epoch 2: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.696, train_loss=0.542]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:23<00:00, 13.07batch/s, valid_acc=0.685, valid_loss=0.569]\n","Train Epoch 3: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.701, train_loss=0.532]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:24<00:00, 13.00batch/s, valid_acc=0.662, valid_loss=0.622]\n","Train Epoch 4: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.706, train_loss=0.525]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:23<00:00, 13.11batch/s, valid_acc=0.686, valid_loss=0.572]\n","Train Epoch 5: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.715, train_loss=0.503]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:24<00:00, 12.96batch/s, valid_acc=0.691, valid_loss=0.584]\n","Train Epoch 6: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.721, train_loss=0.497]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:23<00:00, 13.01batch/s, valid_acc=0.684, valid_loss=0.584]\n","Train Epoch 7: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.726, train_loss=0.497]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:23<00:00, 13.02batch/s, valid_acc=0.689, valid_loss=0.599]\n","Train Epoch 8: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.731, train_loss=0.475]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:23<00:00, 13.05batch/s, valid_acc=0.687, valid_loss=0.594]\n","Train Epoch 9: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.736, train_loss=0.467]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:23<00:00, 13.15batch/s, valid_acc=0.691, valid_loss=0.636]\n","  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 4]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.724, train_loss=0.512]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:24<00:00, 12.94batch/s, valid_acc=0.742, valid_loss=0.467]\n","Train Epoch 1: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.73, train_loss=0.506]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:24<00:00, 12.97batch/s, valid_acc=0.739, valid_loss=0.478]\n","Train Epoch 2: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.735, train_loss=0.496]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:24<00:00, 12.91batch/s, valid_acc=0.736, valid_loss=0.469]\n","Train Epoch 3: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.74, train_loss=0.475]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:24<00:00, 12.91batch/s, valid_acc=0.727, valid_loss=0.491]\n","Train Epoch 4: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.743, train_loss=0.471]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:24<00:00, 12.98batch/s, valid_acc=0.728, valid_loss=0.49]\n","Train Epoch 5: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.75, train_loss=0.464]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:24<00:00, 12.84batch/s, valid_acc=0.727, valid_loss=0.504]\n","Train Epoch 6: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.754, train_loss=0.443]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:24<00:00, 12.89batch/s, valid_acc=0.728, valid_loss=0.513]\n","Train Epoch 7: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.757, train_loss=0.446]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:24<00:00, 12.82batch/s, valid_acc=0.727, valid_loss=0.515]\n","Train Epoch 8: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.76, train_loss=0.438]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:24<00:00, 12.79batch/s, valid_acc=0.726, valid_loss=0.527]\n","Train Epoch 9: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.762, train_loss=0.43]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:24<00:00, 12.85batch/s, valid_acc=0.723, valid_loss=0.534]\n","  0%|          | 0/312 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["[fold: 5]\n"],"name":"stdout"},{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.748, train_loss=0.48]\n","Valid Epoch 0: 100%|██████████| 312/312 [00:23<00:00, 13.08batch/s, valid_acc=0.766, valid_loss=0.418]\n","Train Epoch 1: 100%|██████████| 312/312 [02:58<00:00,  1.74batch/s, train_acc=0.754, train_loss=0.456]\n","Valid Epoch 1: 100%|██████████| 312/312 [00:23<00:00, 13.04batch/s, valid_acc=0.764, valid_loss=0.425]\n","Train Epoch 2: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.757, train_loss=0.453]\n","Valid Epoch 2: 100%|██████████| 312/312 [00:24<00:00, 12.94batch/s, valid_acc=0.766, valid_loss=0.42]\n","Train Epoch 3: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.76, train_loss=0.431]\n","Valid Epoch 3: 100%|██████████| 312/312 [00:24<00:00, 12.99batch/s, valid_acc=0.756, valid_loss=0.44]\n","Train Epoch 4: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.762, train_loss=0.429]\n","Valid Epoch 4: 100%|██████████| 312/312 [00:24<00:00, 12.90batch/s, valid_acc=0.755, valid_loss=0.434]\n","Train Epoch 5: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.767, train_loss=0.42]\n","Valid Epoch 5: 100%|██████████| 312/312 [00:23<00:00, 13.08batch/s, valid_acc=0.761, valid_loss=0.433]\n","Train Epoch 6: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.77, train_loss=0.417]\n","Valid Epoch 6: 100%|██████████| 312/312 [00:24<00:00, 13.00batch/s, valid_acc=0.754, valid_loss=0.451]\n","Train Epoch 7: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.772, train_loss=0.4]\n","Valid Epoch 7: 100%|██████████| 312/312 [00:24<00:00, 12.99batch/s, valid_acc=0.755, valid_loss=0.458]\n","Train Epoch 8: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.774, train_loss=0.402]\n","Valid Epoch 8: 100%|██████████| 312/312 [00:24<00:00, 12.96batch/s, valid_acc=0.76, valid_loss=0.431]\n","Train Epoch 9: 100%|██████████| 312/312 [02:59<00:00,  1.74batch/s, train_acc=0.775, train_loss=0.399]\n","Valid Epoch 9: 100%|██████████| 312/312 [00:24<00:00, 12.89batch/s, valid_acc=0.755, valid_loss=0.441]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"byckt4mfDb9Z"},"source":["# SaveModel 하나 불러오기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oRiBcxctefv3","executionInfo":{"elapsed":2040,"status":"ok","timestamp":1613578000469,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"},"user_tz":-540},"outputId":"e90daacc-d7eb-45e7-c164-9c7323990aa3"},"source":["savemodel=torch.load(('/content/drive/MyDrive/Colab Notebooks/dacon/models2/5_SE-resnet34_0.4120_epoch_0.pth'))\r\n","savemodel"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["my_resnet_34(\n","  (conv2d): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1))\n","  (se_resnet34): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=4, out_features=64, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=4, out_features=64, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=64, out_features=4, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=4, out_features=64, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (3): SEBasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=128, out_features=8, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=8, out_features=128, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (3): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (4): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (5): SEBasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=256, out_features=16, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=16, out_features=256, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): SEBasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=32, out_features=512, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): SEBasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=32, out_features=512, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","      (2): SEBasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (se): SELayer(\n","          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n","          (fc): Sequential(\n","            (0): Linear(in_features=512, out_features=32, bias=False)\n","            (1): ReLU(inplace=True)\n","            (2): Linear(in_features=32, out_features=512, bias=False)\n","            (3): Sigmoid()\n","          )\n","        )\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=1)\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (FC): Linear(in_features=1000, out_features=26, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"_tUnHr6YvlAH"},"source":["#test Dataset 정의\r\n","sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","test_dataset = DatasetMNIST(\"test_dirty_mnist/\", sample_submission)\r\n","batch_size = 128\r\n","test_data_loader = DataLoader(\r\n","    test_dataset,\r\n","    batch_size = batch_size,\r\n","    shuffle = False,\r\n","    num_workers = 3,\r\n","    drop_last = False\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-s0YmIylwSOG"},"source":["predictions_list = []\r\n","# 배치 단위로 추론\r\n","prediction_df = pd.read_csv(\"sample_submission.csv\")\r\n","\r\n","# 5개의 fold마다 가장 좋은 모델을 이용하여 예측\r\n","\r\n","# 0으로 채워진 array 생성\r\n","prediction_array = np.zeros([prediction_df.shape[0],\r\n","                             prediction_df.shape[1] -1])\r\n","for idx, sample in enumerate(test_data_loader):\r\n","    with torch.no_grad():\r\n","       # 추론\r\n","        hub_model.eval()\r\n","        images = sample['image']\r\n","        images = images.to(device)\r\n","        probs  = hub_model(images)\r\n","        probs = probs.cpu().detach().numpy()\r\n","        preds = (probs > 0.5)\r\n","\r\n","        # 예측 결과를 \r\n","        # prediction_array에 입력\r\n","        batch_index = batch_size * idx\r\n","        prediction_array[batch_index: batch_index + images.shape[0],:]\\\r\n","                     = preds.astype(int)\r\n","                         \r\n","# 채널을 하나 추가하여 list에 append\r\n","predictions_list.append(prediction_array[...,np.newaxis])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"jEkqauLKwx6B","executionInfo":{"elapsed":626,"status":"ok","timestamp":1613580035788,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"},"user_tz":-540},"outputId":"9b3f24bf-15b6-4381-fd11-44fbcc396e8a"},"source":["answer=predictions_list[0]\r\n","answer=answer.astype('int64')\r\n","answer.shape\r\n","answer=np.squeeze(answer, 2)\r\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 0, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 0, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 0, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 1, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 1, 1])"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["array([1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n","       0, 1, 0, 1])"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"EW3UEy9txNfR","executionInfo":{"elapsed":643,"status":"ok","timestamp":1613580327422,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"},"user_tz":-540},"outputId":"62a0bc7d-5e84-4236-c0d8-01f7b1d9dbc4"},"source":["sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","sample_submission.iloc[:,1:] = answer\r\n","sample_submission.to_csv(\"/content/drive/MyDrive/Colab Notebooks/se_resnet34_prediction.csv\", index = False)\r\n","sample_submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","      <th>f</th>\n","      <th>g</th>\n","      <th>h</th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>k</th>\n","      <th>l</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>o</th>\n","      <th>p</th>\n","      <th>q</th>\n","      <th>r</th>\n","      <th>s</th>\n","      <th>t</th>\n","      <th>u</th>\n","      <th>v</th>\n","      <th>w</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50001</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>50002</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50003</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50004</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>54995</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>54996</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>54997</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>54998</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>54999</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 27 columns</p>\n","</div>"],"text/plain":["      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n","0     50000  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","1     50001  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","2     50002  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","3     50003  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  1  1\n","4     50004  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  1  1\n","...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n","4995  54995  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","4996  54996  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","4997  54997  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  1  1\n","4998  54998  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  0  1\n","4999  54999  1  0  0  1  1  0  0  1  0  0  ...  1  1  0  0  0  1  1  0  1  1  1\n","\n","[5000 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":73}]},{"cell_type":"markdown","metadata":{"id":"7rX_u9KaDt5T"},"source":["# 모델 다 불러와서 Ensemble"]},{"cell_type":"code","metadata":{"id":"em87pHWeGBmK","executionInfo":{"status":"ok","timestamp":1613760671379,"user_tz":-540,"elapsed":7511,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}}},"source":["'''\r\n","model_path_front='/content/drive/MyDrive/Colab Notebooks/dacon/models2/'\r\n","model_names=['1_SE-resnet34_0.6583_epoch_6.pth', '1_SE-resnet34_0.6610_epoch_3.pth', '1_SE-resnet34_0.6799_epoch_1.pth', '1_SE-resnet34_0.6967_epoch_2.pth', \\\r\n","             '1_SE-resnet34_0.7262_epoch_0.pth', '2_SE-resnet34_0.6222_epoch_1.pth', '2_SE-resnet34_0.6316_epoch_0.pth', '3_SE-resnet34_0.6117_epoch_0.pth', \\\r\n","             '3_SE-resnet34_0.6850_epoch_6.pth', '4_SE-resnet34_0.5352_epoch_0.pth', '4_SE-resnet34_0.5420_epoch_7.pth', '4_SE-resnet34_0.5508_epoch_6.pth', '5_SE-resnet34_0.4120_epoch_0.pth']\r\n","model_1perfold_names=['1_SE-resnet34_0.6583_epoch_6.pth', '2_SE-resnet34_0.6222_epoch_1.pth', '3_SE-resnet34_0.6117_epoch_0.pth', '4_SE-resnet34_0.5352_epoch_0.pth', '5_SE-resnet34_0.4120_epoch_0.pth']\r\n","'''\r\n","model_path_front='/content/drive/MyDrive/Colab Notebooks/dacon/models3/'\r\n","model_names=['5_SE-resnet34_0.4181_epoch_0.pth', '4_SE-resnet34_0.4666_epoch_0.pth', '3_SE-resnet34_0.5853_epoch_1.pth', '3_SE-resnet34_0.5842_epoch_5.pth', \\\r\n","             '3_SE-resnet34_0.5724_epoch_4.pth', '3_SE-resnet34_0.5709_epoch_0.pth', '3_SE-resnet34_0.5689_epoch_2.pth', '2_SE-resnet34_0.6394_epoch_7.pth', \\\r\n","             '2_SE-resnet34_0.6335_epoch_5.pth', '2_SE-resnet34_0.6292_epoch_2.pth', '2_SE-resnet34_0.6287_epoch_3.pth', '1_SE-resnet34_0.6288_epoch_9.pth']\r\n","\r\n","model_paths=[]\r\n","for i in range(len(model_names)):\r\n","  model_paths.append(model_path_front + model_names[i])\r\n","best_models=[] \r\n","for i in range(len(model_paths)):\r\n","  temp_model=torch.load((model_paths[i]))\r\n","  best_models.append(temp_model)\r\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"VnqJb8kqDqM_","executionInfo":{"status":"ok","timestamp":1613760677442,"user_tz":-540,"elapsed":739,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}}},"source":["#test Dataset 정의\r\n","sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","test_dataset = DatasetMNIST(\"test_dirty_mnist/\", sample_submission)\r\n","batch_size = 128\r\n","test_data_loader = DataLoader(\r\n","    test_dataset,\r\n","    batch_size = batch_size,\r\n","    shuffle = False,\r\n","    num_workers = 3,\r\n","    drop_last = False\r\n",")"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9b80OZaDyAL","executionInfo":{"status":"ok","timestamp":1613760793471,"user_tz":-540,"elapsed":113385,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}}},"source":["predictions_list = []\r\n","# 배치 단위로 추론\r\n","prediction_df = pd.read_csv(\"sample_submission.csv\")\r\n","\r\n","# 5개의 fold마다 가장 좋은 모델을 이용하여 예측\r\n","for model in best_models:\r\n","    # 0으로 채워진 array 생성\r\n","    prediction_array = np.zeros([prediction_df.shape[0],\r\n","                                 prediction_df.shape[1] -1])\r\n","    for idx, sample in enumerate(test_data_loader):\r\n","        with torch.no_grad():\r\n","            # 추론\r\n","            model.eval()\r\n","            images = sample['image']\r\n","            images = images.to(device)\r\n","            probs  = model(images)\r\n","            probs = probs.cpu().detach().numpy()\r\n","            preds = (probs > 0.5)\r\n","\r\n","            # 예측 결과를 \r\n","            # prediction_array에 입력\r\n","            batch_index = batch_size * idx\r\n","            prediction_array[batch_index: batch_index + images.shape[0],:]\\\r\n","                         = preds.astype(int)\r\n","                         \r\n","    # 채널을 하나 추가하여 list에 append\r\n","    predictions_list.append(prediction_array[...,np.newaxis])"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q14pVyHnD0hY","executionInfo":{"status":"ok","timestamp":1613760809514,"user_tz":-540,"elapsed":893,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"3efb163d-eaff-4e51-d931-75390d5fcebd"},"source":["# axis = 2를 기준으로 평균\r\n","predictions_array = np.concatenate(predictions_list, axis = 2)\r\n","predictions_mean = predictions_array.mean(axis = 2)\r\n","\r\n","# 평균 값이 0.5보다 클 경우 1 작으면 0\r\n","predictions_mean = (predictions_mean > 0.5) * 1\r\n","predictions_mean"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 0, 1, ..., 1, 0, 1],\n","       [1, 1, 0, ..., 0, 0, 0],\n","       [1, 0, 1, ..., 0, 0, 1],\n","       ...,\n","       [0, 0, 1, ..., 0, 0, 1],\n","       [0, 0, 1, ..., 0, 0, 0],\n","       [0, 0, 0, ..., 1, 0, 0]])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hukGtk06D2By","executionInfo":{"status":"ok","timestamp":1613760846620,"user_tz":-540,"elapsed":937,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"ae412e93-cb5f-4997-d627-14b5d8265637"},"source":["sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","sample_submission.iloc[:,1:] = predictions_mean\r\n","sample_submission.to_csv(\"/content/drive/MyDrive/Colab Notebooks/dacon/ensemble_prediction2_dropout.csv\", index = False)\r\n","sample_submission"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","      <th>f</th>\n","      <th>g</th>\n","      <th>h</th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>k</th>\n","      <th>l</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>o</th>\n","      <th>p</th>\n","      <th>q</th>\n","      <th>r</th>\n","      <th>s</th>\n","      <th>t</th>\n","      <th>u</th>\n","      <th>v</th>\n","      <th>w</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50001</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>50002</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50003</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50004</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>54995</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>54996</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>54997</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>54998</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>54999</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 27 columns</p>\n","</div>"],"text/plain":["      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n","0     50000  1  0  1  0  0  1  0  1  1  1  ...  1  0  1  0  1  0  0  0  1  0  1\n","1     50001  1  1  0  1  1  0  1  0  1  1  ...  1  1  0  1  0  0  0  0  0  0  0\n","2     50002  1  0  1  1  1  1  0  1  0  1  ...  1  0  0  0  0  1  1  1  0  0  1\n","3     50003  1  1  0  1  0  1  1  0  1  0  ...  1  1  0  0  1  0  0  1  1  0  1\n","4     50004  0  0  1  0  1  0  0  0  0  0  ...  0  0  0  1  0  1  0  1  1  0  0\n","...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n","4995  54995  0  0  1  0  0  1  0  1  0  0  ...  0  0  0  0  1  0  0  1  0  0  1\n","4996  54996  0  1  1  1  0  0  0  0  0  0  ...  1  0  0  1  0  0  0  0  1  0  0\n","4997  54997  0  0  1  1  0  1  0  1  0  0  ...  1  0  1  0  1  1  1  0  0  0  1\n","4998  54998  0  0  1  0  1  0  0  0  1  0  ...  0  0  0  0  0  0  0  1  0  0  0\n","4999  54999  0  0  0  0  0  0  0  0  1  0  ...  0  0  0  1  1  0  0  1  1  0  0\n","\n","[5000 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"hY6KwU_DMq18"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pPTS_PZ1mghf"},"source":["# bestmodel array 활용"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":169},"id":"_vPInbNIm0xz","executionInfo":{"status":"error","timestamp":1613760267415,"user_tz":-540,"elapsed":834,"user":{"displayName":"임지혜","photoUrl":"","userId":"15033595692039293722"}},"outputId":"b087ed06-3587-4a85-bbc9-4479bb8b9a69"},"source":[""],"execution_count":13,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-2ef73c424d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'best_models' is not defined"]}]},{"cell_type":"code","metadata":{"id":"GLlOwzZ2m1zy"},"source":[""],"execution_count":null,"outputs":[]}]}