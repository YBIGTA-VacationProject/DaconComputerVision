{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1GKtN11oeam5yKPc4qozlPfZNgS_tKgXb",
      "authorship_tag": "ABX9TyPZkka21XxNDzxuGTaCv67n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ea805f7ba1fe42a097943387c8f85b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_11010afe2bcb4080864b89e362fde373",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7f51e5a10fbb4bf7bb642490e9d389bb",
              "IPY_MODEL_26e660858c6d456e87635692deaf62ec"
            ]
          }
        },
        "11010afe2bcb4080864b89e362fde373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7f51e5a10fbb4bf7bb642490e9d389bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_016bd93b98b446bc900f85f528f5885f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100441675,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100441675,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf0e8c79869d429fa8aae95267cf5fd6"
          }
        },
        "26e660858c6d456e87635692deaf62ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_722eea7b674344359a4ae3c1c2740530",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 95.8M/95.8M [00:00&lt;00:00, 205MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_513a7ec05cc64e6b9d45e2e352e68ebf"
          }
        },
        "016bd93b98b446bc900f85f528f5885f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf0e8c79869d429fa8aae95267cf5fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "722eea7b674344359a4ae3c1c2740530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "513a7ec05cc64e6b9d45e2e352e68ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YBIGTA-VacationProject/DaconComputerVision/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6DJ0zKI0sOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815c70f2-d63a-4317-eb82-f281b8a2de4b"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kk6EiT6c0tdk",
        "outputId": "2466b2c7-441f-4fd3-fc7d-3e40b0d9976a"
      },
      "source": [
        "from google.colab import output\r\n",
        "# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\r\n",
        "# !cp \"/content/gdrive/MyDrive/data/data_2.zip\" \"data_2.zip\"\r\n",
        "# data_2.zip을 현재 디렉터리에 압축해제\r\n",
        "\r\n",
        "\r\n",
        "!unzip \"/content/gdrive/MyDrive/data/data_2.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/MyDrive/data/data_2.zip\n",
            "  inflating: dirty_mnist_2nd.zip     \n",
            "  inflating: dirty_mnist_2nd_answer.csv  \n",
            "  inflating: mnist_data.zip          \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test_dirty_mnist_2nd.zip  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eOsYlNb0tza"
      },
      "source": [
        "from google.colab import output\r\n",
        "# 현재 디렉터리에 dirty_mnist라는 폴더 생성\r\n",
        "!mkdir \"./dirty_mnist\"\r\n",
        "#dirty_mnist.zip라는 zip파일을 dirty_mnist라는 폴더에 압축 풀기\r\n",
        "!unzip \"dirty_mnist_2nd.zip\" -d \"./dirty_mnist/\"\r\n",
        "# 현재 디렉터리에 test_dirty_mnist라는 폴더 생성\r\n",
        "!mkdir \"./test_dirty_mnist\"\r\n",
        "#test_dirty_mnist.zip라는 zip파일을 test_dirty_mnist라는 폴더에 압축 풀기\r\n",
        "!unzip \"test_dirty_mnist_2nd.zip\" -d \"./test_dirty_mnist/\"\r\n",
        "# 출력 결과 지우기\r\n",
        "output.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwmtmPFf48tz"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "from tqdm import tqdm\r\n",
        "import imutils\r\n",
        "import zipfile\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "from typing import Tuple, Sequence, Callable\r\n",
        "import glob\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "import random\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision.models as models\r\n",
        "from torchvision import transforms\r\n",
        "import torchvision.transforms as T\r\n",
        "from torch.utils.data import DataLoader, Dataset\r\n",
        "from google.colab import output\r\n",
        "\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 디바이스 설정"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HiEeT6R7f6d"
      },
      "source": [
        "labels_df = pd.read_csv('/content/dirty_mnist_2nd_answer.csv')[:]\r\n",
        "imgs_dir = np.array(sorted(glob.glob('/content/dirty_mnist/*')))[:]\r\n",
        "labels = np.array(labels_df.values[:,1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHFgz-KpntOV"
      },
      "source": [
        "test_imgs_dir = np.array(sorted(glob.glob('/content/test_dirty_mnist/*')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Ph470UAKDdGv",
        "outputId": "7d254311-05d0-449a-9323-c7818310740d"
      },
      "source": [
        "labels_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>f</th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "      <th>i</th>\n",
              "      <th>j</th>\n",
              "      <th>k</th>\n",
              "      <th>l</th>\n",
              "      <th>m</th>\n",
              "      <th>n</th>\n",
              "      <th>o</th>\n",
              "      <th>p</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>t</th>\n",
              "      <th>u</th>\n",
              "      <th>v</th>\n",
              "      <th>w</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>49995</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>49996</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>49997</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>49998</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>49999</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n",
              "0          0  1  1  0  1  0  1  0  0  0  0  ...  1  0  1  1  0  1  0  0  1  1  1\n",
              "1          1  1  0  0  1  0  1  0  1  0  1  ...  1  0  1  0  1  0  0  0  0  1  1\n",
              "2          2  0  0  0  0  0  0  0  0  1  1  ...  1  0  0  1  1  1  0  1  1  1  0\n",
              "3          3  0  0  1  0  0  0  1  1  0  0  ...  1  1  0  1  1  0  1  1  0  1  0\n",
              "4          4  0  1  0  1  0  1  0  1  1  0  ...  1  0  1  0  0  0  1  0  1  0  0\n",
              "...      ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n",
              "49995  49995  0  1  1  0  0  0  0  1  0  0  ...  0  0  0  0  1  0  0  0  1  1  0\n",
              "49996  49996  0  1  0  1  0  1  1  1  0  1  ...  0  0  1  1  1  0  1  0  0  0  1\n",
              "49997  49997  0  1  0  0  1  1  1  1  0  0  ...  0  1  0  0  0  0  1  1  1  0  0\n",
              "49998  49998  0  1  1  1  0  0  1  1  0  1  ...  0  0  1  1  1  0  0  0  1  0  0\n",
              "49999  49999  1  0  1  0  0  0  0  0  0  1  ...  1  0  1  1  0  1  1  0  1  0  0\n",
              "\n",
              "[50000 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cDd_pUV8NQl"
      },
      "source": [
        "class MnistDataset(Dataset):\r\n",
        "    def __init__(self, imgs_dir=None, labels=None, transform=None, train=True):\r\n",
        "        self.imgs_dir = imgs_dir\r\n",
        "        self.labels = labels\r\n",
        "        self.transform = transform\r\n",
        "        self.train = train\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def __len__(self):\r\n",
        "        # 데이터 총 샘플 수\r\n",
        "        return len(self.imgs_dir)\r\n",
        "    \r\n",
        "    def __getitem__(self, idx):\r\n",
        "        # 1개 샘플 get\r\n",
        "        img = cv2.imread(self.imgs_dir[idx], cv2.IMREAD_COLOR)\r\n",
        "        img = self.transform(img)\r\n",
        "        if self.train==True:\r\n",
        "            label = self.labels[idx]\r\n",
        "            return img, label\r\n",
        "        else:\r\n",
        "            return img\r\n",
        "        \r\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wzZvm5HIM_j"
      },
      "source": [
        "train_transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.RandomHorizontalFlip(),\r\n",
        "    transforms.RandomVerticalFlip(),\r\n",
        "    transforms.Normalize(\r\n",
        "    [0.485, 0.456, 0.406],\r\n",
        "    [0.229, 0.224, 0.225]\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFNLR7HS-rso"
      },
      "source": [
        "train_dataset = MnistDataset(imgs_dir=imgs_dir, labels=labels, transform=train_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEUz8minIZes"
      },
      "source": [
        "train_dataset.__getitem__(1)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ea805f7ba1fe42a097943387c8f85b72",
            "11010afe2bcb4080864b89e362fde373",
            "7f51e5a10fbb4bf7bb642490e9d389bb",
            "26e660858c6d456e87635692deaf62ec",
            "016bd93b98b446bc900f85f528f5885f",
            "cf0e8c79869d429fa8aae95267cf5fd6",
            "722eea7b674344359a4ae3c1c2740530",
            "513a7ec05cc64e6b9d45e2e352e68ebf"
          ]
        },
        "id": "2iGxtJwjBOXe",
        "outputId": "e96fea99-5cf3-40f2-a5fc-2180632726b2"
      },
      "source": [
        "resnext = torch.hub.load('pytorch/vision:v0.6.0', 'resnext50_32x4d', pretrained=True)\r\n",
        "\r\n",
        "class Resnext(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Resnext, self).__init__()\r\n",
        "        self.resnext = resnext \r\n",
        "        self.FC = nn.Linear(1000, 26)\r\n",
        "        nn.init.xavier_normal_(self.FC.weight)\r\n",
        "      \r\n",
        "        \r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.resnext(x)\r\n",
        "        x = torch.sigmoid(self.FC(x))\r\n",
        "        return x\r\n",
        "\r\n",
        "model = Resnext()\r\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /root/.cache/torch/hub/v0.6.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea805f7ba1fe42a097943387c8f85b72",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=100441675.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resnext(\n",
              "  (resnext): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "  )\n",
              "  (FC): Linear(in_features=1000, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqvuhxP68eYZ"
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\r\n",
        "folds=[]\r\n",
        "for train_idx, valid_idx in kf.split(labels_df):\r\n",
        "    folds.append((train_idx, valid_idx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nry4gwbJFBlZ",
        "outputId": "5a9f1c02-2caf-4ab2-eb4f-35b7cdc2cc28"
      },
      "source": [
        "train_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     1,     3, ..., 49996, 49998, 49999])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh0FVh2BFEk0",
        "outputId": "8181a7a7-b325-444d-ddc1-908b06d2a023"
      },
      "source": [
        "valid_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    2,     9,    10, ..., 49981, 49985, 49997])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvLYON-1KyuY"
      },
      "source": [
        "train_dataset = MnistDataset(imgs_dir=imgs_dir[train_idx], labels=labels[train_idx], transform=train_transform)\r\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDDmtBdj8Xi-",
        "outputId": "69ff1e9c-30c9-454d-aabf-5bae17573921"
      },
      "source": [
        "train_dataset.__len__()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB6duwc1K4BC",
        "outputId": "45ea542c-3944-45e0-c568-5b9d59d36899"
      },
      "source": [
        "train_loader.__len__()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE6WyMbU8eic",
        "outputId": "f4ad55a4-a991-410b-f6b5-22f4a6b83db6"
      },
      "source": [
        "for fold in range(1):\r\n",
        "    model = Resnext().to(device)\r\n",
        "\r\n",
        "    train_idx = folds[fold][0]\r\n",
        "    valid_idx = folds[fold][1]\r\n",
        "\r\n",
        "    train_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.RandomHorizontalFlip(),\r\n",
        "        transforms.RandomVerticalFlip(),\r\n",
        "        transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225]\r\n",
        "    )\r\n",
        "        ])\r\n",
        "    valid_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225]\r\n",
        "    )\r\n",
        "        ])\r\n",
        "\r\n",
        "\r\n",
        "    epochs=30\r\n",
        "    batch_size=64\r\n",
        "    \r\n",
        "    # Data Loader\r\n",
        "    train_dataset = MnistDataset(imgs_dir=imgs_dir[train_idx], labels=labels[train_idx], transform=train_transform)\r\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\r\n",
        "\r\n",
        "    valid_dataset = MnistDataset(imgs_dir=imgs_dir[valid_idx], labels=labels[valid_idx], transform=valid_transform)\r\n",
        "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=32, shuffle=False)  \r\n",
        "    \r\n",
        "    \r\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\r\n",
        "    decay_steps = (len(train_dataset)//batch_size)*epochs\r\n",
        "\r\n",
        "    criterion = torch.nn.BCELoss()\r\n",
        "    \r\n",
        "    \r\n",
        "    epoch_accuracy = []\r\n",
        "    valid_accuracy = []\r\n",
        "    valid_losses=[]\r\n",
        "    valid_best_accuracy=0\r\n",
        "\r\n",
        "    best_models=[]\r\n",
        "\r\n",
        "    for epoch in range(epochs):\r\n",
        "      with tqdm(train_loader,total=train_loader.__len__(),unit='batch') as train_bar:\r\n",
        "        model.train()\r\n",
        "        batch_accuracy_list = []\r\n",
        "        batch_loss_list = []\r\n",
        "        start=time.time()\r\n",
        "        for n, (X, y) in enumerate((train_bar)):\r\n",
        "            train_bar.set_description(f\"Train Epoch {epoch}\")\r\n",
        "            X = torch.tensor(X, device=device, dtype=torch.float32)\r\n",
        "            y = torch.tensor(y, device=device, dtype=torch.float32)\r\n",
        "            y_pred = model(X)\r\n",
        "            \r\n",
        "            \r\n",
        "            optimizer.zero_grad()\r\n",
        "            loss = criterion(y_pred, y)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "\r\n",
        "            \r\n",
        "            y_pred  = y_pred.cpu().detach().numpy()\r\n",
        "            y_pred = y_pred>0.5\r\n",
        "            y = y.cpu().detach().numpy()\r\n",
        "\r\n",
        "            batch_accuracy = (y_pred == y).mean()\r\n",
        "            batch_accuracy_list.append(batch_accuracy)\r\n",
        "            batch_loss_list.append(loss.item())\r\n",
        "            train_acc = np.mean(batch_accuracy_list)\r\n",
        "            \r\n",
        "            train_bar.set_postfix(train_loss= loss.item(),train_acc = train_acc)\r\n",
        "\r\n",
        "        model.eval()\r\n",
        "        valid_batch_accuracy=[]\r\n",
        "        valid_batch_loss = []\r\n",
        "\r\n",
        "        with torch.no_grad():\r\n",
        "          with tqdm(valid_loader,total=valid_loader.__len__(),unit=\"batch\") as valid_bar:\r\n",
        "            for n_valid, (X_valid, y_valid) in enumerate((valid_bar)):\r\n",
        "                valid_bar.set_description(f\"Valid Epoch {epoch}\") \r\n",
        "                X_valid = torch.tensor(X_valid, device=device)#, dtype=torch.float32)\r\n",
        "                y_valid = torch.tensor(y_valid, device=device, dtype=torch.float32)\r\n",
        "                y_valid_hat = model(X_valid)\r\n",
        "                \r\n",
        "                valid_loss = criterion(y_valid_hat, y_valid).item()\r\n",
        "                \r\n",
        "                y_valid_hat = y_valid_hat.cpu().detach().numpy()>0.5\r\n",
        "                \r\n",
        "                \r\n",
        "                valid_batch_loss.append(valid_loss)\r\n",
        "                valid_batch_accuracy.append((y_valid_hat == y_valid.cpu().detach().numpy()).mean())\r\n",
        "                val_acc=np.mean(valid_batch_accuracy)\r\n",
        "                valid_bar.set_postfix(valid_loss = valid_loss,valid_acc = val_acc)\r\n",
        "                \r\n",
        "            valid_losses.append(np.mean(valid_batch_loss))\r\n",
        "            valid_accuracy.append(np.mean(valid_batch_accuracy))\r\n",
        "\r\n",
        "\r\n",
        "        if np.mean(valid_batch_accuracy)>valid_best_accuracy:\r\n",
        "            best_model=model\r\n",
        "            path = \"/content/gdrive/MyDrive/Colab Notebooks/models/\"\r\n",
        "            MODEL = \"resnext\"\r\n",
        "            torch.save(best_model, f'{path}{n}_{MODEL}_{valid_loss:2.4f}_epoch_{epoch}.pth')\r\n",
        "            valid_best_accuracy = np.mean(valid_batch_accuracy)\r\n",
        "\r\n",
        "    best_models.append(best_model)        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 0:   0%|          | 0/625 [00:00<?, ?batch/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "Train Epoch 0: 100%|██████████| 625/625 [19:19<00:00,  1.86s/batch, train_acc=0.523, train_loss=0.691]\n",
            "Valid Epoch 0:   0%|          | 0/313 [00:00<?, ?batch/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "Valid Epoch 0: 100%|██████████| 313/313 [01:14<00:00,  4.21batch/s, valid_acc=0.533, valid_loss=0.707]\n",
            "Train Epoch 1: 100%|██████████| 625/625 [19:03<00:00,  1.83s/batch, train_acc=0.548, train_loss=0.681]\n",
            "Valid Epoch 1: 100%|██████████| 313/313 [01:11<00:00,  4.35batch/s, valid_acc=0.547, valid_loss=0.703]\n",
            "Train Epoch 2: 100%|██████████| 625/625 [19:01<00:00,  1.83s/batch, train_acc=0.575, train_loss=0.667]\n",
            "Valid Epoch 2: 100%|██████████| 313/313 [01:11<00:00,  4.40batch/s, valid_acc=0.566, valid_loss=0.702]\n",
            "Train Epoch 3: 100%|██████████| 625/625 [18:50<00:00,  1.81s/batch, train_acc=0.594, train_loss=0.65]\n",
            "Valid Epoch 3: 100%|██████████| 313/313 [01:10<00:00,  4.41batch/s, valid_acc=0.604, valid_loss=0.657]\n",
            "Train Epoch 4: 100%|██████████| 625/625 [18:57<00:00,  1.82s/batch, train_acc=0.625, train_loss=0.622]\n",
            "Valid Epoch 4: 100%|██████████| 313/313 [01:09<00:00,  4.50batch/s, valid_acc=0.613, valid_loss=0.668]\n",
            "Train Epoch 5: 100%|██████████| 625/625 [18:28<00:00,  1.77s/batch, train_acc=0.655, train_loss=0.594]\n",
            "Valid Epoch 5: 100%|██████████| 313/313 [01:09<00:00,  4.53batch/s, valid_acc=0.669, valid_loss=0.578]\n",
            "Train Epoch 6: 100%|██████████| 625/625 [18:27<00:00,  1.77s/batch, train_acc=0.673, train_loss=0.584]\n",
            "Valid Epoch 6: 100%|██████████| 313/313 [01:08<00:00,  4.56batch/s, valid_acc=0.667, valid_loss=0.599]\n",
            "Train Epoch 7: 100%|██████████| 625/625 [18:25<00:00,  1.77s/batch, train_acc=0.7, train_loss=0.545]\n",
            "Valid Epoch 7: 100%|██████████| 313/313 [01:08<00:00,  4.57batch/s, valid_acc=0.714, valid_loss=0.541]\n",
            "Train Epoch 8: 100%|██████████| 625/625 [18:23<00:00,  1.77s/batch, train_acc=0.732, train_loss=0.509]\n",
            "Valid Epoch 8: 100%|██████████| 313/313 [01:08<00:00,  4.57batch/s, valid_acc=0.74, valid_loss=0.529]\n",
            "Train Epoch 9: 100%|██████████| 625/625 [18:22<00:00,  1.76s/batch, train_acc=0.767, train_loss=0.462]\n",
            "Valid Epoch 9: 100%|██████████| 313/313 [01:08<00:00,  4.57batch/s, valid_acc=0.769, valid_loss=0.485]\n",
            "Train Epoch 10: 100%|██████████| 625/625 [18:24<00:00,  1.77s/batch, train_acc=0.794, train_loss=0.415]\n",
            "Valid Epoch 10: 100%|██████████| 313/313 [01:08<00:00,  4.55batch/s, valid_acc=0.797, valid_loss=0.442]\n",
            "Train Epoch 11: 100%|██████████| 625/625 [18:23<00:00,  1.77s/batch, train_acc=0.817, train_loss=0.396]\n",
            "Valid Epoch 11: 100%|██████████| 313/313 [01:09<00:00,  4.53batch/s, valid_acc=0.807, valid_loss=0.403]\n",
            "Train Epoch 12: 100%|██████████| 625/625 [18:26<00:00,  1.77s/batch, train_acc=0.83, train_loss=0.365]\n",
            "Valid Epoch 12: 100%|██████████| 313/313 [01:08<00:00,  4.56batch/s, valid_acc=0.824, valid_loss=0.432]\n",
            "Train Epoch 13: 100%|██████████| 625/625 [18:37<00:00,  1.79s/batch, train_acc=0.847, train_loss=0.341]\n",
            "Valid Epoch 13: 100%|██████████| 313/313 [01:09<00:00,  4.51batch/s, valid_acc=0.833, valid_loss=0.38]\n",
            "Train Epoch 14: 100%|██████████| 625/625 [18:25<00:00,  1.77s/batch, train_acc=0.86, train_loss=0.324]\n",
            "Valid Epoch 14: 100%|██████████| 313/313 [01:08<00:00,  4.54batch/s, valid_acc=0.843, valid_loss=0.371]\n",
            "Train Epoch 15: 100%|██████████| 625/625 [18:22<00:00,  1.76s/batch, train_acc=0.871, train_loss=0.307]\n",
            "Valid Epoch 15: 100%|██████████| 313/313 [01:08<00:00,  4.56batch/s, valid_acc=0.857, valid_loss=0.356]\n",
            "Train Epoch 16: 100%|██████████| 625/625 [18:19<00:00,  1.76s/batch, train_acc=0.881, train_loss=0.284]\n",
            "Valid Epoch 16: 100%|██████████| 313/313 [01:08<00:00,  4.56batch/s, valid_acc=0.861, valid_loss=0.349]\n",
            "Train Epoch 17: 100%|██████████| 625/625 [18:18<00:00,  1.76s/batch, train_acc=0.888, train_loss=0.248]\n",
            "Valid Epoch 17: 100%|██████████| 313/313 [01:08<00:00,  4.56batch/s, valid_acc=0.866, valid_loss=0.316]\n",
            "Train Epoch 18: 100%|██████████| 625/625 [18:19<00:00,  1.76s/batch, train_acc=0.895, train_loss=0.277]\n",
            "Valid Epoch 18: 100%|██████████| 313/313 [01:09<00:00,  4.53batch/s, valid_acc=0.872, valid_loss=0.35]\n",
            "Train Epoch 19:  30%|██▉       | 185/625 [05:27<12:54,  1.76s/batch, train_acc=0.903, train_loss=0.253]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmipfKDozyUa"
      },
      "source": [
        "#저장된 model load\r\n",
        "#load_models=[]\r\n",
        "#model1 = torch.load('/content/gdrive/MyDrive/Colab Notebooks/models/624_resnext_0.5905_epoch_9.pth')\r\n",
        "#load_models.append(model1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffbLQBsBnhJ6"
      },
      "source": [
        "test_transform = transforms.Compose([\r\n",
        "        transforms.ToTensor(),\r\n",
        "        transforms.Normalize(\r\n",
        "        [0.485, 0.456, 0.406],\r\n",
        "        [0.229, 0.224, 0.225])\r\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBHPEINYnJ6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c261cb0d-ba04-40f2-d4ae-f00618e6124c"
      },
      "source": [
        "submission = pd.read_csv(\"sample_submission.csv\")\r\n",
        "\r\n",
        "for model in best_models:\r\n",
        "    with torch.no_grad():\r\n",
        "        model.eval()\r\n",
        "\r\n",
        "        test_dataset = MnistDataset(imgs_dir=test_imgs_dir, transform=test_transform, train=False)\r\n",
        "        test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\r\n",
        "\r\n",
        "        for n, X_test in enumerate(tqdm(test_loader)):\r\n",
        "            X_test = torch.tensor(X_test, device=device, dtype=torch.float32)\r\n",
        "            with torch.no_grad():\r\n",
        "                model.eval()  \r\n",
        "                pred_test = model(X_test).cpu().detach().numpy()\r\n",
        "                submission.iloc[n*32:(n+1)*32,1:] += pred_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/157 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "100%|██████████| 157/157 [28:08<00:00, 10.76s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZjiMq99nJ8J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "bf8817aa-97a0-407f-def1-f6e287dce336"
      },
      "source": [
        "submission.iloc[:,1:] = np.where(submission.values[:,1:]>=0.5, 1,0)\r\n",
        "submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>f</th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "      <th>i</th>\n",
              "      <th>j</th>\n",
              "      <th>k</th>\n",
              "      <th>l</th>\n",
              "      <th>m</th>\n",
              "      <th>n</th>\n",
              "      <th>o</th>\n",
              "      <th>p</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>t</th>\n",
              "      <th>u</th>\n",
              "      <th>v</th>\n",
              "      <th>w</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50001</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50002</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50004</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>54995</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>54996</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>54997</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>54998</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>54999</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n",
              "0     50000  0  0  1  0  1  1  1  1  1  1  ...  0  0  1  0  1  1  1  0  1  1  0\n",
              "1     50001  0  1  0  1  1  0  1  0  1  1  ...  1  1  1  0  0  0  1  0  0  1  0\n",
              "2     50002  1  1  1  1  1  1  1  1  1  1  ...  1  1  1  1  0  1  1  1  0  1  1\n",
              "3     50003  1  1  0  1  1  1  1  1  0  0  ...  1  1  1  0  1  0  0  1  1  1  0\n",
              "4     50004  0  1  1  1  1  0  1  0  0  0  ...  1  1  0  1  0  0  0  1  0  0  0\n",
              "...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n",
              "4995  54995  0  0  1  0  1  0  0  0  0  0  ...  0  0  0  0  0  1  1  1  0  0  0\n",
              "4996  54996  0  1  1  1  0  0  1  0  1  0  ...  1  1  0  0  1  0  1  0  1  0  0\n",
              "4997  54997  0  0  0  0  1  1  1  1  1  1  ...  0  0  1  0  0  1  1  1  0  1  1\n",
              "4998  54998  0  0  1  1  1  0  0  0  1  0  ...  1  0  0  1  0  0  0  1  0  0  0\n",
              "4999  54999  0  0  0  0  1  0  0  0  1  0  ...  0  0  0  1  1  0  0  1  1  0  1\n",
              "\n",
              "[5000 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y-InheYnJ-J"
      },
      "source": [
        "submission.to_csv('Resnext_prediction.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdj_kd9xnKAO"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}