{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ECp9atME8W"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "954WxGTSkddB",
        "outputId": "3e76ee71-94ba-441f-be6d-a7a83783ee04"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_lA5C3cXTq4",
        "outputId": "9bb9acd2-9715-4425-834c-0f4132d8df51"
      },
      "source": [
        "%cd /content/drive/MyDrive/dacon_cv/ASL\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/dacon_cv/ASL\n",
            "infer.py\t\tMODEL_ZOO.md\t\t\t resnext_asl_5.csv\n",
            "LICENSE\t\t\tpics\t\t\t\t resnext_asl_75.csv\n",
            "model_asl\t\tprediction.csv\t\t\t resnext.ipynb\n",
            "model_hard_set\t\tprediction_hard_set_8.csv\t src\n",
            "model_large_train\tprediction_without_cutout_7.csv  train.ipynb\n",
            "model_new_augmentation\tprediction_without_cutout_8.csv  train.py\n",
            "models\t\t\tREADME.md\t\t\t tresnet_m.pth\n",
            "models_hard_asl\t\trequirements.txt\t\t validate.py\n",
            "model_without_cutout\tresnext_asl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh6s6z70awqp",
        "outputId": "8f067c71-dd14-4c5b-975e-e4fa0f231a7a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Feb 26 11:02:43 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "jR9wN2cPdPED",
        "outputId": "6cdac5d6-77d6-40fe-d4a0-4878d3be448f"
      },
      "source": [
        "import os\n",
        "len(os.listdir(\"./dirty_mnist/\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2881\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2882\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2883\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-cd8389ac2032>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./dirty_mnist/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: './dirty_mnist/'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzrC9J3OGrK2",
        "outputId": "0957fe24-8604-498d-d014-f0909a898ae5"
      },
      "source": [
        "!rm -rf dirty_mnist/ \n",
        "!mkdir dirty_mnist/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'제_2회 컴퓨터 비전 학습 경진대회 베이스라인 코드.ipynb'\n",
            " ASL\n",
            " converT2coco.ipynb\n",
            " dirty_mnist\n",
            " dirty_mnist_2nd_answer.csv\n",
            " dirty_mnist_2nd.zip\n",
            " dirty_mnist_answer.csv\n",
            " dirty_mnist.zip\n",
            " mnist_data\n",
            " prediction.csv\n",
            " sample_submission.csv\n",
            " test_dirty_mnist\n",
            " test_dirty_mnist_2nd.zip\n",
            " test.json\n",
            " train.json\n",
            " val.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaMcfTqyL6M6",
        "outputId": "68135522-a553-453d-9e99-79840840f245"
      },
      "source": [
        "!unzip -q dirty_mnist_2nd.zip -d dirty_mnist/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'제_2회 컴퓨터 비전 학습 경진대회 베이스라인 코드.ipynb'\n",
            " ASL\n",
            " converT2coco.ipynb\n",
            " dirty_mnist\n",
            " dirty_mnist_2nd_answer.csv\n",
            " dirty_mnist_2nd.zip\n",
            " dirty_mnist_answer.csv\n",
            " dirty_mnist.zip\n",
            " mnist_data\n",
            " prediction.csv\n",
            " sample_submission.csv\n",
            " test_dirty_mnist\n",
            " test_dirty_mnist_2nd.zip\n",
            " test.json\n",
            " train.json\n",
            " val.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfqh0xNecbND"
      },
      "source": [
        "!rm -rf dirty_mnist/dirty_mnist_train/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qddEGp0bgHs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0mr5L08blTk"
      },
      "source": [
        "namelist = os.listdir('./dirty_mnist/')\n",
        "answer = pd.read_csv('dirty_mnist_answer.csv')\n",
        "train, val = train_test_split(namelist, test_size=0.1, random_state=23)\n",
        "train_num = [int(t[:5]) for t in train]\n",
        "val_num = [int(v[:5]) for v in val]\n",
        "train_ohe = [True if i in train_num else False for i in range(50000)]\n",
        "val_ohe = [True if i in val_num else False for i in range(50000)]\n",
        "train_ans = answer[train_ohe]\n",
        "val_ans = answer[val_ohe]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PJ30bSobxn6"
      },
      "source": [
        "%cd ./dirty_mnist/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afbyD31jb0Fc"
      },
      "source": [
        "os.makedirs('./dirty_mnist_train', exist_ok=True)\n",
        "os.makedirs('./dirty_mnist_val', exist_ok=True)\n",
        "for t in train:\n",
        "    shutil.move(t, './dirty_mnist_train')\n",
        "for v in val:\n",
        "    shutil.move(v, './dirty_mnist_val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOtC7LJLb01c"
      },
      "source": [
        "def csv_to_coco(df, json_name):\n",
        "    dic = {\n",
        "        \"info\": {\n",
        "            \"description\": \"DACON DIRTY MNIST DATASET\",\n",
        "            \"url\": \"https://oranz.tistory.com/\",\n",
        "            \"version\": \"1.0\",\n",
        "            \"year\": 2021,\n",
        "            \"contributor\": \"DACON\",\n",
        "            \"date_created\": \"2021/02/18\"\n",
        "        },\n",
        "        \"licenses\": [{\n",
        "            \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\",\n",
        "            \"id\": 1,\n",
        "            \"name\": \"Attribution-NonCommercial-ShareAlike License\"\n",
        "        }],\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": []\n",
        "    }\n",
        "    \n",
        "    for i in range(1, 27):\n",
        "        dic[\"categories\"].append({\"supercategory\": \"alphabet\", \"id\": i, \"name\": chr(i + 96)})\n",
        "        \n",
        "    anno_id = 1\n",
        "    for r in range(len(df)):\n",
        "        image_id = int(df.iloc[r, 0]) # cast to int for JSON serialization\n",
        "        name = str(image_id)\n",
        "        name = '0' * (5 - len(name)) + name + '.png'\n",
        "        dic[\"images\"].append({\n",
        "            \"license\": 1,\n",
        "            \"file_name\": name,\n",
        "            \"coco_url\": \"\",\n",
        "            \"height\": 256,\n",
        "            \"width\": 256,\n",
        "            \"date_captured\": \"2020-05-19 23:03:57\",\n",
        "            \"flickr_url\": \"\",\n",
        "            \"id\": image_id\n",
        "        })\n",
        "        \n",
        "        for c in range(1, 27):\n",
        "            if df.iloc[r, c] == 1:\n",
        "                dic[\"annotations\"].append({\n",
        "                    \"segmentation\": [],\n",
        "                    \"area\": 232,\n",
        "                    \"iscrowd\": 0,\n",
        "                    \"image_id\": image_id,\n",
        "                    \"bbox\": [1, 5, 4, 9],\n",
        "                    \"category_id\": c,\n",
        "                    \"id\": anno_id\n",
        "                })\n",
        "                anno_id += 1\n",
        "    with open(json_name, \"w\") as json_file:\n",
        "        json.dump(dic, json_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8HXplx1b5me"
      },
      "source": [
        "csv_to_coco(val_ans, \"val.json\")\n",
        "csv_to_coco(train_ans, \"train.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JutUitkuMKwz"
      },
      "source": [
        "# Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tODw8jcRq6G",
        "outputId": "3009c836-25ea-4a13-8484-0a97f10ac119"
      },
      "source": [
        "!pip install inplace-abn\n",
        "!pip install randaugment"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting inplace-abn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/27/c5791febcdd9af346b66dff19759898476f148177c02b02a72e07ca8aba0/inplace-abn-1.1.0.tar.gz (137kB)\n",
            "\r\u001b[K     |██▍                             | 10kB 18.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20kB 24.8MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40kB 27.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51kB 21.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61kB 19.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 71kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81kB 18.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 92kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 102kB 18.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 112kB 18.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 122kB 18.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 133kB 18.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 18.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: inplace-abn\n",
            "  Building wheel for inplace-abn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for inplace-abn: filename=inplace_abn-1.1.0-cp37-cp37m-linux_x86_64.whl size=2754632 sha256=d23e688ed0643882bf7266066bd0360695946a4cb053a366c07952f4f25b7f1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/e6/ce/baadcff0441c600caa5874d4d3322a7909e724fb7abab21a15\n",
            "Successfully built inplace-abn\n",
            "Installing collected packages: inplace-abn\n",
            "Successfully installed inplace-abn-1.1.0\n",
            "Collecting randaugment\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/ea/e24549f459800dc3bed21cd4e9c0d49d5b8deed65214b2444bd3e5a49f30/randaugment-1.0.2-py3-none-any.whl\n",
            "Installing collected packages: randaugment\n",
            "Successfully installed randaugment-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8epwFeaNfSX",
        "outputId": "9bb8234e-20d7-4ddd-bb63-757141a71bfc"
      },
      "source": [
        "cd ./ASL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: './ASL'\n",
            "/content/drive/MyDrive/dacon_cv/ASL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUcYQkhSsGgk",
        "outputId": "4c1186bb-306a-43a1-b85b-a75a9fbfbc27"
      },
      "source": [
        "!mkdir model_hard_set\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "infer.py\t\tmodels_hard_asl\t\t\t README.md\n",
            "LICENSE\t\t\tmodel_without_cutout\t\t requirements.txt\n",
            "model_asl\t\tMODEL_ZOO.md\t\t\t src\n",
            "model_hard_set\t\tpics\t\t\t\t train.ipynb\n",
            "model_large_train\tprediction.csv\t\t\t train.py\n",
            "model_new_augmentation\tprediction_without_cutout_7.csv  tresnet_m.pth\n",
            "models\t\t\tprediction_without_cutout_8.csv  validate.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRqxe8_MMQ6m"
      },
      "source": [
        "# PPT (모델 구조)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJPZJvB-AeIR",
        "outputId": "5250d3d9-3a67-485e-f736-bd6cd18d21f8"
      },
      "source": [
        "from torchsummary import summary\n",
        "import easydict\n",
        "from src.models import create_model\n",
        "\n",
        "args = easydict.EasyDict({ \"data\": \"../dirty_mnist\", \n",
        "                          \"lr\": 23e-5, \n",
        "                          \"model_name\": \"tresnet_m\", \n",
        "                          \"model_path\": \"./tresnet_m.pth\",\n",
        "                          \"num_classes\": 26, \n",
        "                          \"workers\": 4, \n",
        "                          \"image_size\": 224, \n",
        "                          \"thre\": 0.8,\n",
        "                          \"batch_size\": 512,\n",
        "                          \"print_freq\": 64\n",
        "                          })\n",
        "args.do_bottleneck_head = False\n",
        "\n",
        "# Setup model\n",
        "print('creating model...')\n",
        "model = create_model(args).cuda()\n",
        "summary(model,(3,256,256))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating model...\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "SpaceToDepthModule-1           [-1, 48, 64, 64]               0\n",
            "            Conv2d-2           [-1, 64, 64, 64]          27,648\n",
            "        InPlaceABN-3           [-1, 64, 64, 64]             128\n",
            "            Conv2d-4           [-1, 64, 64, 64]          36,864\n",
            "        InPlaceABN-5           [-1, 64, 64, 64]             128\n",
            "            Conv2d-6           [-1, 64, 64, 64]          36,864\n",
            "        InPlaceABN-7           [-1, 64, 64, 64]             128\n",
            "     FastAvgPool2d-8             [-1, 64, 1, 1]               0\n",
            "            Conv2d-9             [-1, 64, 1, 1]           4,160\n",
            "             ReLU-10             [-1, 64, 1, 1]               0\n",
            "           Conv2d-11             [-1, 64, 1, 1]           4,160\n",
            "          Sigmoid-12             [-1, 64, 1, 1]               0\n",
            "         SEModule-13           [-1, 64, 64, 64]               0\n",
            "             ReLU-14           [-1, 64, 64, 64]               0\n",
            "       BasicBlock-15           [-1, 64, 64, 64]               0\n",
            "           Conv2d-16           [-1, 64, 64, 64]          36,864\n",
            "       InPlaceABN-17           [-1, 64, 64, 64]             128\n",
            "           Conv2d-18           [-1, 64, 64, 64]          36,864\n",
            "       InPlaceABN-19           [-1, 64, 64, 64]             128\n",
            "    FastAvgPool2d-20             [-1, 64, 1, 1]               0\n",
            "           Conv2d-21             [-1, 64, 1, 1]           4,160\n",
            "             ReLU-22             [-1, 64, 1, 1]               0\n",
            "           Conv2d-23             [-1, 64, 1, 1]           4,160\n",
            "          Sigmoid-24             [-1, 64, 1, 1]               0\n",
            "         SEModule-25           [-1, 64, 64, 64]               0\n",
            "             ReLU-26           [-1, 64, 64, 64]               0\n",
            "       BasicBlock-27           [-1, 64, 64, 64]               0\n",
            "           Conv2d-28           [-1, 64, 64, 64]          36,864\n",
            "       InPlaceABN-29           [-1, 64, 64, 64]             128\n",
            "           Conv2d-30           [-1, 64, 64, 64]          36,864\n",
            "       InPlaceABN-31           [-1, 64, 64, 64]             128\n",
            "    FastAvgPool2d-32             [-1, 64, 1, 1]               0\n",
            "           Conv2d-33             [-1, 64, 1, 1]           4,160\n",
            "             ReLU-34             [-1, 64, 1, 1]               0\n",
            "           Conv2d-35             [-1, 64, 1, 1]           4,160\n",
            "          Sigmoid-36             [-1, 64, 1, 1]               0\n",
            "         SEModule-37           [-1, 64, 64, 64]               0\n",
            "             ReLU-38           [-1, 64, 64, 64]               0\n",
            "       BasicBlock-39           [-1, 64, 64, 64]               0\n",
            "        AvgPool2d-40           [-1, 64, 32, 32]               0\n",
            "           Conv2d-41          [-1, 128, 32, 32]           8,192\n",
            "       InPlaceABN-42          [-1, 128, 32, 32]             256\n",
            "           Conv2d-43          [-1, 128, 64, 64]          73,728\n",
            "       InPlaceABN-44          [-1, 128, 64, 64]             256\n",
            "AntiAliasDownsampleLayer-45          [-1, 128, 32, 32]               0\n",
            "           Conv2d-46          [-1, 128, 32, 32]         147,456\n",
            "       InPlaceABN-47          [-1, 128, 32, 32]             256\n",
            "    FastAvgPool2d-48            [-1, 128, 1, 1]               0\n",
            "           Conv2d-49             [-1, 64, 1, 1]           8,256\n",
            "             ReLU-50             [-1, 64, 1, 1]               0\n",
            "           Conv2d-51            [-1, 128, 1, 1]           8,320\n",
            "          Sigmoid-52            [-1, 128, 1, 1]               0\n",
            "         SEModule-53          [-1, 128, 32, 32]               0\n",
            "             ReLU-54          [-1, 128, 32, 32]               0\n",
            "       BasicBlock-55          [-1, 128, 32, 32]               0\n",
            "           Conv2d-56          [-1, 128, 32, 32]         147,456\n",
            "       InPlaceABN-57          [-1, 128, 32, 32]             256\n",
            "           Conv2d-58          [-1, 128, 32, 32]         147,456\n",
            "       InPlaceABN-59          [-1, 128, 32, 32]             256\n",
            "    FastAvgPool2d-60            [-1, 128, 1, 1]               0\n",
            "           Conv2d-61             [-1, 64, 1, 1]           8,256\n",
            "             ReLU-62             [-1, 64, 1, 1]               0\n",
            "           Conv2d-63            [-1, 128, 1, 1]           8,320\n",
            "          Sigmoid-64            [-1, 128, 1, 1]               0\n",
            "         SEModule-65          [-1, 128, 32, 32]               0\n",
            "             ReLU-66          [-1, 128, 32, 32]               0\n",
            "       BasicBlock-67          [-1, 128, 32, 32]               0\n",
            "           Conv2d-68          [-1, 128, 32, 32]         147,456\n",
            "       InPlaceABN-69          [-1, 128, 32, 32]             256\n",
            "           Conv2d-70          [-1, 128, 32, 32]         147,456\n",
            "       InPlaceABN-71          [-1, 128, 32, 32]             256\n",
            "    FastAvgPool2d-72            [-1, 128, 1, 1]               0\n",
            "           Conv2d-73             [-1, 64, 1, 1]           8,256\n",
            "             ReLU-74             [-1, 64, 1, 1]               0\n",
            "           Conv2d-75            [-1, 128, 1, 1]           8,320\n",
            "          Sigmoid-76            [-1, 128, 1, 1]               0\n",
            "         SEModule-77          [-1, 128, 32, 32]               0\n",
            "             ReLU-78          [-1, 128, 32, 32]               0\n",
            "       BasicBlock-79          [-1, 128, 32, 32]               0\n",
            "           Conv2d-80          [-1, 128, 32, 32]         147,456\n",
            "       InPlaceABN-81          [-1, 128, 32, 32]             256\n",
            "           Conv2d-82          [-1, 128, 32, 32]         147,456\n",
            "       InPlaceABN-83          [-1, 128, 32, 32]             256\n",
            "    FastAvgPool2d-84            [-1, 128, 1, 1]               0\n",
            "           Conv2d-85             [-1, 64, 1, 1]           8,256\n",
            "             ReLU-86             [-1, 64, 1, 1]               0\n",
            "           Conv2d-87            [-1, 128, 1, 1]           8,320\n",
            "          Sigmoid-88            [-1, 128, 1, 1]               0\n",
            "         SEModule-89          [-1, 128, 32, 32]               0\n",
            "             ReLU-90          [-1, 128, 32, 32]               0\n",
            "       BasicBlock-91          [-1, 128, 32, 32]               0\n",
            "        AvgPool2d-92          [-1, 128, 16, 16]               0\n",
            "           Conv2d-93         [-1, 1024, 16, 16]         131,072\n",
            "       InPlaceABN-94         [-1, 1024, 16, 16]           2,048\n",
            "           Conv2d-95          [-1, 256, 32, 32]          32,768\n",
            "       InPlaceABN-96          [-1, 256, 32, 32]             512\n",
            "           Conv2d-97          [-1, 256, 32, 32]         589,824\n",
            "       InPlaceABN-98          [-1, 256, 32, 32]             512\n",
            "AntiAliasDownsampleLayer-99          [-1, 256, 16, 16]               0\n",
            "   FastAvgPool2d-100            [-1, 256, 1, 1]               0\n",
            "          Conv2d-101            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-102            [-1, 128, 1, 1]               0\n",
            "          Conv2d-103            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-104            [-1, 256, 1, 1]               0\n",
            "        SEModule-105          [-1, 256, 16, 16]               0\n",
            "          Conv2d-106         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-107         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-108         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-109         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-110          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-111          [-1, 256, 16, 16]             512\n",
            "          Conv2d-112          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-113          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-114            [-1, 256, 1, 1]               0\n",
            "          Conv2d-115            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-116            [-1, 128, 1, 1]               0\n",
            "          Conv2d-117            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-118            [-1, 256, 1, 1]               0\n",
            "        SEModule-119          [-1, 256, 16, 16]               0\n",
            "          Conv2d-120         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-121         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-122         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-123         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-124          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-125          [-1, 256, 16, 16]             512\n",
            "          Conv2d-126          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-127          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-128            [-1, 256, 1, 1]               0\n",
            "          Conv2d-129            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-130            [-1, 128, 1, 1]               0\n",
            "          Conv2d-131            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-132            [-1, 256, 1, 1]               0\n",
            "        SEModule-133          [-1, 256, 16, 16]               0\n",
            "          Conv2d-134         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-135         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-136         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-137         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-138          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-139          [-1, 256, 16, 16]             512\n",
            "          Conv2d-140          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-141          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-142            [-1, 256, 1, 1]               0\n",
            "          Conv2d-143            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-144            [-1, 128, 1, 1]               0\n",
            "          Conv2d-145            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-146            [-1, 256, 1, 1]               0\n",
            "        SEModule-147          [-1, 256, 16, 16]               0\n",
            "          Conv2d-148         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-149         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-150         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-151         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-152          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-153          [-1, 256, 16, 16]             512\n",
            "          Conv2d-154          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-155          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-156            [-1, 256, 1, 1]               0\n",
            "          Conv2d-157            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-158            [-1, 128, 1, 1]               0\n",
            "          Conv2d-159            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-160            [-1, 256, 1, 1]               0\n",
            "        SEModule-161          [-1, 256, 16, 16]               0\n",
            "          Conv2d-162         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-163         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-164         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-165         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-166          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-167          [-1, 256, 16, 16]             512\n",
            "          Conv2d-168          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-169          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-170            [-1, 256, 1, 1]               0\n",
            "          Conv2d-171            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-172            [-1, 128, 1, 1]               0\n",
            "          Conv2d-173            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-174            [-1, 256, 1, 1]               0\n",
            "        SEModule-175          [-1, 256, 16, 16]               0\n",
            "          Conv2d-176         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-177         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-178         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-179         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-180          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-181          [-1, 256, 16, 16]             512\n",
            "          Conv2d-182          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-183          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-184            [-1, 256, 1, 1]               0\n",
            "          Conv2d-185            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-186            [-1, 128, 1, 1]               0\n",
            "          Conv2d-187            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-188            [-1, 256, 1, 1]               0\n",
            "        SEModule-189          [-1, 256, 16, 16]               0\n",
            "          Conv2d-190         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-191         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-192         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-193         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-194          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-195          [-1, 256, 16, 16]             512\n",
            "          Conv2d-196          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-197          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-198            [-1, 256, 1, 1]               0\n",
            "          Conv2d-199            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-200            [-1, 128, 1, 1]               0\n",
            "          Conv2d-201            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-202            [-1, 256, 1, 1]               0\n",
            "        SEModule-203          [-1, 256, 16, 16]               0\n",
            "          Conv2d-204         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-205         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-206         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-207         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-208          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-209          [-1, 256, 16, 16]             512\n",
            "          Conv2d-210          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-211          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-212            [-1, 256, 1, 1]               0\n",
            "          Conv2d-213            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-214            [-1, 128, 1, 1]               0\n",
            "          Conv2d-215            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-216            [-1, 256, 1, 1]               0\n",
            "        SEModule-217          [-1, 256, 16, 16]               0\n",
            "          Conv2d-218         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-219         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-220         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-221         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-222          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-223          [-1, 256, 16, 16]             512\n",
            "          Conv2d-224          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-225          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-226            [-1, 256, 1, 1]               0\n",
            "          Conv2d-227            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-228            [-1, 128, 1, 1]               0\n",
            "          Conv2d-229            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-230            [-1, 256, 1, 1]               0\n",
            "        SEModule-231          [-1, 256, 16, 16]               0\n",
            "          Conv2d-232         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-233         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-234         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-235         [-1, 1024, 16, 16]               0\n",
            "          Conv2d-236          [-1, 256, 16, 16]         262,144\n",
            "      InPlaceABN-237          [-1, 256, 16, 16]             512\n",
            "          Conv2d-238          [-1, 256, 16, 16]         589,824\n",
            "      InPlaceABN-239          [-1, 256, 16, 16]             512\n",
            "   FastAvgPool2d-240            [-1, 256, 1, 1]               0\n",
            "          Conv2d-241            [-1, 128, 1, 1]          32,896\n",
            "            ReLU-242            [-1, 128, 1, 1]               0\n",
            "          Conv2d-243            [-1, 256, 1, 1]          33,024\n",
            "         Sigmoid-244            [-1, 256, 1, 1]               0\n",
            "        SEModule-245          [-1, 256, 16, 16]               0\n",
            "          Conv2d-246         [-1, 1024, 16, 16]         262,144\n",
            "      InPlaceABN-247         [-1, 1024, 16, 16]           2,048\n",
            "            ReLU-248         [-1, 1024, 16, 16]               0\n",
            "      Bottleneck-249         [-1, 1024, 16, 16]               0\n",
            "       AvgPool2d-250           [-1, 1024, 8, 8]               0\n",
            "          Conv2d-251           [-1, 2048, 8, 8]       2,097,152\n",
            "      InPlaceABN-252           [-1, 2048, 8, 8]           4,096\n",
            "          Conv2d-253          [-1, 512, 16, 16]         524,288\n",
            "      InPlaceABN-254          [-1, 512, 16, 16]           1,024\n",
            "          Conv2d-255          [-1, 512, 16, 16]       2,359,296\n",
            "      InPlaceABN-256          [-1, 512, 16, 16]           1,024\n",
            "AntiAliasDownsampleLayer-257            [-1, 512, 8, 8]               0\n",
            "          Conv2d-258           [-1, 2048, 8, 8]       1,048,576\n",
            "      InPlaceABN-259           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-260           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-261           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-262            [-1, 512, 8, 8]       1,048,576\n",
            "      InPlaceABN-263            [-1, 512, 8, 8]           1,024\n",
            "          Conv2d-264            [-1, 512, 8, 8]       2,359,296\n",
            "      InPlaceABN-265            [-1, 512, 8, 8]           1,024\n",
            "          Conv2d-266           [-1, 2048, 8, 8]       1,048,576\n",
            "      InPlaceABN-267           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-268           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-269           [-1, 2048, 8, 8]               0\n",
            "          Conv2d-270            [-1, 512, 8, 8]       1,048,576\n",
            "      InPlaceABN-271            [-1, 512, 8, 8]           1,024\n",
            "          Conv2d-272            [-1, 512, 8, 8]       2,359,296\n",
            "      InPlaceABN-273            [-1, 512, 8, 8]           1,024\n",
            "          Conv2d-274           [-1, 2048, 8, 8]       1,048,576\n",
            "      InPlaceABN-275           [-1, 2048, 8, 8]           4,096\n",
            "            ReLU-276           [-1, 2048, 8, 8]               0\n",
            "      Bottleneck-277           [-1, 2048, 8, 8]               0\n",
            "   FastAvgPool2d-278                 [-1, 2048]               0\n",
            "          Linear-279                   [-1, 26]          53,274\n",
            "================================================================\n",
            "Total params: 29,393,306\n",
            "Trainable params: 29,393,306\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 232.12\n",
            "Params size (MB): 112.13\n",
            "Estimated Total Size (MB): 345.00\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvHQtj7EMWGT"
      },
      "source": [
        "# Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e81_-1TERvYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51581ba5-cc80-4dce-e1fc-cce2e74ccf5b"
      },
      "source": [
        "import argparse\n",
        "import easydict\n",
        "import torch\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from torch.optim import lr_scheduler\n",
        "from src.helper_functions.helper_functions import mAP, CocoDetection, CutoutPIL, ModelEma, add_weight_decay\n",
        "from src.models import create_model\n",
        "from src.loss_functions.losses import AsymmetricLoss\n",
        "from randaugment import RandAugment\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "parser = argparse.ArgumentParser(description='PyTorch MS_COCO Training')\n",
        "parser.add_argument('data', metavar='DIR', help='path to dataset', default='../dirty_mnist')\n",
        "parser.add_argument('--lr', default=1e-4, type=float)\n",
        "parser.add_argument('--model-name', default='tresnet_m')\n",
        "parser.add_argument('--model-path', default='./tresnet_m.pth', type=str)\n",
        "parser.add_argument('--num-classes', default=26)\n",
        "parser.add_argument('-j', '--workers', default=4, type=int, metavar='N',\n",
        "                    help='number of data loading workers (default: 16)')\n",
        "parser.add_argument('--image-size', default=224, type=int,\n",
        "                    metavar='N', help='input image size (default: 448)')\n",
        "parser.add_argument('--thre', default=0.8, type=float,\n",
        "                    metavar='N', help='threshold value')\n",
        "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
        "                    metavar='N', help='mini-batch size (default: 16)')\n",
        "parser.add_argument('--print-freq', '-p', default=64, type=int,\n",
        "                    metavar='N', help='print frequency (default: 64)')\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = easydict.EasyDict({ \"data\": \"../dirty_mnist\", \n",
        "                              \"lr\": 23e-5, \n",
        "                              \"model_name\": \"tresnet_m\", \n",
        "                              \"model_path\": \"./tresnet_m.pth\",\n",
        "                              \"num_classes\": 26, \n",
        "                              \"workers\": 4, \n",
        "                              \"image_size\": 224, \n",
        "                              \"thre\": 0.8,\n",
        "                              \"batch_size\": 512,\n",
        "                              \"print_freq\": 64\n",
        "                              })\n",
        "    args.do_bottleneck_head = False\n",
        "\n",
        "    # Setup model\n",
        "    print('creating model...')\n",
        "    model = create_model(args).cuda()\n",
        "    if args.model_path:  # make sure to load pretrained ImageNet model\n",
        "        state = torch.load(args.model_path, map_location='cpu')\n",
        "        filtered_dict = {k: v for k, v in state['model'].items() if\n",
        "                         (k in model.state_dict() and 'head.fc' not in k)}\n",
        "        model.load_state_dict(filtered_dict, strict=False)\n",
        "    print('done\\n')\n",
        "\n",
        "    # COCO Data loading\n",
        "    instances_path_val = os.path.join(\"/content/drive/My Drive/dacon_cv\", 'val.json')\n",
        "    instances_path_train = os.path.join(\"/content/drive/My Drive/dacon_cv\", 'train.json')\n",
        "    # data_path_val = args.data\n",
        "    # data_path_train = args.data\n",
        "    data_path_val   = f'{args.data}/'    # args.data\n",
        "    data_path_train = f'{args.data}/'  # args.data\n",
        "    val_dataset = CocoDetection(data_path_val,\n",
        "                                instances_path_val,\n",
        "                                transforms.Compose([\n",
        "                                    transforms.Resize((args.image_size, args.image_size)),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    # normalize, # no need, toTensor does normalization\n",
        "                                ]))\n",
        "    train_dataset = CocoDetection(data_path_train,\n",
        "                                  instances_path_train,\n",
        "                                  transforms.Compose([\n",
        "                                      transforms.Resize((args.image_size, args.image_size)),\n",
        "                                      CutoutPIL(cutout_factor=0.5),\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomVerticalFlip(),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      # normalize,\n",
        "                                  ]))\n",
        "    print(\"len(val_dataset): \", len(val_dataset))\n",
        "    print(\"len(train_dataset): \", len(train_dataset))\n",
        "\n",
        "    # Pytorch Data loader\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "        num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "        num_workers=args.workers, pin_memory=False)\n",
        "\n",
        "    # Actuall Training\n",
        "    train_multi_label_coco(model, train_loader, val_loader, args.lr)\n",
        "\n",
        "\n",
        "def train_multi_label_coco(model, train_loader, val_loader, lr):\n",
        "    ema = ModelEma(model, 0.9997)  # 0.9997^641=0.82\n",
        "\n",
        "    # set optimizer\n",
        "    Epochs = 80\n",
        "    Stop_epoch = 40\n",
        "    weight_decay = 1e-4\n",
        "    criterion = AsymmetricLoss(gamma_neg=4, gamma_pos=1, clip=0.05)\n",
        "    parameters = add_weight_decay(model, weight_decay)\n",
        "    optimizer = torch.optim.Adam(params=parameters, lr=lr, weight_decay=0)  # true wd, filter_bias_and_bn\n",
        "    steps_per_epoch = len(train_loader)\n",
        "    scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=steps_per_epoch, epochs=Epochs,\n",
        "                                        pct_start=0.2)\n",
        "\n",
        "    highest_mAP = 0\n",
        "    trainInfoList = []\n",
        "    scaler = GradScaler()\n",
        "    for epoch in range(Epochs):\n",
        "        if epoch > Stop_epoch:\n",
        "          break\n",
        "        for i, (inputData, target) in enumerate(train_loader):\n",
        "            inputData = inputData.cuda()\n",
        "            target = target.cuda()  # (batch,3,num_classes)\n",
        "            target = target.max(dim=1)[0]\n",
        "            with autocast():  # mixed precision\n",
        "                output = model(inputData).float()  # sigmoid will be done in loss !\n",
        "            loss = criterion(output, target)\n",
        "            model.zero_grad()\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            # loss.backward()\n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            # optimizer.step()\n",
        "\n",
        "            scheduler.step()\n",
        "\n",
        "            ema.update(model)\n",
        "            # store information\n",
        "            if i % 50 == 0:\n",
        "                trainInfoList.append([epoch, i, loss.item()])\n",
        "                print('Epoch [{}/{}], Step [{}/{}], LR {:.1e}, Loss: {:.1f}'\n",
        "                      .format(epoch, Epochs, str(i).zfill(3), str(steps_per_epoch).zfill(3),\n",
        "                              scheduler.get_last_lr()[0], \\\n",
        "                              loss.item()))\n",
        "\n",
        "        try:\n",
        "            torch.save(model.state_dict(), os.path.join(\n",
        "                'model_hard_set/', 'model-{}-{}.pth'.format(epoch + 1, i + 1)))\n",
        "        except:\n",
        "            print(\"model per epoch is not being saved.\")\n",
        "            pass\n",
        "\n",
        "        model.eval()\n",
        "        mAP_score = validate_multi(val_loader, model, ema)\n",
        "        model.train()\n",
        "        if mAP_score > highest_mAP:\n",
        "            highest_mAP = mAP_score\n",
        "            try:\n",
        "                torch.save(model.state_dict(), os.path.join(\n",
        "                    'model_hard_set/', 'model-highest.pth'))\n",
        "            except:\n",
        "                print(\"best model is not being saved.\")\n",
        "                pass\n",
        "        print('current_mAP = {:.2f}, highest_mAP = {:.2f}\\n'.format(mAP_score, highest_mAP))\n",
        "\n",
        "\n",
        "def validate_multi(val_loader, model, ema_model):\n",
        "    print(\"starting validation\")\n",
        "    Sig = torch.nn.Sigmoid()\n",
        "    preds_regular = []\n",
        "    preds_ema = []\n",
        "    targets = []\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        target = target\n",
        "        target = target.max(dim=1)[0]\n",
        "        # compute output\n",
        "        with torch.no_grad():\n",
        "            with autocast():\n",
        "                output_regular = Sig(model(input.cuda())).cpu()\n",
        "                output_ema = Sig(ema_model.module(input.cuda())).cpu()\n",
        "\n",
        "        # for mAP calculation\n",
        "        preds_regular.append(output_regular.cpu().detach())\n",
        "        preds_ema.append(output_ema.cpu().detach())\n",
        "        targets.append(target.cpu().detach())\n",
        "\n",
        "    mAP_score_regular = mAP(torch.cat(targets).numpy(), torch.cat(preds_regular).numpy())\n",
        "    mAP_score_ema = mAP(torch.cat(targets).numpy(), torch.cat(preds_ema).numpy())\n",
        "    print(\"mAP score regular {:.2f}, mAP score EMA {:.2f}\".format(mAP_score_regular, mAP_score_ema))\n",
        "    return max(mAP_score_regular, mAP_score_ema)\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating model...\n",
            "done\n",
            "\n",
            "loading annotations into memory...\n",
            "Done (t=0.19s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=2.63s)\n",
            "creating index...\n",
            "index created!\n",
            "len(val_dataset):  5000\n",
            "len(train_dataset):  45000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/80], Step [000/088], LR 9.2e-06, Loss: 2355.5\n",
            "Epoch [0/80], Step [050/088], LR 9.9e-06, Loss: 1945.8\n",
            "starting validation\n",
            "mAP score regular 46.59, mAP score EMA 45.93\n",
            "current_mAP = 46.59, highest_mAP = 46.59\n",
            "\n",
            "Epoch [1/80], Step [000/088], LR 1.1e-05, Loss: 1818.6\n",
            "Epoch [1/80], Step [050/088], LR 1.4e-05, Loss: 1797.8\n",
            "starting validation\n",
            "mAP score regular 47.10, mAP score EMA 45.95\n",
            "current_mAP = 47.10, highest_mAP = 47.10\n",
            "\n",
            "Epoch [2/80], Step [000/088], LR 1.8e-05, Loss: 1783.8\n",
            "Epoch [2/80], Step [050/088], LR 2.3e-05, Loss: 1766.3\n",
            "starting validation\n",
            "mAP score regular 47.88, mAP score EMA 46.00\n",
            "current_mAP = 47.88, highest_mAP = 47.88\n",
            "\n",
            "Epoch [3/80], Step [000/088], LR 2.8e-05, Loss: 1764.4\n",
            "Epoch [3/80], Step [050/088], LR 3.5e-05, Loss: 1752.2\n",
            "starting validation\n",
            "mAP score regular 49.13, mAP score EMA 46.05\n",
            "current_mAP = 49.13, highest_mAP = 49.13\n",
            "\n",
            "Epoch [4/80], Step [000/088], LR 4.2e-05, Loss: 1751.1\n",
            "Epoch [4/80], Step [050/088], LR 5.1e-05, Loss: 1751.8\n",
            "starting validation\n",
            "mAP score regular 50.55, mAP score EMA 46.11\n",
            "current_mAP = 50.55, highest_mAP = 50.55\n",
            "\n",
            "Epoch [5/80], Step [000/088], LR 5.9e-05, Loss: 1742.1\n",
            "Epoch [5/80], Step [050/088], LR 6.9e-05, Loss: 1743.5\n",
            "starting validation\n",
            "mAP score regular 52.15, mAP score EMA 46.19\n",
            "current_mAP = 52.15, highest_mAP = 52.15\n",
            "\n",
            "Epoch [6/80], Step [000/088], LR 7.8e-05, Loss: 1737.0\n",
            "Epoch [6/80], Step [050/088], LR 8.9e-05, Loss: 1727.9\n",
            "starting validation\n",
            "mAP score regular 54.60, mAP score EMA 46.29\n",
            "current_mAP = 54.60, highest_mAP = 54.60\n",
            "\n",
            "Epoch [7/80], Step [000/088], LR 9.8e-05, Loss: 1720.0\n",
            "Epoch [7/80], Step [050/088], LR 1.1e-04, Loss: 1711.6\n",
            "starting validation\n",
            "mAP score regular 57.20, mAP score EMA 46.41\n",
            "current_mAP = 57.20, highest_mAP = 57.20\n",
            "\n",
            "Epoch [8/80], Step [000/088], LR 1.2e-04, Loss: 1712.9\n",
            "Epoch [8/80], Step [050/088], LR 1.3e-04, Loss: 1700.3\n",
            "starting validation\n",
            "mAP score regular 60.25, mAP score EMA 46.55\n",
            "current_mAP = 60.25, highest_mAP = 60.25\n",
            "\n",
            "Epoch [9/80], Step [000/088], LR 1.4e-04, Loss: 1685.1\n",
            "Epoch [9/80], Step [050/088], LR 1.5e-04, Loss: 1681.0\n",
            "starting validation\n",
            "mAP score regular 63.41, mAP score EMA 46.69\n",
            "current_mAP = 63.41, highest_mAP = 63.41\n",
            "\n",
            "Epoch [10/80], Step [000/088], LR 1.6e-04, Loss: 1664.7\n",
            "Epoch [10/80], Step [050/088], LR 1.7e-04, Loss: 1642.7\n",
            "starting validation\n",
            "mAP score regular 66.23, mAP score EMA 46.87\n",
            "current_mAP = 66.23, highest_mAP = 66.23\n",
            "\n",
            "Epoch [11/80], Step [000/088], LR 1.8e-04, Loss: 1617.1\n",
            "Epoch [11/80], Step [050/088], LR 1.9e-04, Loss: 1619.4\n",
            "starting validation\n",
            "mAP score regular 69.05, mAP score EMA 47.09\n",
            "current_mAP = 69.05, highest_mAP = 69.05\n",
            "\n",
            "Epoch [12/80], Step [000/088], LR 2.0e-04, Loss: 1604.3\n",
            "Epoch [12/80], Step [050/088], LR 2.1e-04, Loss: 1583.6\n",
            "starting validation\n",
            "mAP score regular 71.45, mAP score EMA 47.34\n",
            "current_mAP = 71.45, highest_mAP = 71.45\n",
            "\n",
            "Epoch [13/80], Step [000/088], LR 2.1e-04, Loss: 1568.9\n",
            "Epoch [13/80], Step [050/088], LR 2.2e-04, Loss: 1557.8\n",
            "starting validation\n",
            "mAP score regular 73.35, mAP score EMA 47.63\n",
            "current_mAP = 73.35, highest_mAP = 73.35\n",
            "\n",
            "Epoch [14/80], Step [000/088], LR 2.2e-04, Loss: 1543.6\n",
            "Epoch [14/80], Step [050/088], LR 2.3e-04, Loss: 1516.7\n",
            "starting validation\n",
            "mAP score regular 75.28, mAP score EMA 47.96\n",
            "current_mAP = 75.28, highest_mAP = 75.28\n",
            "\n",
            "Epoch [15/80], Step [000/088], LR 2.3e-04, Loss: 1497.5\n",
            "Epoch [15/80], Step [050/088], LR 2.3e-04, Loss: 1508.5\n",
            "starting validation\n",
            "mAP score regular 77.06, mAP score EMA 48.34\n",
            "current_mAP = 77.06, highest_mAP = 77.06\n",
            "\n",
            "Epoch [16/80], Step [000/088], LR 2.3e-04, Loss: 1475.0\n",
            "Epoch [16/80], Step [050/088], LR 2.3e-04, Loss: 1470.4\n",
            "starting validation\n",
            "mAP score regular 78.29, mAP score EMA 48.78\n",
            "current_mAP = 78.29, highest_mAP = 78.29\n",
            "\n",
            "Epoch [17/80], Step [000/088], LR 2.3e-04, Loss: 1433.8\n",
            "Epoch [17/80], Step [050/088], LR 2.3e-04, Loss: 1430.2\n",
            "starting validation\n",
            "mAP score regular 79.22, mAP score EMA 49.27\n",
            "current_mAP = 79.22, highest_mAP = 79.22\n",
            "\n",
            "Epoch [18/80], Step [000/088], LR 2.3e-04, Loss: 1423.6\n",
            "Epoch [18/80], Step [050/088], LR 2.3e-04, Loss: 1420.3\n",
            "starting validation\n",
            "mAP score regular 80.38, mAP score EMA 49.80\n",
            "current_mAP = 80.38, highest_mAP = 80.38\n",
            "\n",
            "Epoch [19/80], Step [000/088], LR 2.3e-04, Loss: 1397.8\n",
            "Epoch [19/80], Step [050/088], LR 2.3e-04, Loss: 1375.7\n",
            "starting validation\n",
            "mAP score regular 81.35, mAP score EMA 50.37\n",
            "current_mAP = 81.35, highest_mAP = 81.35\n",
            "\n",
            "Epoch [20/80], Step [000/088], LR 2.3e-04, Loss: 1359.3\n",
            "Epoch [20/80], Step [050/088], LR 2.3e-04, Loss: 1382.9\n",
            "starting validation\n",
            "mAP score regular 81.69, mAP score EMA 50.98\n",
            "current_mAP = 81.69, highest_mAP = 81.69\n",
            "\n",
            "Epoch [21/80], Step [000/088], LR 2.3e-04, Loss: 1350.6\n",
            "Epoch [21/80], Step [050/088], LR 2.3e-04, Loss: 1344.4\n",
            "starting validation\n",
            "mAP score regular 82.36, mAP score EMA 51.62\n",
            "current_mAP = 82.36, highest_mAP = 82.36\n",
            "\n",
            "Epoch [22/80], Step [000/088], LR 2.3e-04, Loss: 1336.2\n",
            "Epoch [22/80], Step [050/088], LR 2.2e-04, Loss: 1340.3\n",
            "starting validation\n",
            "mAP score regular 82.95, mAP score EMA 52.30\n",
            "current_mAP = 82.95, highest_mAP = 82.95\n",
            "\n",
            "Epoch [23/80], Step [000/088], LR 2.2e-04, Loss: 1315.4\n",
            "Epoch [23/80], Step [050/088], LR 2.2e-04, Loss: 1304.0\n",
            "starting validation\n",
            "mAP score regular 83.20, mAP score EMA 53.01\n",
            "current_mAP = 83.20, highest_mAP = 83.20\n",
            "\n",
            "Epoch [24/80], Step [000/088], LR 2.2e-04, Loss: 1279.0\n",
            "Epoch [24/80], Step [050/088], LR 2.2e-04, Loss: 1282.9\n",
            "starting validation\n",
            "mAP score regular 83.43, mAP score EMA 53.74\n",
            "current_mAP = 83.43, highest_mAP = 83.43\n",
            "\n",
            "Epoch [25/80], Step [000/088], LR 2.2e-04, Loss: 1244.7\n",
            "Epoch [25/80], Step [050/088], LR 2.2e-04, Loss: 1257.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2epbDaOaMY9g"
      },
      "source": [
        "# Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdyoJQrXVefV",
        "outputId": "56681c80-1ba0-4602-db3c-233bdf303e87"
      },
      "source": [
        "!rm -rf test_dirty_mnist/\n",
        "!mkdir test_dirty_mnist/\n",
        "!unzip -q test_dirty_mnist_2nd.zip -d test_dirty_mnist/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'제_2회 컴퓨터 비전 학습 경진대회 베이스라인 코드.ipynb'\n",
            " ASL\n",
            " converT2coco.ipynb\n",
            " dirty_mnist\n",
            " dirty_mnist_2nd_answer.csv\n",
            " dirty_mnist_2nd.zip\n",
            " dirty_mnist_answer.csv\n",
            " dirty_mnist.zip\n",
            " mnist_data\n",
            " sample_submission.csv\n",
            " test_dirty_mnist\n",
            " test_dirty_mnist_2nd.zip\n",
            " test.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyupVaLHt8L1",
        "outputId": "d2476d01-3cfb-4504-d1ed-ee44bd7e4991"
      },
      "source": [
        "import torch\n",
        "from src.helper_functions.helper_functions import mAP, CocoDetection, CutoutPIL, ModelEma, add_weight_decay\n",
        "from src.loss_functions.losses import AsymmetricLoss, AsymmetricLossOptimized\n",
        "import torchvision.transforms as transforms\n",
        "from src.models import create_model\n",
        "import argparse\n",
        "import easydict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# parsing args\n",
        "args = easydict.EasyDict({ \"model_path\": \"/content/drive/My Drive/dacon_cv/ASL/model_hard_set/model-highest.pth\",\n",
        "                          \"model_name\": \"tresnet_m\",\n",
        "                          \"workers\": 4, \n",
        "                          \"dataset_type\": \"MS-COCO\", \n",
        "                          \"th\": 0.8,\n",
        "                          \"num_classes\": 26\n",
        "                          })\n",
        "instances_path_test = '/content/drive/My Drive/dacon_cv/test.json'\n",
        "data_path_test = '/content/drive/My Drive/dacon_cv/test_dirty_mnist'\n",
        "test_dataset = CocoDetection(data_path_test,\n",
        "                            instances_path_test,\n",
        "                            transforms.Compose([\n",
        "                                transforms.Resize((224, 224)),\n",
        "                                transforms.ToTensor(),\n",
        "                            ]))\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=128, shuffle=False,\n",
        "    num_workers=4, pin_memory=True, drop_last=False)\n",
        "\n",
        "predictions_list = []\n",
        "# 배치 단위로 추론\n",
        "prediction_df = pd.read_csv(\"/content/drive/My Drive/dacon_cv/sample_submission.csv\")\n",
        "prediction_array = np.zeros([prediction_df.shape[0],\n",
        "                            prediction_df.shape[1]- 1])\n",
        "\n",
        "\n",
        "                    \n",
        "print(\"test dset: \", test_dataset)\n",
        "\n",
        "# setup model\n",
        "print('creating and loading the model...')\n",
        "state = torch.load(args.model_path, map_location='cpu')\n",
        "model = create_model(args).cuda()\n",
        "model.load_state_dict(state, strict=True)\n",
        "for idx, sample in enumerate(test_data_loader):\n",
        "    with torch.no_grad():\n",
        "        # 추론\n",
        "        model.eval()\n",
        "        images = sample[0].cuda()\n",
        "        probs  = model(images)\n",
        "        probs = probs.cpu().detach().numpy()\n",
        "        preds = (probs > 0.8)\n",
        "\n",
        "        # 예측 결과를 \n",
        "        # prediction_array에 입력\n",
        "        batch_index = 128 * idx\n",
        "        prediction_array[batch_index: batch_index + images.shape[0],:] = preds.astype(int)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.47s)\n",
            "creating index...\n",
            "index created!\n",
            "test dset:  Dataset CocoDetection\n",
            "    Number of datapoints: 5000\n",
            "    Root location: /content/drive/My Drive/dacon_cv/test_dirty_mnist\n",
            "creating and loading the model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "qAfZbq4s4FPS",
        "outputId": "b1cf7f66-e1f7-43f1-c3da-45adfc381c43"
      },
      "source": [
        "sample_submission = pd.read_csv(\"/content/drive/My Drive/dacon_cv/sample_submission.csv\")\n",
        "sample_submission.iloc[:,1:] = prediction_array\n",
        "sample_submission = sample_submission.astype('int32')\n",
        "sample_submission.to_csv(\"prediction_hard_set_8.csv\", index = False)\n",
        "sample_submission"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>f</th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "      <th>i</th>\n",
              "      <th>j</th>\n",
              "      <th>k</th>\n",
              "      <th>l</th>\n",
              "      <th>m</th>\n",
              "      <th>n</th>\n",
              "      <th>o</th>\n",
              "      <th>p</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>t</th>\n",
              "      <th>u</th>\n",
              "      <th>v</th>\n",
              "      <th>w</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50001</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>54995</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>54996</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>54997</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>54998</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>54999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n",
              "0     50000  1  0  0  1  0  1  0  1  0  0  ...  0  0  0  0  1  1  0  0  1  0  1\n",
              "1     50001  0  1  0  0  1  0  0  0  0  1  ...  1  0  1  0  0  1  1  0  0  0  0\n",
              "2     50002  0  0  0  0  1  0  1  0  1  0  ...  1  0  0  1  0  1  0  1  0  0  1\n",
              "3     50003  1  1  0  0  0  1  1  0  0  0  ...  0  1  0  0  0  0  0  0  1  0  1\n",
              "4     50004  0  0  1  0  1  1  0  0  0  0  ...  0  1  0  1  1  0  0  1  0  0  0\n",
              "...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n",
              "4995  54995  0  0  1  0  0  1  0  1  0  1  ...  0  0  0  0  1  0  0  1  0  1  0\n",
              "4996  54996  1  0  1  0  0  1  1  0  0  1  ...  0  0  0  0  0  0  0  0  0  0  1\n",
              "4997  54997  1  0  0  1  0  1  0  0  0  1  ...  0  0  0  0  0  1  1  1  0  0  1\n",
              "4998  54998  0  0  1  0  0  1  0  0  1  1  ...  0  1  1  0  0  0  0  1  0  0  1\n",
              "4999  54999  1  1  0  0  0  0  0  0  1  0  ...  0  0  0  1  0  0  0  1  1  1  1\n",
              "\n",
              "[5000 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}