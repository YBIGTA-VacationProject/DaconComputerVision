{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "resnext.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "699388612fde42019b2c0fa731ac8c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3379615672c44e98be890340dbb1bceb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5f6a85a22644404192ce52fa75c65834",
              "IPY_MODEL_25f34e4aef9641ecb7af33add7527757"
            ]
          }
        },
        "3379615672c44e98be890340dbb1bceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f6a85a22644404192ce52fa75c65834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14528c8062394dc581eb2e0834b90d90",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 100441675,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 100441675,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_563133b26bf94844b48dbe7c92cb817e"
          }
        },
        "25f34e4aef9641ecb7af33add7527757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d9faf21d53194d019ba5e42f3134b300",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 95.8M/95.8M [03:57&lt;00:00, 423kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f50407d425e443fb1d8fef66efd845a"
          }
        },
        "14528c8062394dc581eb2e0834b90d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "563133b26bf94844b48dbe7c92cb817e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9faf21d53194d019ba5e42f3134b300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f50407d425e443fb1d8fef66efd845a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcGqZqS5LajM"
      },
      "source": [
        "# 데이터 준비\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "954WxGTSkddB",
        "outputId": "92d49f21-0fd1-4849-b517-451d94095939"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_lA5C3cXTq4",
        "outputId": "278fda41-7066-4a76-cc13-a556f5661682"
      },
      "source": [
        "%cd /content/drive/MyDrive/dacon_cv\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/dacon_cv\n",
            "'제_2회 컴퓨터 비전 학습 경진대회 베이스라인 코드.ipynb'\n",
            " ASL\n",
            " converT2coco.ipynb\n",
            " dirty_mnist_2nd_answer.csv\n",
            " dirty_mnist_2nd.zip\n",
            " dirty_mnist_answer.csv\n",
            " dirty_mnist.zip\n",
            " mnist_data\n",
            " prediction.csv\n",
            " sample_submission.csv\n",
            " test_dirty_mnist\n",
            " test_dirty_mnist_2nd.zip\n",
            " test.json\n",
            " train.json\n",
            " val.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh6s6z70awqp",
        "outputId": "9d8e4b59-0d12-4ba8-937b-a67915086bc6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Feb 26 02:10:17 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR9wN2cPdPED"
      },
      "source": [
        "import os\n",
        "len(os.listdir(\"./dirty_mnist/\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzrC9J3OGrK2",
        "outputId": "e0990749-7478-4c95-fcb9-f5383dcfc3c8"
      },
      "source": [
        "!rm -rf dirty_mnist/ \n",
        "!mkdir dirty_mnist/\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'제_2회 컴퓨터 비전 학습 경진대회 베이스라인 코드.ipynb'\n",
            " ASL\n",
            " converT2coco.ipynb\n",
            " dirty_mnist_2nd_answer.csv\n",
            " dirty_mnist_2nd.zip\n",
            " dirty_mnist_answer.csv\n",
            " dirty_mnist.zip\n",
            " mnist_data\n",
            " prediction.csv\n",
            " sample_submission.csv\n",
            " test_dirty_mnist\n",
            " test_dirty_mnist_2nd.zip\n",
            " test.json\n",
            " train.json\n",
            " val.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaMcfTqyL6M6",
        "outputId": "7ae88851-7cac-40a9-d04b-673c9abc001e"
      },
      "source": [
        "!unzip -q dirty_mnist_2nd.zip -d dirty_mnist/\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'제_2회 컴퓨터 비전 학습 경진대회 베이스라인 코드.ipynb'\n",
            " ASL\n",
            " converT2coco.ipynb\n",
            " dirty_mnist\n",
            " dirty_mnist_2nd_answer.csv\n",
            " dirty_mnist_2nd.zip\n",
            " dirty_mnist_answer.csv\n",
            " dirty_mnist.zip\n",
            " mnist_data\n",
            " prediction.csv\n",
            " sample_submission.csv\n",
            " test_dirty_mnist\n",
            " test_dirty_mnist_2nd.zip\n",
            " test.json\n",
            " train.json\n",
            " val.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfqh0xNecbND"
      },
      "source": [
        "!rm -rf dirty_mnist/dirty_mnist_train/"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qddEGp0bgHs"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import os\n",
        "import json"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0mr5L08blTk"
      },
      "source": [
        "namelist = os.listdir('./dirty_mnist/')\n",
        "answer = pd.read_csv('dirty_mnist_answer.csv')\n",
        "train, val = train_test_split(namelist, test_size=0.1, random_state=23)\n",
        "train_num = [int(t[:5]) for t in train]\n",
        "val_num = [int(v[:5]) for v in val]\n",
        "train_ohe = [True if i in train_num else False for i in range(50000)]\n",
        "val_ohe = [True if i in val_num else False for i in range(50000)]\n",
        "train_ans = answer[train_ohe]\n",
        "val_ans = answer[val_ohe]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PJ30bSobxn6"
      },
      "source": [
        "%cd ./dirty_mnist/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afbyD31jb0Fc"
      },
      "source": [
        "os.makedirs('./dirty_mnist_train', exist_ok=True)\n",
        "os.makedirs('./dirty_mnist_val', exist_ok=True)\n",
        "for t in train:\n",
        "    shutil.move(t, './dirty_mnist_train')\n",
        "for v in val:\n",
        "    shutil.move(v, './dirty_mnist_val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOtC7LJLb01c"
      },
      "source": [
        "def csv_to_coco(df, json_name):\n",
        "    dic = {\n",
        "        \"info\": {\n",
        "            \"description\": \"DACON DIRTY MNIST DATASET\",\n",
        "            \"url\": \"https://oranz.tistory.com/\",\n",
        "            \"version\": \"1.0\",\n",
        "            \"year\": 2021,\n",
        "            \"contributor\": \"DACON\",\n",
        "            \"date_created\": \"2021/02/18\"\n",
        "        },\n",
        "        \"licenses\": [{\n",
        "            \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\",\n",
        "            \"id\": 1,\n",
        "            \"name\": \"Attribution-NonCommercial-ShareAlike License\"\n",
        "        }],\n",
        "        \"images\": [],\n",
        "        \"annotations\": [],\n",
        "        \"categories\": []\n",
        "    }\n",
        "    \n",
        "    for i in range(1, 27):\n",
        "        dic[\"categories\"].append({\"supercategory\": \"alphabet\", \"id\": i, \"name\": chr(i + 96)})\n",
        "        \n",
        "    anno_id = 1\n",
        "    for r in range(len(df)):\n",
        "        image_id = int(df.iloc[r, 0]) # cast to int for JSON serialization\n",
        "        name = str(image_id)\n",
        "        name = '0' * (5 - len(name)) + name + '.png'\n",
        "        dic[\"images\"].append({\n",
        "            \"license\": 1,\n",
        "            \"file_name\": name,\n",
        "            \"coco_url\": \"\",\n",
        "            \"height\": 256,\n",
        "            \"width\": 256,\n",
        "            \"date_captured\": \"2020-05-19 23:03:57\",\n",
        "            \"flickr_url\": \"\",\n",
        "            \"id\": image_id\n",
        "        })\n",
        "        \n",
        "        for c in range(1, 27):\n",
        "            if df.iloc[r, c] == 1:\n",
        "                dic[\"annotations\"].append({\n",
        "                    \"segmentation\": [],\n",
        "                    \"area\": 232,\n",
        "                    \"iscrowd\": 0,\n",
        "                    \"image_id\": image_id,\n",
        "                    \"bbox\": [1, 5, 4, 9],\n",
        "                    \"category_id\": c,\n",
        "                    \"id\": anno_id\n",
        "                })\n",
        "                anno_id += 1\n",
        "    with open(json_name, \"w\") as json_file:\n",
        "        json.dump(dic, json_file)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8HXplx1b5me"
      },
      "source": [
        "csv_to_coco(val_ans, \"val.json\")\n",
        "csv_to_coco(train_ans, \"train.json\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWVMb5BKLjY9"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tODw8jcRq6G",
        "outputId": "b0c9471a-e177-4fc3-d958-5f5f4c98487a"
      },
      "source": [
        "!pip install inplace-abn\n",
        "!pip install randaugment"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting inplace-abn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/27/c5791febcdd9af346b66dff19759898476f148177c02b02a72e07ca8aba0/inplace-abn-1.1.0.tar.gz (137kB)\n",
            "\r\u001b[K     |██▍                             | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 20kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 61kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 102kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 112kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 122kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 133kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 7.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: inplace-abn\n",
            "  Building wheel for inplace-abn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for inplace-abn: filename=inplace_abn-1.1.0-cp37-cp37m-linux_x86_64.whl size=2754614 sha256=06e9537d5d0fe656de669d606c26cc200730cc6a1b9504363099977e86e2a2c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/e6/ce/baadcff0441c600caa5874d4d3322a7909e724fb7abab21a15\n",
            "Successfully built inplace-abn\n",
            "Installing collected packages: inplace-abn\n",
            "Successfully installed inplace-abn-1.1.0\n",
            "Collecting randaugment\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/ea/e24549f459800dc3bed21cd4e9c0d49d5b8deed65214b2444bd3e5a49f30/randaugment-1.0.2-py3-none-any.whl\n",
            "Installing collected packages: randaugment\n",
            "Successfully installed randaugment-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETxrEs5Nd6uz",
        "outputId": "9f072d7d-9d96-49b8-aa72-fd5af2e08be3"
      },
      "source": [
        "%cd ./ASL/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/dacon_cv/ASL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "699388612fde42019b2c0fa731ac8c0b",
            "3379615672c44e98be890340dbb1bceb",
            "5f6a85a22644404192ce52fa75c65834",
            "25f34e4aef9641ecb7af33add7527757",
            "14528c8062394dc581eb2e0834b90d90",
            "563133b26bf94844b48dbe7c92cb817e",
            "d9faf21d53194d019ba5e42f3134b300",
            "9f50407d425e443fb1d8fef66efd845a"
          ]
        },
        "id": "4zzaB243YF4D",
        "outputId": "7d70bccb-1cb8-4b29-fa09-ce6713b894d6"
      },
      "source": [
        "import argparse\n",
        "import easydict\n",
        "import torch\n",
        "import torch.nn.parallel\n",
        "import torch.optim\n",
        "import torch.utils.data.distributed\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from torch.optim import lr_scheduler\n",
        "from src.helper_functions.helper_functions import mAP, CocoDetection, CutoutPIL, ModelEma, add_weight_decay\n",
        "from src.models import create_model\n",
        "from src.loss_functions.losses import AsymmetricLoss\n",
        "from randaugment import RandAugment\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import imutils\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "from typing import Tuple, Sequence, Callable\n",
        "import glob\n",
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "resnext = torch.hub.load('pytorch/vision:v0.6.0', 'resnext50_32x4d', pretrained=True)\n",
        "\n",
        "class Resnext(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Resnext, self).__init__()\n",
        "        self.resnext = resnext \n",
        "        self.FC = nn.Linear(1000, 26)\n",
        "        nn.init.xavier_normal_(self.FC.weight)\n",
        "      \n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnext(x)\n",
        "        x = torch.sigmoid(self.FC(x))\n",
        "        return x\n",
        "\n",
        "model = Resnext()\n",
        "model"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /root/.cache/torch/hub/v0.6.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\" to /root/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "699388612fde42019b2c0fa731ac8c0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=100441675.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Resnext(\n",
              "  (resnext): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              "  )\n",
              "  (FC): Linear(in_features=1000, out_features=26, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KKn-mxktZGJj",
        "outputId": "48899bf5-942c-499d-b3b7-00ff4f2281cc"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = Resnext().to(device)\n",
        "\n",
        "args = easydict.EasyDict({ \"data\": \"../dirty_mnist\", \n",
        "                          \"num_classes\": 26, \n",
        "                          \"workers\": 4, \n",
        "                          \"image_size\": 224, \n",
        "                          \"thre\": 0.8,\n",
        "                          \"batch_size\": 128,\n",
        "                          \"print_freq\": 64\n",
        "                          })\n",
        "args.do_bottleneck_head = False\n",
        "\n",
        "def validate_multi(val_loader, model):\n",
        "    print(\"starting validation\")\n",
        "    Sig = torch.nn.Sigmoid()\n",
        "    preds_regular = []\n",
        "    targets = []\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        target = target\n",
        "        target = target.max(dim=1)[0]\n",
        "        # compute output\n",
        "        with torch.no_grad():\n",
        "            with autocast():\n",
        "                output_regular = Sig(model(input.cuda())).cpu()\n",
        "\n",
        "        # for mAP calculation\n",
        "        preds_regular.append(output_regular.cpu().detach())\n",
        "        targets.append(target.cpu().detach())\n",
        "\n",
        "    mAP_score_regular = mAP(torch.cat(targets).numpy(), torch.cat(preds_regular).numpy())\n",
        "    print(\"mAP score regular {:.2f}\".format(mAP_score_regular))\n",
        "    return mAP_score_regular\n",
        "\n",
        "\n",
        "# COCO Data loading\n",
        "instances_path_val = os.path.join(\"/content/drive/My Drive/dacon_cv\", 'val.json')\n",
        "instances_path_train = os.path.join(\"/content/drive/My Drive/dacon_cv\", 'train.json')\n",
        "data_path_val   = f'{args.data}/'    # args.data\n",
        "data_path_train = f'{args.data}/'  # args.data\n",
        "val_dataset = CocoDetection(data_path_val,\n",
        "                            instances_path_val,\n",
        "                            transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                # normalize, # no need, toTensor does normalization\n",
        "                            ]))\n",
        "train_dataset = CocoDetection(data_path_train,\n",
        "                              instances_path_train,\n",
        "                              transforms.Compose([\n",
        "                                  CutoutPIL(cutout_factor=0.5),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.RandomVerticalFlip(),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  # normalize,\n",
        "                              ]))\n",
        "print(\"len(val_dataset): \", len(val_dataset))\n",
        "print(\"len(train_dataset): \", len(train_dataset))\n",
        "\n",
        "# Pytorch Data loader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=args.batch_size, shuffle=True,\n",
        "    num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "    num_workers=args.workers, pin_memory=False)\n",
        "\n",
        "\n",
        "Epochs=30\n",
        "batch_size=64 \n",
        "lr = 23e-5\n",
        "weight_decay = 1e-7\n",
        "criterion = AsymmetricLoss(gamma_neg=4, gamma_pos=1, clip=0.05)\n",
        "parameters = add_weight_decay(model, weight_decay)\n",
        "optimizer = torch.optim.Adam(params=parameters, lr=lr, weight_decay=0)  # true wd, filter_bias_and_bn\n",
        "steps_per_epoch = len(train_loader)\n",
        "scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=lr, steps_per_epoch=steps_per_epoch, epochs=Epochs,\n",
        "                                    pct_start=0.2)\n",
        "\n",
        "highest_mAP = 0\n",
        "trainInfoList = []\n",
        "scaler = GradScaler()\n",
        "\n",
        "for epoch in range(Epochs):\n",
        "  for i, (inputData, target) in enumerate(train_loader):\n",
        "      inputData = inputData.cuda()\n",
        "      target = target.cuda()  # (batch,3,num_classes)\n",
        "      target = target.max(dim=1)[0]\n",
        "      with autocast():  # mixed precision\n",
        "          output = model(inputData).float()  # sigmoid will be done in loss !\n",
        "      loss = criterion(output, target)\n",
        "      model.zero_grad()\n",
        "\n",
        "      scaler.scale(loss).backward()\n",
        "      # loss.backward()\n",
        "\n",
        "      scaler.step(optimizer)\n",
        "      scaler.update()\n",
        "      # optimizer.step()\n",
        "\n",
        "      scheduler.step()\n",
        "\n",
        "      # store information\n",
        "      if i % 100 == 0:\n",
        "          trainInfoList.append([epoch, i, loss.item()])\n",
        "          print('Epoch [{}/{}], Step [{}/{}], LR {:.1e}, Loss: {:.1f}'\n",
        "                .format(epoch, Epochs, str(i).zfill(3), str(steps_per_epoch).zfill(3),\n",
        "                        scheduler.get_last_lr()[0], \\\n",
        "                        loss.item()))\n",
        "\n",
        "  try:\n",
        "      torch.save(model.state_dict(), os.path.join(\n",
        "          'resnext_asl/', 'model-{}-{}.pth'.format(epoch + 1, i + 1)))\n",
        "  except:\n",
        "      print(\"model per epoch is not being saved.\")\n",
        "      pass\n",
        "\n",
        "  model.eval()\n",
        "  mAP_score = validate_multi(val_loader, model)\n",
        "  model.train()\n",
        "  if mAP_score > highest_mAP:\n",
        "      highest_mAP = mAP_score\n",
        "      try:\n",
        "          torch.save(model.state_dict(), os.path.join(\n",
        "              'resnext_asl/', 'model-highest.pth'))\n",
        "      except:\n",
        "          print(\"best model is not being saved.\")\n",
        "          pass\n",
        "  print('current_mAP = {:.2f}, highest_mAP = {:.2f}\\n'.format(mAP_score, highest_mAP))\n",
        "\n",
        "\n",
        "def validate_multi(val_loader, model):\n",
        "    print(\"starting validation\")\n",
        "    Sig = torch.nn.Sigmoid()\n",
        "    preds_regular = []\n",
        "    targets = []\n",
        "    for i, (input, target) in enumerate(val_loader):\n",
        "        target = target\n",
        "        target = target.max(dim=1)[0]\n",
        "        # compute output\n",
        "        with torch.no_grad():\n",
        "            with autocast():\n",
        "                output_regular = Sig(model(input.cuda())).cpu()\n",
        "\n",
        "        # for mAP calculation\n",
        "        preds_regular.append(output_regular.cpu().detach())\n",
        "        targets.append(target.cpu().detach())\n",
        "\n",
        "    mAP_score_regular = mAP(torch.cat(targets).numpy(), torch.cat(preds_regular).numpy())\n",
        "    print(\"mAP score regular {:.2f}\".format(mAP_score_regular))\n",
        "    return mAP_score_regular\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.15s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=2.34s)\n",
            "creating index...\n",
            "index created!\n",
            "len(val_dataset):  5000\n",
            "len(train_dataset):  45000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/30], Step [000/352], LR 9.2e-06, Loss: 489.7\n",
            "Epoch [0/30], Step [100/352], LR 1.0e-05, Loss: 452.1\n",
            "Epoch [0/30], Step [200/352], LR 1.4e-05, Loss: 440.2\n",
            "Epoch [0/30], Step [300/352], LR 2.0e-05, Loss: 439.7\n",
            "starting validation\n",
            "mAP score regular 49.73\n",
            "current_mAP = 49.73, highest_mAP = 49.73\n",
            "\n",
            "Epoch [1/30], Step [000/352], LR 2.4e-05, Loss: 438.4\n",
            "Epoch [1/30], Step [100/352], LR 3.3e-05, Loss: 439.0\n",
            "Epoch [1/30], Step [200/352], LR 4.5e-05, Loss: 439.3\n",
            "Epoch [1/30], Step [300/352], LR 5.7e-05, Loss: 432.7\n",
            "starting validation\n",
            "mAP score regular 54.86\n",
            "current_mAP = 54.86, highest_mAP = 54.86\n",
            "\n",
            "Epoch [2/30], Step [000/352], LR 6.5e-05, Loss: 432.9\n",
            "Epoch [2/30], Step [100/352], LR 7.9e-05, Loss: 428.3\n",
            "Epoch [2/30], Step [200/352], LR 9.5e-05, Loss: 429.0\n",
            "Epoch [2/30], Step [300/352], LR 1.1e-04, Loss: 424.2\n",
            "starting validation\n",
            "mAP score regular 61.49\n",
            "current_mAP = 61.49, highest_mAP = 61.49\n",
            "\n",
            "Epoch [3/30], Step [000/352], LR 1.2e-04, Loss: 423.6\n",
            "Epoch [3/30], Step [100/352], LR 1.4e-04, Loss: 423.9\n",
            "Epoch [3/30], Step [200/352], LR 1.5e-04, Loss: 419.9\n",
            "Epoch [3/30], Step [300/352], LR 1.7e-04, Loss: 414.5\n",
            "starting validation\n",
            "mAP score regular 67.65\n",
            "current_mAP = 67.65, highest_mAP = 67.65\n",
            "\n",
            "Epoch [4/30], Step [000/352], LR 1.8e-04, Loss: 415.6\n",
            "Epoch [4/30], Step [100/352], LR 1.9e-04, Loss: 402.4\n",
            "Epoch [4/30], Step [200/352], LR 2.0e-04, Loss: 410.6\n",
            "Epoch [4/30], Step [300/352], LR 2.1e-04, Loss: 408.3\n",
            "starting validation\n",
            "mAP score regular 73.38\n",
            "current_mAP = 73.38, highest_mAP = 73.38\n",
            "\n",
            "Epoch [5/30], Step [000/352], LR 2.2e-04, Loss: 402.3\n",
            "Epoch [5/30], Step [100/352], LR 2.2e-04, Loss: 400.9\n",
            "Epoch [5/30], Step [200/352], LR 2.3e-04, Loss: 396.5\n",
            "Epoch [5/30], Step [300/352], LR 2.3e-04, Loss: 387.6\n",
            "starting validation\n",
            "mAP score regular 72.72\n",
            "current_mAP = 72.72, highest_mAP = 73.38\n",
            "\n",
            "Epoch [6/30], Step [000/352], LR 2.3e-04, Loss: 387.3\n",
            "Epoch [6/30], Step [100/352], LR 2.3e-04, Loss: 388.7\n",
            "Epoch [6/30], Step [200/352], LR 2.3e-04, Loss: 384.8\n",
            "Epoch [6/30], Step [300/352], LR 2.3e-04, Loss: 387.1\n",
            "starting validation\n",
            "mAP score regular 80.52\n",
            "current_mAP = 80.52, highest_mAP = 80.52\n",
            "\n",
            "Epoch [7/30], Step [000/352], LR 2.3e-04, Loss: 379.7\n",
            "Epoch [7/30], Step [100/352], LR 2.3e-04, Loss: 376.0\n",
            "Epoch [7/30], Step [200/352], LR 2.3e-04, Loss: 375.9\n",
            "Epoch [7/30], Step [300/352], LR 2.3e-04, Loss: 382.3\n",
            "starting validation\n",
            "mAP score regular 82.64\n",
            "current_mAP = 82.64, highest_mAP = 82.64\n",
            "\n",
            "Epoch [8/30], Step [000/352], LR 2.3e-04, Loss: 374.8\n",
            "Epoch [8/30], Step [100/352], LR 2.2e-04, Loss: 371.9\n",
            "Epoch [8/30], Step [200/352], LR 2.2e-04, Loss: 369.2\n",
            "Epoch [8/30], Step [300/352], LR 2.2e-04, Loss: 368.0\n",
            "starting validation\n",
            "mAP score regular 84.22\n",
            "current_mAP = 84.22, highest_mAP = 84.22\n",
            "\n",
            "Epoch [9/30], Step [000/352], LR 2.2e-04, Loss: 360.6\n",
            "Epoch [9/30], Step [100/352], LR 2.2e-04, Loss: 356.4\n",
            "Epoch [9/30], Step [200/352], LR 2.2e-04, Loss: 359.3\n",
            "Epoch [9/30], Step [300/352], LR 2.2e-04, Loss: 360.6\n",
            "starting validation\n",
            "mAP score regular 84.75\n",
            "current_mAP = 84.75, highest_mAP = 84.75\n",
            "\n",
            "Epoch [10/30], Step [000/352], LR 2.1e-04, Loss: 353.8\n",
            "Epoch [10/30], Step [100/352], LR 2.1e-04, Loss: 352.4\n",
            "Epoch [10/30], Step [200/352], LR 2.1e-04, Loss: 355.3\n",
            "Epoch [10/30], Step [300/352], LR 2.1e-04, Loss: 354.7\n",
            "starting validation\n",
            "mAP score regular 86.49\n",
            "current_mAP = 86.49, highest_mAP = 86.49\n",
            "\n",
            "Epoch [11/30], Step [000/352], LR 2.1e-04, Loss: 348.6\n",
            "Epoch [11/30], Step [100/352], LR 2.0e-04, Loss: 355.6\n",
            "Epoch [11/30], Step [200/352], LR 2.0e-04, Loss: 352.4\n",
            "Epoch [11/30], Step [300/352], LR 2.0e-04, Loss: 344.4\n",
            "starting validation\n",
            "mAP score regular 86.87\n",
            "current_mAP = 86.87, highest_mAP = 86.87\n",
            "\n",
            "Epoch [12/30], Step [000/352], LR 2.0e-04, Loss: 344.4\n",
            "Epoch [12/30], Step [100/352], LR 1.9e-04, Loss: 354.9\n",
            "Epoch [12/30], Step [200/352], LR 1.9e-04, Loss: 342.8\n",
            "Epoch [12/30], Step [300/352], LR 1.9e-04, Loss: 346.0\n",
            "starting validation\n",
            "mAP score regular 88.14\n",
            "current_mAP = 88.14, highest_mAP = 88.14\n",
            "\n",
            "Epoch [13/30], Step [000/352], LR 1.8e-04, Loss: 341.8\n",
            "Epoch [13/30], Step [100/352], LR 1.8e-04, Loss: 346.9\n",
            "Epoch [13/30], Step [200/352], LR 1.8e-04, Loss: 337.5\n",
            "Epoch [13/30], Step [300/352], LR 1.7e-04, Loss: 346.4\n",
            "starting validation\n",
            "mAP score regular 88.76\n",
            "current_mAP = 88.76, highest_mAP = 88.76\n",
            "\n",
            "Epoch [14/30], Step [000/352], LR 1.7e-04, Loss: 343.6\n",
            "Epoch [14/30], Step [100/352], LR 1.7e-04, Loss: 343.3\n",
            "Epoch [14/30], Step [200/352], LR 1.6e-04, Loss: 332.0\n",
            "Epoch [14/30], Step [300/352], LR 1.6e-04, Loss: 344.1\n",
            "starting validation\n",
            "mAP score regular 89.12\n",
            "current_mAP = 89.12, highest_mAP = 89.12\n",
            "\n",
            "Epoch [15/30], Step [000/352], LR 1.6e-04, Loss: 331.0\n",
            "Epoch [15/30], Step [100/352], LR 1.5e-04, Loss: 334.2\n",
            "Epoch [15/30], Step [200/352], LR 1.5e-04, Loss: 325.3\n",
            "Epoch [15/30], Step [300/352], LR 1.5e-04, Loss: 328.6\n",
            "starting validation\n",
            "mAP score regular 89.85\n",
            "current_mAP = 89.85, highest_mAP = 89.85\n",
            "\n",
            "Epoch [16/30], Step [000/352], LR 1.4e-04, Loss: 333.3\n",
            "Epoch [16/30], Step [100/352], LR 1.4e-04, Loss: 335.5\n",
            "Epoch [16/30], Step [200/352], LR 1.4e-04, Loss: 333.1\n",
            "Epoch [16/30], Step [300/352], LR 1.3e-04, Loss: 333.5\n",
            "starting validation\n",
            "mAP score regular 90.38\n",
            "current_mAP = 90.38, highest_mAP = 90.38\n",
            "\n",
            "Epoch [17/30], Step [000/352], LR 1.3e-04, Loss: 322.9\n",
            "Epoch [17/30], Step [100/352], LR 1.3e-04, Loss: 331.7\n",
            "Epoch [17/30], Step [200/352], LR 1.2e-04, Loss: 321.7\n",
            "Epoch [17/30], Step [300/352], LR 1.2e-04, Loss: 331.4\n",
            "starting validation\n",
            "mAP score regular 90.77\n",
            "current_mAP = 90.77, highest_mAP = 90.77\n",
            "\n",
            "Epoch [18/30], Step [000/352], LR 1.1e-04, Loss: 316.6\n",
            "Epoch [18/30], Step [100/352], LR 1.1e-04, Loss: 320.0\n",
            "Epoch [18/30], Step [200/352], LR 1.1e-04, Loss: 320.1\n",
            "Epoch [18/30], Step [300/352], LR 1.0e-04, Loss: 326.5\n",
            "starting validation\n",
            "mAP score regular 90.85\n",
            "current_mAP = 90.85, highest_mAP = 90.85\n",
            "\n",
            "Epoch [19/30], Step [000/352], LR 1.0e-04, Loss: 316.9\n",
            "Epoch [19/30], Step [100/352], LR 9.6e-05, Loss: 320.9\n",
            "Epoch [19/30], Step [200/352], LR 9.1e-05, Loss: 326.0\n",
            "Epoch [19/30], Step [300/352], LR 8.7e-05, Loss: 321.5\n",
            "starting validation\n",
            "mAP score regular 90.91\n",
            "current_mAP = 90.91, highest_mAP = 90.91\n",
            "\n",
            "Epoch [20/30], Step [000/352], LR 8.5e-05, Loss: 315.4\n",
            "Epoch [20/30], Step [100/352], LR 8.1e-05, Loss: 312.1\n",
            "Epoch [20/30], Step [200/352], LR 7.7e-05, Loss: 313.5\n",
            "Epoch [20/30], Step [300/352], LR 7.3e-05, Loss: 322.8\n",
            "starting validation\n",
            "mAP score regular 91.06\n",
            "current_mAP = 91.06, highest_mAP = 91.06\n",
            "\n",
            "Epoch [21/30], Step [000/352], LR 7.1e-05, Loss: 310.5\n",
            "Epoch [21/30], Step [100/352], LR 6.7e-05, Loss: 314.6\n",
            "Epoch [21/30], Step [200/352], LR 6.3e-05, Loss: 303.8\n",
            "Epoch [21/30], Step [300/352], LR 5.9e-05, Loss: 319.0\n",
            "starting validation\n",
            "mAP score regular 91.17\n",
            "current_mAP = 91.17, highest_mAP = 91.17\n",
            "\n",
            "Epoch [22/30], Step [000/352], LR 5.7e-05, Loss: 309.7\n",
            "Epoch [22/30], Step [100/352], LR 5.4e-05, Loss: 309.3\n",
            "Epoch [22/30], Step [200/352], LR 5.0e-05, Loss: 304.8\n",
            "Epoch [22/30], Step [300/352], LR 4.7e-05, Loss: 312.2\n",
            "starting validation\n",
            "mAP score regular 91.16\n",
            "current_mAP = 91.16, highest_mAP = 91.17\n",
            "\n",
            "Epoch [23/30], Step [000/352], LR 4.5e-05, Loss: 308.0\n",
            "Epoch [23/30], Step [100/352], LR 4.2e-05, Loss: 313.3\n",
            "Epoch [23/30], Step [200/352], LR 3.8e-05, Loss: 299.5\n",
            "Epoch [23/30], Step [300/352], LR 3.5e-05, Loss: 306.9\n",
            "starting validation\n",
            "mAP score regular 90.89\n",
            "current_mAP = 90.89, highest_mAP = 91.17\n",
            "\n",
            "Epoch [24/30], Step [000/352], LR 3.4e-05, Loss: 295.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-a78ac8bfe11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m       \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m       \u001b[0;31m# loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WORhhGH9Lx0y"
      },
      "source": [
        "# Test\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdyoJQrXVefV",
        "outputId": "56681c80-1ba0-4602-db3c-233bdf303e87"
      },
      "source": [
        "!rm -rf test_dirty_mnist/\n",
        "!mkdir test_dirty_mnist/\n",
        "!unzip -q test_dirty_mnist_2nd.zip -d test_dirty_mnist/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'제_2회 컴퓨터 비전 학습 경진대회 베이스라인 코드.ipynb'\n",
            " ASL\n",
            " converT2coco.ipynb\n",
            " dirty_mnist\n",
            " dirty_mnist_2nd_answer.csv\n",
            " dirty_mnist_2nd.zip\n",
            " dirty_mnist_answer.csv\n",
            " dirty_mnist.zip\n",
            " mnist_data\n",
            " sample_submission.csv\n",
            " test_dirty_mnist\n",
            " test_dirty_mnist_2nd.zip\n",
            " test.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyupVaLHt8L1",
        "outputId": "75c58e75-48fe-41db-e692-246c7df5a5ef"
      },
      "source": [
        "import torch\n",
        "from src.helper_functions.helper_functions import mAP, CocoDetection, CutoutPIL, ModelEma, add_weight_decay\n",
        "from src.loss_functions.losses import AsymmetricLoss, AsymmetricLossOptimized\n",
        "import torchvision.transforms as transforms\n",
        "from src.models import create_model\n",
        "import argparse\n",
        "import easydict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# parsing args\n",
        "args = easydict.EasyDict({ \"model_path\": \"/content/drive/My Drive/dacon_cv/ASL/resnext_asl/model-highest.pth\",\n",
        "                          \"model_name\": \"resnext_asl\",\n",
        "                          \"workers\": 4, \n",
        "                          \"dataset_type\": \"MS-COCO\", \n",
        "                          \"th\": 0.8,\n",
        "                          \"num_classes\": 26\n",
        "                          })\n",
        "instances_path_test = '/content/drive/My Drive/dacon_cv/test.json'\n",
        "data_path_test = '/content/drive/My Drive/dacon_cv/test_dirty_mnist'\n",
        "test_dataset = CocoDetection(data_path_test,\n",
        "                            instances_path_test,\n",
        "                            transforms.Compose([\n",
        "                                #transforms.Resize((224, 224)),\n",
        "                                transforms.ToTensor()\n",
        "                            ]))\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=128, shuffle=False,\n",
        "    num_workers=4, pin_memory=True, drop_last=False)\n",
        "\n",
        "predictions_list = []\n",
        "# 배치 단위로 추론\n",
        "prediction_df = pd.read_csv(\"/content/drive/My Drive/dacon_cv/sample_submission.csv\")\n",
        "prediction_array = np.zeros([prediction_df.shape[0],\n",
        "                            prediction_df.shape[1]- 1])\n",
        "\n",
        "\n",
        "                    \n",
        "print(\"test dset: \", test_dataset)\n",
        "\n",
        "# setup model\n",
        "print('creating and loading the model...')\n",
        "model = Resnext().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/dacon_cv/ASL/resnext_asl/model-highest.pth\", map_location='cpu'))\n",
        "for idx, sample in enumerate(test_data_loader):\n",
        "    with torch.no_grad():\n",
        "        # 추론\n",
        "        model.eval()\n",
        "        images = sample[0].cuda()\n",
        "        probs  = model(images)\n",
        "        probs = probs.cpu().detach().numpy()\n",
        "        preds = (probs > 0.5)\n",
        "\n",
        "        # 예측 결과를 \n",
        "        # prediction_array에 입력\n",
        "        batch_index = 128 * idx\n",
        "        prediction_array[batch_index: batch_index + images.shape[0],:] = preds.astype(int)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n",
            "test dset:  Dataset CocoDetection\n",
            "    Number of datapoints: 5000\n",
            "    Root location: /content/drive/My Drive/dacon_cv/test_dirty_mnist\n",
            "creating and loading the model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YtHL8Zss_bj-",
        "outputId": "730bf206-6203-4dbe-9d0c-7ab046dc23c6"
      },
      "source": [
        "sample_submission = pd.read_csv(\"/content/drive/My Drive/dacon_cv/sample_submission.csv\")\n",
        "sample_submission.iloc[:,1:] = prediction_array\n",
        "sample_submission = sample_submission.astype('int32')\n",
        "sample_submission.to_csv(\"resnext_asl_5.csv\", index = False)\n",
        "sample_submission"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>f</th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "      <th>i</th>\n",
              "      <th>j</th>\n",
              "      <th>k</th>\n",
              "      <th>l</th>\n",
              "      <th>m</th>\n",
              "      <th>n</th>\n",
              "      <th>o</th>\n",
              "      <th>p</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>t</th>\n",
              "      <th>u</th>\n",
              "      <th>v</th>\n",
              "      <th>w</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50001</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>54995</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>54996</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>54997</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>54998</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>54999</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n",
              "0     50000  1  0  1  0  1  1  0  1  1  0  ...  1  0  0  0  1  1  0  0  1  0  1\n",
              "1     50001  0  1  1  0  1  0  0  0  1  1  ...  1  1  1  0  0  1  1  0  0  1  1\n",
              "2     50002  0  0  0  1  1  0  1  0  1  1  ...  1  0  1  1  0  1  0  1  0  0  1\n",
              "3     50003  1  1  0  1  0  0  1  0  1  0  ...  1  1  0  0  1  0  1  0  1  1  1\n",
              "4     50004  0  0  1  0  1  1  0  0  0  0  ...  0  1  0  1  1  1  1  0  0  0  0\n",
              "...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n",
              "4995  54995  0  0  1  0  0  0  0  1  0  0  ...  0  0  0  0  1  0  0  1  0  1  0\n",
              "4996  54996  1  0  1  0  1  0  0  0  1  1  ...  1  1  0  1  0  0  0  0  1  0  1\n",
              "4997  54997  1  0  0  1  0  1  0  0  0  1  ...  1  0  0  0  1  1  1  1  0  0  1\n",
              "4998  54998  0  0  1  0  0  0  1  0  1  1  ...  0  1  1  0  1  0  0  1  0  0  1\n",
              "4999  54999  1  1  0  0  0  1  0  0  1  0  ...  0  1  0  1  0  0  1  1  1  1  1\n",
              "\n",
              "[5000 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}