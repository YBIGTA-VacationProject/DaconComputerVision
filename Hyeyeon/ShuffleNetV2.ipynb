{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[2/22] shufflenetv2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "797a928c165b4ba4918d208eff02b248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5c39e32454a54f4eb6b98badc4f5e7ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8647c605df1244f7ad888bf4e4b9fb92",
              "IPY_MODEL_a3dab6090a104a7a9e1687f55b09d0b4"
            ]
          }
        },
        "5c39e32454a54f4eb6b98badc4f5e7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8647c605df1244f7ad888bf4e4b9fb92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8b04cd5332994c86ba85d32736c2d428",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5538128,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5538128,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c22b659a5ecb46e6a374e15a7b61f851"
          }
        },
        "a3dab6090a104a7a9e1687f55b09d0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7c767d513a3c41e79236ffb8da7966fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5.28M/5.28M [00:00&lt;00:00, 47.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7da2b88b00994915a2fbc7a8e49f0988"
          }
        },
        "8b04cd5332994c86ba85d32736c2d428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c22b659a5ecb46e6a374e15a7b61f851": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7c767d513a3c41e79236ffb8da7966fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7da2b88b00994915a2fbc7a8e49f0988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR55u0LvgTok",
        "outputId": "f5d481f0-15a9-4e6d-bb94-bbaef5bfb905"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\\"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_8ITlgigZ2g"
      },
      "source": [
        "from google.colab import output\n",
        "# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\n",
        "!cp -r \"/content/drive/MyDrive/21-1/data\" \"data\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAESTs9rhsit"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import imutils\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "from typing import Tuple, Sequence, Callable\n",
        "import glob\n",
        "from sklearn.model_selection import KFold\n",
        "import time\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from google.colab import output\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 디바이스 설정"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIV4iRXYgi4D"
      },
      "source": [
        "os.chdir('/content/data')\n",
        "\n",
        "from google.colab import output\n",
        "# 현재 디렉터리에 dirty_mnist라는 폴더 생성\n",
        "!mkdir \"./dirty_mnist_2nd\"\n",
        "#dirty_mnist.zip라는 zip파일을 dirty_mnist라는 폴더에 압축 풀기\n",
        "!unzip \"dirty_mnist_2nd.zip\" -d \"./dirty_mnist_2nd/\"\n",
        "# 현재 디렉터리에 test_dirty_mnist라는 폴더 생성\n",
        "!mkdir \"./test_dirty_mnist_2nd\"\n",
        "#test_dirty_mnist.zip라는 zip파일을 test_dirty_mnist라는 폴더에 압축 풀기\n",
        "!unzip \"test_dirty_mnist_2nd.zip\" -d \"./test_dirty_mnist_2nd/\"\n",
        "# 출력 결과 지우기\n",
        "output.clear()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k_l1VEpplBL"
      },
      "source": [
        "os.chdir('/content/data')\n",
        "labels_df = pd.read_csv('dirty_mnist_2nd_answer.csv')[:]\n",
        "imgs_dir = np.array(sorted(glob.glob('/content/data/dirty_mnist_2nd/*')))[:]\n",
        "labels = np.array(labels_df.values[:,1:])\n",
        "test_imgs_dir = np.array(sorted(glob.glob('/content/data/test_dirty_mnist_2nd/*')))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "YYrRP8izpk9N",
        "outputId": "1b62cb94-aff6-462d-a0a9-c7b59fa3e3fb"
      },
      "source": [
        "labels_df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>f</th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "      <th>i</th>\n",
              "      <th>j</th>\n",
              "      <th>k</th>\n",
              "      <th>l</th>\n",
              "      <th>m</th>\n",
              "      <th>n</th>\n",
              "      <th>o</th>\n",
              "      <th>p</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>t</th>\n",
              "      <th>u</th>\n",
              "      <th>v</th>\n",
              "      <th>w</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>49995</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>49996</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>49997</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>49998</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>49999</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n",
              "0          0  1  1  0  1  0  1  0  0  0  0  ...  1  0  1  1  0  1  0  0  1  1  1\n",
              "1          1  1  0  0  1  0  1  0  1  0  1  ...  1  0  1  0  1  0  0  0  0  1  1\n",
              "2          2  0  0  0  0  0  0  0  0  1  1  ...  1  0  0  1  1  1  0  1  1  1  0\n",
              "3          3  0  0  1  0  0  0  1  1  0  0  ...  1  1  0  1  1  0  1  1  0  1  0\n",
              "4          4  0  1  0  1  0  1  0  1  1  0  ...  1  0  1  0  0  0  1  0  1  0  0\n",
              "...      ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n",
              "49995  49995  0  1  1  0  0  0  0  1  0  0  ...  0  0  0  0  1  0  0  0  1  1  0\n",
              "49996  49996  0  1  0  1  0  1  1  1  0  1  ...  0  0  1  1  1  0  1  0  0  0  1\n",
              "49997  49997  0  1  0  0  1  1  1  1  0  0  ...  0  1  0  0  0  0  1  1  1  0  0\n",
              "49998  49998  0  1  1  1  0  0  1  1  0  1  ...  0  0  1  1  1  0  0  0  1  0  0\n",
              "49999  49999  1  0  1  0  0  0  0  0  0  1  ...  1  0  1  1  0  1  1  0  1  0  0\n",
              "\n",
              "[50000 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9-gTZFwpk45",
        "outputId": "f02c6167-8749-437c-f229-abd3393d4acd"
      },
      "source": [
        "imgs_dir"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/content/data/dirty_mnist_2nd/00000.png',\n",
              "       '/content/data/dirty_mnist_2nd/00001.png',\n",
              "       '/content/data/dirty_mnist_2nd/00002.png', ...,\n",
              "       '/content/data/dirty_mnist_2nd/49997.png',\n",
              "       '/content/data/dirty_mnist_2nd/49998.png',\n",
              "       '/content/data/dirty_mnist_2nd/49999.png'], dtype='<U39')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_v7l7Ccpk0D",
        "outputId": "6dfb0ec6-d37b-4e58-c6cd-91c11c3570a1"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX8YEfrGpkvz"
      },
      "source": [
        "class MnistDataset_v1(Dataset):\n",
        "    def __init__(self, imgs_dir=None, labels=None, transform=None, train=True):\n",
        "        self.imgs_dir = imgs_dir\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        # 데이터 총 샘플 수\n",
        "        return len(self.imgs_dir)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 1개 샘플 get\n",
        "        img = cv2.imread(self.imgs_dir[idx], cv2.IMREAD_COLOR)\n",
        "        img = self.transform(img)\n",
        "        if self.train==True:\n",
        "            label = self.labels[idx]\n",
        "            return img, label\n",
        "        else:\n",
        "            return img\n",
        "        \n",
        "        pass"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "797a928c165b4ba4918d208eff02b248",
            "5c39e32454a54f4eb6b98badc4f5e7ab",
            "8647c605df1244f7ad888bf4e4b9fb92",
            "a3dab6090a104a7a9e1687f55b09d0b4",
            "8b04cd5332994c86ba85d32736c2d428",
            "c22b659a5ecb46e6a374e15a7b61f851",
            "7c767d513a3c41e79236ffb8da7966fe",
            "7da2b88b00994915a2fbc7a8e49f0988"
          ]
        },
        "id": "2fC4Lnzbs9a8",
        "outputId": "8a4ad9ce-2e44-409e-942e-3f7661415ba1"
      },
      "source": [
        "#shuffle = torch.hub.load('pytorch/vision:v0.6.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
        "shuffle = torch.hub.load('pytorch/vision:v0.6.0', 'shufflenet_v2_x0_5', pretrained=True)\n",
        "\n",
        "class my_Shuffle(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(my_Shuffle, self).__init__()\n",
        "        self.shuffle = shuffle \n",
        "        self.FC = nn.Linear(1000, 26)\n",
        "        nn.init.xavier_normal_(self.FC.weight)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        x = self.shuffle(x)\n",
        "        x = torch.sigmoid(self.FC(x))\n",
        "        return x\n",
        "\n",
        "model = my_Shuffle()\n",
        "from torchsummary import summary\n",
        "model.to(device)\n",
        "summary(model,(3,256,256))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.6.0.zip\" to /root/.cache/torch/hub/v0.6.0.zip\n",
            "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x0.5-f707e7126e.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x0.5-f707e7126e.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "797a928c165b4ba4918d208eff02b248",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5538128.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 24, 128, 128]             648\n",
            "       BatchNorm2d-2         [-1, 24, 128, 128]              48\n",
            "              ReLU-3         [-1, 24, 128, 128]               0\n",
            "         MaxPool2d-4           [-1, 24, 64, 64]               0\n",
            "            Conv2d-5           [-1, 24, 32, 32]             216\n",
            "       BatchNorm2d-6           [-1, 24, 32, 32]              48\n",
            "            Conv2d-7           [-1, 24, 32, 32]             576\n",
            "       BatchNorm2d-8           [-1, 24, 32, 32]              48\n",
            "              ReLU-9           [-1, 24, 32, 32]               0\n",
            "           Conv2d-10           [-1, 24, 64, 64]             576\n",
            "      BatchNorm2d-11           [-1, 24, 64, 64]              48\n",
            "             ReLU-12           [-1, 24, 64, 64]               0\n",
            "           Conv2d-13           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-14           [-1, 24, 32, 32]              48\n",
            "           Conv2d-15           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-16           [-1, 24, 32, 32]              48\n",
            "             ReLU-17           [-1, 24, 32, 32]               0\n",
            " InvertedResidual-18           [-1, 48, 32, 32]               0\n",
            "           Conv2d-19           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-20           [-1, 24, 32, 32]              48\n",
            "             ReLU-21           [-1, 24, 32, 32]               0\n",
            "           Conv2d-22           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-23           [-1, 24, 32, 32]              48\n",
            "           Conv2d-24           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-25           [-1, 24, 32, 32]              48\n",
            "             ReLU-26           [-1, 24, 32, 32]               0\n",
            " InvertedResidual-27           [-1, 48, 32, 32]               0\n",
            "           Conv2d-28           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-29           [-1, 24, 32, 32]              48\n",
            "             ReLU-30           [-1, 24, 32, 32]               0\n",
            "           Conv2d-31           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-32           [-1, 24, 32, 32]              48\n",
            "           Conv2d-33           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-34           [-1, 24, 32, 32]              48\n",
            "             ReLU-35           [-1, 24, 32, 32]               0\n",
            " InvertedResidual-36           [-1, 48, 32, 32]               0\n",
            "           Conv2d-37           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-38           [-1, 24, 32, 32]              48\n",
            "             ReLU-39           [-1, 24, 32, 32]               0\n",
            "           Conv2d-40           [-1, 24, 32, 32]             216\n",
            "      BatchNorm2d-41           [-1, 24, 32, 32]              48\n",
            "           Conv2d-42           [-1, 24, 32, 32]             576\n",
            "      BatchNorm2d-43           [-1, 24, 32, 32]              48\n",
            "             ReLU-44           [-1, 24, 32, 32]               0\n",
            " InvertedResidual-45           [-1, 48, 32, 32]               0\n",
            "           Conv2d-46           [-1, 48, 16, 16]             432\n",
            "      BatchNorm2d-47           [-1, 48, 16, 16]              96\n",
            "           Conv2d-48           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-49           [-1, 48, 16, 16]              96\n",
            "             ReLU-50           [-1, 48, 16, 16]               0\n",
            "           Conv2d-51           [-1, 48, 32, 32]           2,304\n",
            "      BatchNorm2d-52           [-1, 48, 32, 32]              96\n",
            "             ReLU-53           [-1, 48, 32, 32]               0\n",
            "           Conv2d-54           [-1, 48, 16, 16]             432\n",
            "      BatchNorm2d-55           [-1, 48, 16, 16]              96\n",
            "           Conv2d-56           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-57           [-1, 48, 16, 16]              96\n",
            "             ReLU-58           [-1, 48, 16, 16]               0\n",
            " InvertedResidual-59           [-1, 96, 16, 16]               0\n",
            "           Conv2d-60           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-61           [-1, 48, 16, 16]              96\n",
            "             ReLU-62           [-1, 48, 16, 16]               0\n",
            "           Conv2d-63           [-1, 48, 16, 16]             432\n",
            "      BatchNorm2d-64           [-1, 48, 16, 16]              96\n",
            "           Conv2d-65           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-66           [-1, 48, 16, 16]              96\n",
            "             ReLU-67           [-1, 48, 16, 16]               0\n",
            " InvertedResidual-68           [-1, 96, 16, 16]               0\n",
            "           Conv2d-69           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-70           [-1, 48, 16, 16]              96\n",
            "             ReLU-71           [-1, 48, 16, 16]               0\n",
            "           Conv2d-72           [-1, 48, 16, 16]             432\n",
            "      BatchNorm2d-73           [-1, 48, 16, 16]              96\n",
            "           Conv2d-74           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-75           [-1, 48, 16, 16]              96\n",
            "             ReLU-76           [-1, 48, 16, 16]               0\n",
            " InvertedResidual-77           [-1, 96, 16, 16]               0\n",
            "           Conv2d-78           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-79           [-1, 48, 16, 16]              96\n",
            "             ReLU-80           [-1, 48, 16, 16]               0\n",
            "           Conv2d-81           [-1, 48, 16, 16]             432\n",
            "      BatchNorm2d-82           [-1, 48, 16, 16]              96\n",
            "           Conv2d-83           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-84           [-1, 48, 16, 16]              96\n",
            "             ReLU-85           [-1, 48, 16, 16]               0\n",
            " InvertedResidual-86           [-1, 96, 16, 16]               0\n",
            "           Conv2d-87           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-88           [-1, 48, 16, 16]              96\n",
            "             ReLU-89           [-1, 48, 16, 16]               0\n",
            "           Conv2d-90           [-1, 48, 16, 16]             432\n",
            "      BatchNorm2d-91           [-1, 48, 16, 16]              96\n",
            "           Conv2d-92           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-93           [-1, 48, 16, 16]              96\n",
            "             ReLU-94           [-1, 48, 16, 16]               0\n",
            " InvertedResidual-95           [-1, 96, 16, 16]               0\n",
            "           Conv2d-96           [-1, 48, 16, 16]           2,304\n",
            "      BatchNorm2d-97           [-1, 48, 16, 16]              96\n",
            "             ReLU-98           [-1, 48, 16, 16]               0\n",
            "           Conv2d-99           [-1, 48, 16, 16]             432\n",
            "     BatchNorm2d-100           [-1, 48, 16, 16]              96\n",
            "          Conv2d-101           [-1, 48, 16, 16]           2,304\n",
            "     BatchNorm2d-102           [-1, 48, 16, 16]              96\n",
            "            ReLU-103           [-1, 48, 16, 16]               0\n",
            "InvertedResidual-104           [-1, 96, 16, 16]               0\n",
            "          Conv2d-105           [-1, 48, 16, 16]           2,304\n",
            "     BatchNorm2d-106           [-1, 48, 16, 16]              96\n",
            "            ReLU-107           [-1, 48, 16, 16]               0\n",
            "          Conv2d-108           [-1, 48, 16, 16]             432\n",
            "     BatchNorm2d-109           [-1, 48, 16, 16]              96\n",
            "          Conv2d-110           [-1, 48, 16, 16]           2,304\n",
            "     BatchNorm2d-111           [-1, 48, 16, 16]              96\n",
            "            ReLU-112           [-1, 48, 16, 16]               0\n",
            "InvertedResidual-113           [-1, 96, 16, 16]               0\n",
            "          Conv2d-114           [-1, 48, 16, 16]           2,304\n",
            "     BatchNorm2d-115           [-1, 48, 16, 16]              96\n",
            "            ReLU-116           [-1, 48, 16, 16]               0\n",
            "          Conv2d-117           [-1, 48, 16, 16]             432\n",
            "     BatchNorm2d-118           [-1, 48, 16, 16]              96\n",
            "          Conv2d-119           [-1, 48, 16, 16]           2,304\n",
            "     BatchNorm2d-120           [-1, 48, 16, 16]              96\n",
            "            ReLU-121           [-1, 48, 16, 16]               0\n",
            "InvertedResidual-122           [-1, 96, 16, 16]               0\n",
            "          Conv2d-123             [-1, 96, 8, 8]             864\n",
            "     BatchNorm2d-124             [-1, 96, 8, 8]             192\n",
            "          Conv2d-125             [-1, 96, 8, 8]           9,216\n",
            "     BatchNorm2d-126             [-1, 96, 8, 8]             192\n",
            "            ReLU-127             [-1, 96, 8, 8]               0\n",
            "          Conv2d-128           [-1, 96, 16, 16]           9,216\n",
            "     BatchNorm2d-129           [-1, 96, 16, 16]             192\n",
            "            ReLU-130           [-1, 96, 16, 16]               0\n",
            "          Conv2d-131             [-1, 96, 8, 8]             864\n",
            "     BatchNorm2d-132             [-1, 96, 8, 8]             192\n",
            "          Conv2d-133             [-1, 96, 8, 8]           9,216\n",
            "     BatchNorm2d-134             [-1, 96, 8, 8]             192\n",
            "            ReLU-135             [-1, 96, 8, 8]               0\n",
            "InvertedResidual-136            [-1, 192, 8, 8]               0\n",
            "          Conv2d-137             [-1, 96, 8, 8]           9,216\n",
            "     BatchNorm2d-138             [-1, 96, 8, 8]             192\n",
            "            ReLU-139             [-1, 96, 8, 8]               0\n",
            "          Conv2d-140             [-1, 96, 8, 8]             864\n",
            "     BatchNorm2d-141             [-1, 96, 8, 8]             192\n",
            "          Conv2d-142             [-1, 96, 8, 8]           9,216\n",
            "     BatchNorm2d-143             [-1, 96, 8, 8]             192\n",
            "            ReLU-144             [-1, 96, 8, 8]               0\n",
            "InvertedResidual-145            [-1, 192, 8, 8]               0\n",
            "          Conv2d-146             [-1, 96, 8, 8]           9,216\n",
            "     BatchNorm2d-147             [-1, 96, 8, 8]             192\n",
            "            ReLU-148             [-1, 96, 8, 8]               0\n",
            "          Conv2d-149             [-1, 96, 8, 8]             864\n",
            "     BatchNorm2d-150             [-1, 96, 8, 8]             192\n",
            "          Conv2d-151             [-1, 96, 8, 8]           9,216\n",
            "     BatchNorm2d-152             [-1, 96, 8, 8]             192\n",
            "            ReLU-153             [-1, 96, 8, 8]               0\n",
            "InvertedResidual-154            [-1, 192, 8, 8]               0\n",
            "          Conv2d-155             [-1, 96, 8, 8]           9,216\n",
            "     BatchNorm2d-156             [-1, 96, 8, 8]             192\n",
            "            ReLU-157             [-1, 96, 8, 8]               0\n",
            "          Conv2d-158             [-1, 96, 8, 8]             864\n",
            "     BatchNorm2d-159             [-1, 96, 8, 8]             192\n",
            "          Conv2d-160             [-1, 96, 8, 8]           9,216\n",
            "     BatchNorm2d-161             [-1, 96, 8, 8]             192\n",
            "            ReLU-162             [-1, 96, 8, 8]               0\n",
            "InvertedResidual-163            [-1, 192, 8, 8]               0\n",
            "          Conv2d-164           [-1, 1024, 8, 8]         196,608\n",
            "     BatchNorm2d-165           [-1, 1024, 8, 8]           2,048\n",
            "            ReLU-166           [-1, 1024, 8, 8]               0\n",
            "          Linear-167                 [-1, 1000]       1,025,000\n",
            "    ShuffleNetV2-168                 [-1, 1000]               0\n",
            "          Linear-169                   [-1, 26]          26,026\n",
            "================================================================\n",
            "Total params: 1,392,818\n",
            "Trainable params: 1,392,818\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 32.73\n",
            "Params size (MB): 5.31\n",
            "Estimated Total Size (MB): 38.80\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wpct3mxpkmz"
      },
      "source": [
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "folds=[]\n",
        "for train_idx, valid_idx in kf.split(labels_df):\n",
        "    folds.append((train_idx, valid_idx))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO--rnXgqNk_"
      },
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuXhJAz-TPWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3206af-66e2-4f37-a139-1c86118ca56e"
      },
      "source": [
        "#seed_everything(42)\n",
        "for fold in range(1):\n",
        "    model = my_Shuffle().to(device)\n",
        "#     model = nn.DataParallel(model)\n",
        "    train_idx = folds[fold][0]\n",
        "    valid_idx = folds[fold][1]\n",
        "\n",
        "    train_transform = transforms.Compose([                                \n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "        ])\n",
        "    valid_transform = transforms.Compose([                                 \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]\n",
        "    )\n",
        "        ])\n",
        "\n",
        "\n",
        "    epochs=20\n",
        "    batch_size=32   # 자신의 VRAM에 맞게 조절해야 OOM을 피할 수 있습니다.\n",
        "    \n",
        "    \n",
        "    # Data Loader\n",
        "    train_dataset = MnistDataset_v1(imgs_dir=imgs_dir[train_idx], labels=labels[train_idx], transform=train_transform)\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    valid_dataset = MnistDataset_v1(imgs_dir=imgs_dir[valid_idx], labels=labels[valid_idx], transform=valid_transform)\n",
        "    valid_loader = DataLoader(dataset=valid_dataset, batch_size=32, shuffle=False)  \n",
        "    \n",
        "    \n",
        "    # optimizer\n",
        "    # polynomial optimizer를 사용합니다.\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones= [23,29], gamma=0.1)\n",
        "\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    \n",
        "    \n",
        "    epoch_accuracy = []\n",
        "    valid_accuracy = []\n",
        "    valid_losses=[]\n",
        "    valid_best_accuracy=0\n",
        "\n",
        "    best_models=[]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      with tqdm(train_loader,total=train_loader.__len__(),unit='batch') as train_bar:\n",
        "        model.train()\n",
        "        batch_accuracy_list = []\n",
        "        batch_loss_list = []\n",
        "        start=time.time()\n",
        "        for n, (X, y) in enumerate((train_bar)):\n",
        "            train_bar.set_description(f\"Train Epoch {epoch}\")\n",
        "            X = torch.tensor(X, device=device, dtype=torch.float32)\n",
        "            y = torch.tensor(y, device=device, dtype=torch.float32)\n",
        "            y_hat = model(X)\n",
        "            \n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(y_hat, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            \n",
        "            y_hat  = y_hat.cpu().detach().numpy()\n",
        "            y_hat = y_hat>0.5\n",
        "            y = y.cpu().detach().numpy()\n",
        "\n",
        "            batch_accuracy = (y_hat == y).mean()\n",
        "            batch_accuracy_list.append(batch_accuracy)\n",
        "            batch_loss_list.append(loss.item())\n",
        "            train_acc = np.mean(batch_accuracy_list)\n",
        "            \n",
        "            train_bar.set_postfix(train_loss= loss.item(),train_acc = train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        valid_batch_accuracy=[]\n",
        "        valid_batch_loss = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "          with tqdm(valid_loader,total=valid_loader.__len__(),unit=\"batch\") as valid_bar:\n",
        "            for n_valid, (X_valid, y_valid) in enumerate((valid_bar)):\n",
        "                valid_bar.set_description(f\"Valid Epoch {epoch}\")\n",
        "                X_valid = torch.tensor(X_valid, device=device)#, dtype=torch.float32)\n",
        "                y_valid = torch.tensor(y_valid, device=device, dtype=torch.float32)\n",
        "                y_valid_hat = model(X_valid)\n",
        "                \n",
        "                valid_loss = criterion(y_valid_hat, y_valid).item()\n",
        "                \n",
        "                y_valid_hat = y_valid_hat.cpu().detach().numpy()>0.5\n",
        "                \n",
        "                \n",
        "                valid_batch_loss.append(valid_loss)\n",
        "                valid_batch_accuracy.append((y_valid_hat == y_valid.cpu().detach().numpy()).mean())\n",
        "                val_acc=np.mean(valid_batch_accuracy)\n",
        "                valid_bar.set_postfix(valid_loss = valid_loss,valid_acc = val_acc)\n",
        "                \n",
        "            valid_losses.append(np.mean(valid_batch_loss))\n",
        "            valid_accuracy.append(np.mean(valid_batch_accuracy))\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        if np.mean(valid_batch_accuracy) > 0.78:\n",
        "            path = \"/content/drive/MyDrive/21-1/models_3/\"\n",
        "            MODEL = \"BEST_ShuffleNetV2\"\n",
        "            torch.save(model, f'{path}_{MODEL}_{valid_loss:2.4f}_epoch_{epoch}.pth')\n",
        "\n",
        "        if np.mean(valid_batch_accuracy)>valid_best_accuracy:\n",
        "            best_model=model\n",
        "            valid_best_accuracy = np.mean(valid_batch_accuracy)\n",
        "            path = \"/content/drive/MyDrive/21-1/models_3/\"\n",
        "            MODEL = \"0222_ShuffleNetV2\"\n",
        "            torch.save(model, f'{path}_{MODEL}_{valid_loss:2.4f}_epoch_{epoch}.pth')\n",
        "\n",
        "\n",
        "    best_models.append(best_model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch 0:   0%|          | 0/625 [00:00<?, ?batch/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "Train Epoch 0: 100%|██████████| 625/625 [07:16<00:00,  1.43batch/s, train_acc=0.526, train_loss=0.696]\n",
            "Valid Epoch 0:   0%|          | 0/313 [00:00<?, ?batch/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "Valid Epoch 0: 100%|██████████| 313/313 [00:27<00:00, 11.42batch/s, valid_acc=0.524, valid_loss=0.688]\n",
            "Train Epoch 1: 100%|██████████| 625/625 [06:56<00:00,  1.50batch/s, train_acc=0.539, train_loss=0.683]\n",
            "Valid Epoch 1: 100%|██████████| 313/313 [00:25<00:00, 12.38batch/s, valid_acc=0.547, valid_loss=0.691]\n",
            "Train Epoch 2: 100%|██████████| 625/625 [06:51<00:00,  1.52batch/s, train_acc=0.554, train_loss=0.685]\n",
            "Valid Epoch 2: 100%|██████████| 313/313 [00:25<00:00, 12.47batch/s, valid_acc=0.56, valid_loss=0.676]\n",
            "Train Epoch 3: 100%|██████████| 625/625 [06:52<00:00,  1.51batch/s, train_acc=0.567, train_loss=0.672]\n",
            "Valid Epoch 3: 100%|██████████| 313/313 [00:24<00:00, 12.61batch/s, valid_acc=0.571, valid_loss=0.673]\n",
            "Train Epoch 4: 100%|██████████| 625/625 [06:56<00:00,  1.50batch/s, train_acc=0.579, train_loss=0.67]\n",
            "Valid Epoch 4: 100%|██████████| 313/313 [00:25<00:00, 12.38batch/s, valid_acc=0.581, valid_loss=0.665]\n",
            "Train Epoch 5: 100%|██████████| 625/625 [06:52<00:00,  1.52batch/s, train_acc=0.591, train_loss=0.67]\n",
            "Valid Epoch 5: 100%|██████████| 313/313 [00:25<00:00, 12.36batch/s, valid_acc=0.591, valid_loss=0.663]\n",
            "Train Epoch 6: 100%|██████████| 625/625 [06:53<00:00,  1.51batch/s, train_acc=0.603, train_loss=0.658]\n",
            "Valid Epoch 6: 100%|██████████| 313/313 [00:25<00:00, 12.44batch/s, valid_acc=0.603, valid_loss=0.627]\n",
            "Train Epoch 7: 100%|██████████| 625/625 [06:54<00:00,  1.51batch/s, train_acc=0.613, train_loss=0.662]\n",
            "Valid Epoch 7: 100%|██████████| 313/313 [00:24<00:00, 12.62batch/s, valid_acc=0.605, valid_loss=0.654]\n",
            "Train Epoch 8: 100%|██████████| 625/625 [06:50<00:00,  1.52batch/s, train_acc=0.621, train_loss=0.651]\n",
            "Valid Epoch 8: 100%|██████████| 313/313 [00:24<00:00, 12.70batch/s, valid_acc=0.611, valid_loss=0.648]\n",
            "Train Epoch 9: 100%|██████████| 625/625 [06:48<00:00,  1.53batch/s, train_acc=0.628, train_loss=0.629]\n",
            "Valid Epoch 9: 100%|██████████| 313/313 [00:24<00:00, 12.80batch/s, valid_acc=0.621, valid_loss=0.627]\n",
            "Train Epoch 10: 100%|██████████| 625/625 [06:48<00:00,  1.53batch/s, train_acc=0.635, train_loss=0.638]\n",
            "Valid Epoch 10: 100%|██████████| 313/313 [00:24<00:00, 12.82batch/s, valid_acc=0.633, valid_loss=0.625]\n",
            "Train Epoch 11: 100%|██████████| 625/625 [06:49<00:00,  1.53batch/s, train_acc=0.64, train_loss=0.638]\n",
            "Valid Epoch 11: 100%|██████████| 313/313 [00:24<00:00, 12.70batch/s, valid_acc=0.639, valid_loss=0.625]\n",
            "Train Epoch 12: 100%|██████████| 625/625 [06:50<00:00,  1.52batch/s, train_acc=0.646, train_loss=0.623]\n",
            "Valid Epoch 12: 100%|██████████| 313/313 [00:24<00:00, 12.68batch/s, valid_acc=0.643, valid_loss=0.626]\n",
            "Train Epoch 13: 100%|██████████| 625/625 [06:50<00:00,  1.52batch/s, train_acc=0.651, train_loss=0.601]\n",
            "Valid Epoch 13: 100%|██████████| 313/313 [00:24<00:00, 12.71batch/s, valid_acc=0.646, valid_loss=0.629]\n",
            "Train Epoch 14: 100%|██████████| 625/625 [06:48<00:00,  1.53batch/s, train_acc=0.656, train_loss=0.623]\n",
            "Valid Epoch 14: 100%|██████████| 313/313 [00:24<00:00, 12.80batch/s, valid_acc=0.648, valid_loss=0.611]\n",
            "Train Epoch 15: 100%|██████████| 625/625 [06:48<00:00,  1.53batch/s, train_acc=0.66, train_loss=0.613]\n",
            "Valid Epoch 15: 100%|██████████| 313/313 [00:24<00:00, 12.85batch/s, valid_acc=0.655, valid_loss=0.621]\n",
            "Train Epoch 16: 100%|██████████| 625/625 [06:48<00:00,  1.53batch/s, train_acc=0.663, train_loss=0.601]\n",
            "Valid Epoch 16: 100%|██████████| 313/313 [00:24<00:00, 12.86batch/s, valid_acc=0.658, valid_loss=0.617]\n",
            "Train Epoch 17: 100%|██████████| 625/625 [06:46<00:00,  1.54batch/s, train_acc=0.668, train_loss=0.609]\n",
            "Valid Epoch 17: 100%|██████████| 313/313 [00:24<00:00, 12.87batch/s, valid_acc=0.66, valid_loss=0.615]\n",
            "Train Epoch 18: 100%|██████████| 625/625 [06:48<00:00,  1.53batch/s, train_acc=0.671, train_loss=0.618]\n",
            "Valid Epoch 18: 100%|██████████| 313/313 [00:23<00:00, 13.22batch/s, valid_acc=0.666, valid_loss=0.6]\n",
            "Train Epoch 19: 100%|██████████| 625/625 [06:47<00:00,  1.54batch/s, train_acc=0.674, train_loss=0.591]\n",
            "Valid Epoch 19: 100%|██████████| 313/313 [00:25<00:00, 12.49batch/s, valid_acc=0.669, valid_loss=0.606]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB4MyqQrF-ml"
      },
      "source": [
        "best_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OAMaNeiI2Qi"
      },
      "source": [
        "test_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "        [0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "test_dataset = MnistDataset_v1(imgs_dir=test_imgs_dir, transform=test_transform, train=False)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq6jnTJCJRfJ",
        "outputId": "7ea1d65f-3cb0-4095-cc6b-d17db3ec849a"
      },
      "source": [
        "submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "for model in best_models:\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        test_dataset = MnistDataset_v1(imgs_dir=test_imgs_dir, transform=test_transform, train=False)\n",
        "        test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "        for n, X_test in enumerate(tqdm(test_loader)):\n",
        "            X_test = torch.tensor(X_test, device=device, dtype=torch.float32)\n",
        "            with torch.no_grad():\n",
        "                model.eval()  \n",
        "                pred_test = model(X_test).cpu().detach().numpy()\n",
        "                submission.iloc[n*32:(n+1)*32,1:] += pred_test"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  1%|▏         | 2/157 [00:00<00:14, 10.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  3%|▎         | 4/157 [00:00<00:13, 11.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  4%|▍         | 6/157 [00:00<00:13, 11.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  5%|▌         | 8/157 [00:00<00:12, 11.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  6%|▋         | 10/157 [00:00<00:12, 11.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  8%|▊         | 12/157 [00:00<00:12, 12.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  9%|▉         | 14/157 [00:01<00:11, 12.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 10%|█         | 16/157 [00:01<00:11, 12.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 11%|█▏        | 18/157 [00:01<00:11, 12.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 13%|█▎        | 20/157 [00:01<00:11, 12.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 14%|█▍        | 22/157 [00:01<00:10, 12.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 15%|█▌        | 24/157 [00:01<00:10, 12.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 17%|█▋        | 26/157 [00:02<00:10, 12.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 18%|█▊        | 28/157 [00:02<00:10, 12.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 19%|█▉        | 30/157 [00:02<00:10, 12.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 20%|██        | 32/157 [00:02<00:10, 12.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 22%|██▏       | 34/157 [00:02<00:09, 12.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 23%|██▎       | 36/157 [00:02<00:09, 12.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 24%|██▍       | 38/157 [00:03<00:09, 12.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 25%|██▌       | 40/157 [00:03<00:09, 12.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 27%|██▋       | 42/157 [00:03<00:09, 12.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 28%|██▊       | 44/157 [00:03<00:08, 12.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 29%|██▉       | 46/157 [00:03<00:08, 12.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 31%|███       | 48/157 [00:03<00:08, 12.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 32%|███▏      | 50/157 [00:04<00:08, 12.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 33%|███▎      | 52/157 [00:04<00:08, 12.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 34%|███▍      | 54/157 [00:04<00:08, 12.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 36%|███▌      | 56/157 [00:04<00:08, 12.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 37%|███▋      | 58/157 [00:04<00:07, 12.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 38%|███▊      | 60/157 [00:04<00:07, 12.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 39%|███▉      | 62/157 [00:04<00:07, 12.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 41%|████      | 64/157 [00:05<00:07, 12.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 42%|████▏     | 66/157 [00:05<00:07, 12.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 43%|████▎     | 68/157 [00:05<00:07, 12.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 45%|████▍     | 70/157 [00:05<00:06, 12.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 46%|████▌     | 72/157 [00:05<00:06, 12.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 47%|████▋     | 74/157 [00:05<00:06, 12.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 48%|████▊     | 76/157 [00:06<00:06, 12.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 50%|████▉     | 78/157 [00:06<00:06, 12.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 51%|█████     | 80/157 [00:06<00:06, 12.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 52%|█████▏    | 82/157 [00:06<00:06, 12.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 54%|█████▎    | 84/157 [00:06<00:05, 12.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 55%|█████▍    | 86/157 [00:06<00:05, 12.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 56%|█████▌    | 88/157 [00:07<00:05, 12.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 57%|█████▋    | 90/157 [00:07<00:05, 12.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 59%|█████▊    | 92/157 [00:07<00:05, 12.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 60%|█████▉    | 94/157 [00:07<00:05, 12.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 61%|██████    | 96/157 [00:07<00:04, 12.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 62%|██████▏   | 98/157 [00:07<00:04, 12.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 64%|██████▎   | 100/157 [00:08<00:04, 11.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 65%|██████▍   | 102/157 [00:08<00:04, 11.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 66%|██████▌   | 104/157 [00:08<00:04, 11.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 68%|██████▊   | 106/157 [00:08<00:04, 11.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 69%|██████▉   | 108/157 [00:08<00:04, 11.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 70%|███████   | 110/157 [00:08<00:04, 11.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 71%|███████▏  | 112/157 [00:09<00:03, 11.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 73%|███████▎  | 114/157 [00:09<00:03, 11.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 74%|███████▍  | 116/157 [00:09<00:03, 11.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 75%|███████▌  | 118/157 [00:09<00:03, 11.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 76%|███████▋  | 120/157 [00:09<00:03, 11.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 78%|███████▊  | 122/157 [00:10<00:03, 11.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 79%|███████▉  | 124/157 [00:10<00:02, 11.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 80%|████████  | 126/157 [00:10<00:02, 11.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 82%|████████▏ | 128/157 [00:10<00:02, 11.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 83%|████████▎ | 130/157 [00:10<00:02, 12.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 84%|████████▍ | 132/157 [00:10<00:02, 12.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 85%|████████▌ | 134/157 [00:10<00:01, 12.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 87%|████████▋ | 136/157 [00:11<00:01, 12.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 88%|████████▊ | 138/157 [00:11<00:01, 12.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 89%|████████▉ | 140/157 [00:11<00:01, 12.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 90%|█████████ | 142/157 [00:11<00:01, 12.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 92%|█████████▏| 144/157 [00:11<00:01, 12.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 93%|█████████▎| 146/157 [00:11<00:00, 12.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 94%|█████████▍| 148/157 [00:12<00:00, 12.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 96%|█████████▌| 150/157 [00:12<00:00, 12.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 97%|█████████▋| 152/157 [00:12<00:00, 12.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " 98%|█████████▊| 154/157 [00:12<00:00, 12.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "100%|██████████| 157/157 [00:12<00:00, 12.24it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ZMWChi9CKrnI",
        "outputId": "b8128cb7-b093-4dc6-9024-0b91e5e10565"
      },
      "source": [
        "submission.iloc[:,1:] = np.where(submission.values[:,1:]>=0.5, 1,0)\n",
        "submission"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>f</th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "      <th>i</th>\n",
              "      <th>j</th>\n",
              "      <th>k</th>\n",
              "      <th>l</th>\n",
              "      <th>m</th>\n",
              "      <th>n</th>\n",
              "      <th>o</th>\n",
              "      <th>p</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>t</th>\n",
              "      <th>u</th>\n",
              "      <th>v</th>\n",
              "      <th>w</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50001</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50004</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>54995</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>54996</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>54997</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>54998</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>54999</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index  a  b  c  d  e  f  g  h  i  j  ...  p  q  r  s  t  u  v  w  x  y  z\n",
              "0     50000  0  1  1  0  0  0  0  1  1  1  ...  1  0  0  0  0  1  1  0  1  0  0\n",
              "1     50001  0  1  1  1  0  0  1  0  1  0  ...  1  1  1  1  0  0  1  0  0  0  0\n",
              "2     50002  0  0  1  1  1  1  1  0  1  0  ...  1  0  0  0  0  0  0  1  0  0  0\n",
              "3     50003  1  1  0  0  0  0  1  0  0  0  ...  0  1  0  0  0  0  0  0  0  0  0\n",
              "4     50004  0  1  1  0  0  0  1  0  0  0  ...  0  0  0  1  0  1  1  1  0  0  0\n",
              "...     ... .. .. .. .. .. .. .. .. .. ..  ... .. .. .. .. .. .. .. .. .. .. ..\n",
              "4995  54995  0  0  1  0  0  1  0  0  1  0  ...  0  0  0  0  1  0  0  1  1  1  0\n",
              "4996  54996  1  0  1  0  0  0  0  0  1  1  ...  0  0  0  0  0  1  0  0  0  0  0\n",
              "4997  54997  0  0  1  1  0  1  0  0  0  1  ...  0  1  0  1  1  1  0  0  0  1  0\n",
              "4998  54998  0  0  1  1  0  0  1  0  1  1  ...  1  1  1  1  0  0  0  0  0  0  0\n",
              "4999  54999  0  0  0  0  0  1  1  0  1  0  ...  0  0  0  1  0  0  0  1  0  0  1\n",
              "\n",
              "[5000 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXlk_nCNKreG"
      },
      "source": [
        "submission.to_csv('PREDICTION;ShuffleNetV2_prediction.csv', index=False)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "UulqALO9KrPu",
        "outputId": "e5369131-b6cb-405e-fb3c-03d8a3699f95"
      },
      "source": [
        "pred=pd.read_csv('/content/data/PREDICTION;ShuffleNetV2_prediction.csv')\n",
        "pred.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "      <th>f</th>\n",
              "      <th>g</th>\n",
              "      <th>h</th>\n",
              "      <th>i</th>\n",
              "      <th>j</th>\n",
              "      <th>k</th>\n",
              "      <th>l</th>\n",
              "      <th>m</th>\n",
              "      <th>n</th>\n",
              "      <th>o</th>\n",
              "      <th>p</th>\n",
              "      <th>q</th>\n",
              "      <th>r</th>\n",
              "      <th>s</th>\n",
              "      <th>t</th>\n",
              "      <th>u</th>\n",
              "      <th>v</th>\n",
              "      <th>w</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50000</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50001</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>50002</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50004</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  a  b  c  d  e  f  g  h  i  j  k  ...  o  p  q  r  s  t  u  v  w  x  y  z\n",
              "0  50000  0  1  1  0  0  0  0  1  1  1  0  ...  0  1  0  0  0  0  1  1  0  1  0  0\n",
              "1  50001  0  1  1  1  0  0  1  0  1  0  0  ...  0  1  1  1  1  0  0  1  0  0  0  0\n",
              "2  50002  0  0  1  1  1  1  1  0  1  0  0  ...  0  1  0  0  0  0  0  0  1  0  0  0\n",
              "3  50003  1  1  0  0  0  0  1  0  0  0  1  ...  0  0  1  0  0  0  0  0  0  0  0  0\n",
              "4  50004  0  1  1  0  0  0  1  0  0  0  0  ...  1  0  0  0  1  0  1  1  1  0  0  0\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    }
  ]
}